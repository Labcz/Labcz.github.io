<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>IDEA大数据环境安装</title>
    <url>/ckhnafzrj0001etfp2bo1eop5.html</url>
    <content><![CDATA[<h1 id="安装准备"><a href="#安装准备" class="headerlink" title="安装准备"></a>安装准备</h1><h2 id="软件下载"><a href="#软件下载" class="headerlink" title="软件下载"></a>软件下载</h2><p>Scala下载：<a href="https://www.scala-lang.org/download/">https://www.scala-lang.org/download/</a></p>
<p>Spark下载：<a href="https://mirrors.cloud.tencent.com/apache/spark/">https://mirrors.cloud.tencent.com/apache/spark/</a></p>
<div class="note warning flat"><p>without-hadoop版本中不含编译好的hadoop，试用于Linux上已配置好hadoop环境</p>
</div>

<p>Apache-maven下载：<a href="https://mirrors.tuna.tsinghua.edu.cn/apache/maven/maven-3/">https://mirrors.tuna.tsinghua.edu.cn/apache/maven/maven-3/</a></p>
<p>hadoop下载：<a href="http://mirror.bit.edu.cn/apache/hadoop/common/">http://mirror.bit.edu.cn/apache/hadoop/common/</a></p>
<p>IntelliJ IDEA下载：<a href="https://www.jetbrains.com/idea/download/#section=windows">https://www.jetbrains.com/idea/download/#section=windows</a></p>
<h2 id="配置环境变量"><a href="#配置环境变量" class="headerlink" title="配置环境变量"></a>配置环境变量</h2><p>将下述文件安装包解压</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/IDEA大数据环境安装/1.png" style="zoom:100%;" />

<p>配置MAVEN环境变量</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/IDEA大数据环境安装/2.png" style="zoom:76%;" />

<p>配置SCALA环境变量</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/IDEA大数据环境安装/3.png" style="zoom:76%;" />

<p>配置HADOOP环境变量</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/IDEA大数据环境安装/4.png" style="zoom:76%;" />

<p>配置SPARK环境变量</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/IDEA大数据环境安装/5.png" style="zoom:76%;" />

<p>配置Path追加以下变量</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/IDEA大数据环境安装/6.png" style="zoom:76%;" />



<p>测试环境变量是否配置成功</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">C:\Users\Labcz&gt;mvn -version</span><br><span class="line">Apache Maven 3.6.3 (cecedd343002696d0abb50b32b541b8a6ba2883f)</span><br><span class="line">Maven home: D:\BaiduNetdiskDownload\BigDataTools\apache-maven-3.6.3-bin\apache-maven-3.6.3\bin\..</span><br><span class="line">Java version: 12.0.2, vendor: Oracle Corporation, runtime: C:\Program Files\Java\jdk-12.0.2</span><br><span class="line">Default locale: zh_CN, platform encoding: GBK</span><br><span class="line">OS name: &quot;windows 10&quot;, version: &quot;10.0&quot;, arch: &quot;amd64&quot;, family: &quot;windows&quot;</span><br><span class="line"></span><br><span class="line">C:\Users\Labcz&gt;scala -version</span><br><span class="line">Scala code runner version 2.13.3 -- Copyright 2002-2020, LAMP&#x2F;EPFL and Lightbend, Inc.</span><br><span class="line"></span><br><span class="line">C:\Users\Labcz&gt;hadoop version</span><br><span class="line">Hadoop 3.3.0</span><br><span class="line">Source code repository https:&#x2F;&#x2F;gitbox.apache.org&#x2F;repos&#x2F;asf&#x2F;hadoop.git -r aa96f1871bfd858f9bac59cf2a81ec470da649af</span><br><span class="line">Compiled by brahma on 2020-07-06T18:44Z</span><br><span class="line">Compiled with protoc 3.7.1</span><br><span class="line">From source with checksum 5dc29b802d6ccd77b262ef9d04d19c4</span><br><span class="line">This command was run using &#x2F;D:&#x2F;BaiduNetdiskDownload&#x2F;BigDataTools&#x2F;hadoop-3.3.0&#x2F;hadoop-3.3.0&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;hadoop-common-3.3.0.jar</span><br></pre></td></tr></table></figure>

<div class="note warning flat"><p>若测试hadoop显示</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/IDEA大数据环境安装/11.png" style="zoom:76%;" />

<p>需要修改<code>\etc\hadoop\hadoop-env.cmd文件</code></p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/IDEA大数据环境安装/12.png" style="zoom:76%;" />
</div>

<h2 id="配置Spark"><a href="#配置Spark" class="headerlink" title="配置Spark"></a>配置Spark</h2><p>配置完成后在cmd命令行下输入<code>spark-shell</code>，将会提示缺少winutils</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/IDEA大数据环境安装/7.png" style="zoom:76%;" />

<p>winutils下载：<a href="https://gitee.com/labcz/winutils">https://gitee.com/labcz/winutils</a></p>
<p>将winutils.exe放入hadoop的bin目录下</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/IDEA大数据环境安装/8.png" style="zoom:76%;" />

<p>再次cmd命令行下输入<code>spark-shell</code>，即可运行成功</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/IDEA大数据环境安装/9.png" style="zoom:76%;" />

<p>测试Spark</p>
<p>在桌面新建一个测试txt文本文档</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/IDEA大数据环境安装/10.png" style="zoom:76%;" />

<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> textFile = spark.read.textFile(<span class="string">&quot;C:\\Users\\Labcz\\Desktop\\hello.txt&quot;</span>)</span><br><span class="line">textFile: org.apache.spark.sql.<span class="type">Dataset</span>[<span class="type">String</span>] = [value: string]</span><br><span class="line"></span><br><span class="line">scala&gt; textFile.count</span><br><span class="line">res0: <span class="type">Long</span> = <span class="number">3</span></span><br></pre></td></tr></table></figure>

<p>此时spark单机版环境安装完成</p>
<h2 id="配置maven"><a href="#配置maven" class="headerlink" title="配置maven"></a>配置maven</h2><p>修改maven目录下的<code>conf/settings.xml</code>添加以下内容</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">settings</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://maven.apache.org/SETTINGS/1.0.0&quot;</span></span></span><br><span class="line"><span class="tag">          <span class="attr">xmlns:xsi</span>=<span class="string">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span></span></span><br><span class="line"><span class="tag">          <span class="attr">xsi:schemaLocation</span>=<span class="string">&quot;http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd&quot;</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- localRepository</span></span><br><span class="line"><span class="comment">   | The path to the local repository maven will use to store artifacts.</span></span><br><span class="line"><span class="comment">   |</span></span><br><span class="line"><span class="comment">   | Default: $&#123;user.home&#125;/.m2/repository</span></span><br><span class="line"><span class="comment">  &lt;localRepository&gt;/path/to/local/repo&lt;/localRepository&gt;</span></span><br><span class="line"><span class="comment">  --&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--maven从网络上下载的jar包在本地缓存的路径 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">localRepository</span>&gt;</span>D:/BaiduNetdiskDownload/BigDataTools/maven_jars<span class="tag">&lt;/<span class="name">localRepository</span>&gt;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">mirrors</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- mirror</span></span><br><span class="line"><span class="comment">     | Specifies a repository mirror site to use instead of a given repository. The repository that</span></span><br><span class="line"><span class="comment">     | this mirror serves has an ID that matches the mirrorOf element of this mirror. IDs are used</span></span><br><span class="line"><span class="comment">     | for inheritance and direct lookup purposes, and must be unique across the set of mirrors.</span></span><br><span class="line"><span class="comment">     |</span></span><br><span class="line"><span class="comment">    &lt;mirror&gt;</span></span><br><span class="line"><span class="comment">      &lt;id&gt;mirrorId&lt;/id&gt;</span></span><br><span class="line"><span class="comment">      &lt;mirrorOf&gt;repositoryId&lt;/mirrorOf&gt;</span></span><br><span class="line"><span class="comment">      &lt;name&gt;Human Readable Name for this Mirror.&lt;/name&gt;</span></span><br><span class="line"><span class="comment">      &lt;url&gt;http://my.repository.com/repo/path&lt;/url&gt;</span></span><br><span class="line"><span class="comment">    &lt;/mirror&gt;</span></span><br><span class="line"><span class="comment">     --&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--配置maven国内的镜像--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">mirror</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">id</span>&gt;</span>alimaven<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>aliyun maven<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">url</span>&gt;</span>http://maven.aliyun.com/nexus/content/groups/public/<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">mirrorOf</span>&gt;</span>central<span class="tag">&lt;/<span class="name">mirrorOf</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">mirror</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="tag">&lt;<span class="name">mirror</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">id</span>&gt;</span>repo2<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">mirrorOf</span>&gt;</span>central<span class="tag">&lt;/<span class="name">mirrorOf</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>Human Readable Name for this Mirror.<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">url</span>&gt;</span>http://repo2.maven.org/maven2/<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">mirror</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">mirror</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">id</span>&gt;</span>ui<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">mirrorOf</span>&gt;</span>central<span class="tag">&lt;/<span class="name">mirrorOf</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>Human Readable Name for this Mirror.<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">url</span>&gt;</span>http://uk.maven.org/maven2/<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">mirror</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">mirrors</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h1 id="安装IntelliJ-IDEA"><a href="#安装IntelliJ-IDEA" class="headerlink" title="安装IntelliJ IDEA"></a>安装IntelliJ IDEA</h1><img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/IDEA大数据环境安装/13.png" style="zoom:76%;" />

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/IDEA大数据环境安装/14.png" style="zoom:76%;" />

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/IDEA大数据环境安装/15.png" style="zoom:76%;" />

<h2 id="安装Scala插件"><a href="#安装Scala插件" class="headerlink" title="安装Scala插件"></a>安装Scala插件</h2><img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/IDEA大数据环境安装/16.png" style="zoom:76%;" />

<p>选择Plugins，搜索并安装Scala插件</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/IDEA大数据环境安装/17.png" style="zoom:76%;" />

<h2 id="配置IDEA"><a href="#配置IDEA" class="headerlink" title="配置IDEA"></a>配置IDEA</h2><h3 id="配置Scala"><a href="#配置Scala" class="headerlink" title="配置Scala"></a>配置Scala</h3><p>选择Structure for New Project</p>
<p>选择JDK版本</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/IDEA大数据环境安装/18.png" style="zoom:76%;" />

<p>添加Scala SDK</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/IDEA大数据环境安装/19.png" style="zoom:76%;" />

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/IDEA大数据环境安装/20.png" style="zoom:76%;" />

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/IDEA大数据环境安装/21.png" style="zoom:76%;" />

<p><code>Apply</code>应用配置</p>
<p>###　配置maven</p>
<p>选择<code>Settings</code></p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/IDEA大数据环境安装/22.png" style="zoom:76%;" />

<p>进入<code>Build,Execution,Deployment - Build Tools - Maven</code></p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/IDEA大数据环境安装/23.png" style="zoom:76%;" />

<p>根据自己安装的maven进行配置</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/IDEA大数据环境安装/24.png" style="zoom:76%;" />

]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux多节点环境打造</title>
    <url>/ckhnafzrn0003etfp81yg9i41.html</url>
    <content><![CDATA[<h1 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h1><div class="note success no-icon flat"><p>1、提前安装  <a href="https://www.vmware.com/">VMware</a>虚拟机</p>
<p>2、镜像下载：<a href="https://www.centos.org/download/">CentOS</a> 以及<a href="https://ubuntu.com/download/desktop">Ubuntu</a> 系统镜像</p>
</div>

<div class="note info flat"><p>系统镜像推荐使用阿里云镜像站点下载: <a href="https://developer.aliyun.com/mirror/">https://developer.aliyun.com/mirror/</a></p>
</div>

<p>本文使用：</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/Linux多节点环境打造/Linux01.png" style="zoom:67%;" /> 

<h1 id="虚拟机配置"><a href="#虚拟机配置" class="headerlink" title="虚拟机配置"></a>虚拟机配置</h1><h2 id="点击新建虚拟机"><a href="#点击新建虚拟机" class="headerlink" title="点击新建虚拟机"></a>点击新建虚拟机</h2><img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/Linux多节点环境打造/step1.png" style="zoom:67%;" />

<h2 id="选择自定义安装"><a href="#选择自定义安装" class="headerlink" title="选择自定义安装"></a>选择<code>自定义安装</code></h2><img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/Linux多节点环境打造/step2.png" style="zoom:67%;" />

<h2 id="虚拟机兼容性选择"><a href="#虚拟机兼容性选择" class="headerlink" title="虚拟机兼容性选择"></a>虚拟机兼容性选择</h2><p>这里要注意兼容性，如果是VMware15创建的虚拟机复制到VM11、10或者更低的版本会出现一不兼容的现象。如果是用VMware12创建的虚拟机在VMware15中打开则不会出现兼容性问题</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/Linux多节点环境打造/step3.png" style="zoom:67%;" />

<h2 id="选择稍后安装操作系统"><a href="#选择稍后安装操作系统" class="headerlink" title="选择稍后安装操作系统"></a>选择<code>稍后安装操作系统</code></h2><h2 id="选择操作系统"><a href="#选择操作系统" class="headerlink" title="选择操作系统"></a>选择操作系统</h2><p><strong>5、选择操作系统</strong></p>
<p>这里选择之后安装的操作系统，正确的选择会让VM Tools更好的兼容。这里选择linux下的CentOS</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/Linux多节点环境打造/step5.png" style="zoom:67%;" />

<h2 id="选择虚拟机位置与命名"><a href="#选择虚拟机位置与命名" class="headerlink" title="选择虚拟机位置与命名"></a>选择虚拟机位置与命名</h2><p>为该虚拟机就是一个名字，便于快速查找</p>
<div class="note warning flat"><p>虚拟机默认安装在C盘下，由于占用存储较大，建议更换安装路径</p>
</div>

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/Linux多节点环境打造/step6.png" style="zoom:67%;" />

<h2 id="处理器与内存的分配"><a href="#处理器与内存的分配" class="headerlink" title="处理器与内存的分配"></a>处理器与内存的分配</h2><p>处理器分配要根据自己的实际需求来分配。在使用过程中CPU不够的话是可以再增加的。这次只做安装CentOS演示，所以处理器与核心都选1</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/Linux多节点环境打造/step7.png" style="zoom:67%;" />

<h2 id="选择虚拟机内存"><a href="#选择虚拟机内存" class="headerlink" title="选择虚拟机内存"></a>选择虚拟机内存</h2><p>内存也是要根据实际的需求分配，这里选择配置1GB</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/Linux多节点环境打造/step8.png" style="zoom:67%;" />

<h2 id="选择网络类型"><a href="#选择网络类型" class="headerlink" title="选择网络类型"></a>选择网络类型</h2><blockquote>
<p>网络连接类型一共有桥接、NAT、仅主机和不联网四种。</p>
<p>桥接：选择桥接模式的话虚拟机和宿主机在网络上就是平级的关系，相当于连接在同一交换机上。</p>
<p>NAT：NAT模式就是虚拟机要联网得先通过宿主机才能和外面进行通信。</p>
<p>仅主机：虚拟机与宿主机直接连起来</p>
</blockquote>
<p>按照默认选择<code>使用网络地址转换(NAT)</code></p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/Linux多节点环境打造/step9.png" style="zoom:67%;" />

<h2 id="选择I-O控制器类型，选择默认推荐类型LSI-Logic"><a href="#选择I-O控制器类型，选择默认推荐类型LSI-Logic" class="headerlink" title="选择I/O控制器类型，选择默认推荐类型LSI Logic"></a>选择I/O控制器类型，选择默认推荐类型<code>LSI Logic</code></h2><img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/Linux多节点环境打造/step10.png" style="zoom:67%;" />

<h2 id="选择磁盘类型，选择默认推荐类型SCSI"><a href="#选择磁盘类型，选择默认推荐类型SCSI" class="headerlink" title="选择磁盘类型，选择默认推荐类型SCSI"></a>选择磁盘类型，选择默认推荐类型<code>SCSI</code></h2><img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/Linux多节点环境打造/step11.png" style="zoom:67%;" />

<h2 id="选择磁盘，选择默认推荐类型创建新虚拟磁盘"><a href="#选择磁盘，选择默认推荐类型创建新虚拟磁盘" class="headerlink" title="选择磁盘，选择默认推荐类型创建新虚拟磁盘"></a>选择磁盘，选择默认推荐类型<code>创建新虚拟磁盘</code></h2><img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/Linux多节点环境打造/step12.png" style="zoom:67%;" />

<h2 id="选择磁盘容量，选择默认推荐大小为20GB"><a href="#选择磁盘容量，选择默认推荐大小为20GB" class="headerlink" title="选择磁盘容量，选择默认推荐大小为20GB"></a>选择磁盘容量，选择默认推荐大小为20GB</h2><div class="note warning flat"><p><strong>同时选择<code>将虚拟磁盘拆分成多个文件</code></strong></p>
<p><strong>磁盘容量暂时分配20GB即可后期可以随时增加，<code>不要</code>勾选<code>立即分配所有磁盘</code>，否则虚拟机会将20GB直接分配给CentOS，会导致宿主机所剩硬盘容量减少。 勾选将虚拟磁盘拆分成多个文件，这样可以使虚拟机方便用储存设备拷贝复制。</strong></p>
</div>

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/Linux多节点环境打造/step13.png" style="zoom:67%;" />

<h2 id="指定磁盘文件，按照默认即可"><a href="#指定磁盘文件，按照默认即可" class="headerlink" title="指定磁盘文件，按照默认即可"></a>指定磁盘文件，按照默认即可</h2><img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/Linux多节点环境打造/step14.png" style="zoom:67%;" />

<h2 id="自定义硬件"><a href="#自定义硬件" class="headerlink" title="自定义硬件"></a>自定义硬件</h2><div class="note info flat"><p>可将不必要的硬件，例如：声卡，打印机，USB控制器移除，加快系统运行效率</p>
</div>

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/Linux多节点环境打造/step15.png" style="zoom:67%;" />

<div class="note danger flat"><p>选择<code>新CD/DVD(IDE)</code>由<code>自动检测</code>改为<code>准备好的iso系统镜像文件</code>，否则将系统无法正常安装</p>
</div>

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/Linux多节点环境打造/step16.png" style="zoom:67%;" />

<p>最后点击完成，完成虚拟机配置</p>
<h1 id="安装操作系统"><a href="#安装操作系统" class="headerlink" title="安装操作系统"></a>安装操作系统</h1><h2 id="开启此虚拟机"><a href="#开启此虚拟机" class="headerlink" title="开启此虚拟机"></a>开启此虚拟机</h2><blockquote>
<p>开启虚拟机后会出现以下界面:</p>
<ul>
<li>Install CentOS Linux 8 安装CentOS 8</li>
<li>Test this media &amp; install CentOS Linux 8 测试安装文件并安装CentOS 8</li>
<li>Troubleshooting 修复故障</li>
</ul>
</blockquote>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/Linux多节点环境打造/ins1.png" alt="ins1" style="zoom:67%;" />

<p>通过键盘<kbd>↑</kbd> <kbd>↓</kbd> 方向键选择<code>Install CentOS Linux 8</code>进入安装页面</p>
<h2 id="进入语言选择界面"><a href="#进入语言选择界面" class="headerlink" title="进入语言选择界面"></a>进入语言选择界面</h2><p>选择安装过程中使用的语言，这里选择英文、键盘选择美式键盘。点击<code>Continue</code></p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/Linux多节点环境打造/ins2.png" alt="ins1" style="zoom:67%;" />

<h2 id="进入时区选择界面"><a href="#进入时区选择界面" class="headerlink" title="进入时区选择界面"></a>进入时区选择界面</h2><img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/Linux多节点环境打造/ins3.png" alt="ins1" style="zoom:67%;" />

<blockquote>
<p>时区选择 <code>Asia</code>  <code>Shanghai</code>,  选择完成后点击<code>Done</code>返回安装界面</p>
</blockquote>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/Linux多节点环境打造/ins4.png" alt="ins1" style="zoom:67%;" />

<h2 id="进入软件选择界面"><a href="#进入软件选择界面" class="headerlink" title="进入软件选择界面"></a>进入软件选择界面</h2><img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/Linux多节点环境打造/ins5.png" alt="ins1" style="zoom:67%;" />

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/Linux多节点环境打造/ins6.png" alt="ins1" style="zoom:67%;" />

<div class="note info flat"><p>可根据自己需求选择所需功能，一般选择<code>Minimal install</code>(最小安装)，后期可根据自己需要进行安装软件，所选软件包越多，安装过程越慢</p>
</div>

<h2 id="选择安装位置"><a href="#选择安装位置" class="headerlink" title="选择安装位置"></a>选择安装位置</h2><img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/Linux多节点环境打造/ins7.png" alt="ins1" style="zoom:67%;" />

<blockquote>
<p>选择<code>Automatic</code>,自动进行分区</p>
</blockquote>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/Linux多节点环境打造/ins8.png" alt="ins1" style="zoom:67%;" />

<h2 id="返回主界面，点击Begin-Installation-开始安装"><a href="#返回主界面，点击Begin-Installation-开始安装" class="headerlink" title="返回主界面，点击Begin Installation,开始安装"></a>返回主界面，点击<code>Begin Installation</code>,开始安装</h2><img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/Linux多节点环境打造/ins9.png" alt="ins1" style="zoom:67%;" />

<blockquote>
<p>安装过程中可以进行Root用户的密码设置，用户创建可以稍后在进行设置</p>
</blockquote>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/Linux多节点环境打造/ins10.png" alt="ins1" style="zoom:67%;" />

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/Linux多节点环境打造/ins11.png" alt="ins1" style="zoom:67%;" />

<h2 id="安装完成后点击Reboot-重启系统"><a href="#安装完成后点击Reboot-重启系统" class="headerlink" title="安装完成后点击Reboot,重启系统"></a>安装完成后点击<code>Reboot</code>,重启系统</h2><img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/Linux多节点环境打造/ins12.png" alt="ins1" style="zoom:67%;" />

<h2 id="输入正确的用户名及密码进入系统"><a href="#输入正确的用户名及密码进入系统" class="headerlink" title="输入正确的用户名及密码进入系统"></a>输入正确的用户名及密码进入系统</h2><img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/Linux多节点环境打造/ins13.png" alt="ins1"  />

<h1 id="多节点配置"><a href="#多节点配置" class="headerlink" title="多节点配置"></a>多节点配置</h1><h2 id="联网设置"><a href="#联网设置" class="headerlink" title="联网设置"></a>联网设置</h2><div class="note danger flat"><p>系统安装完成后，无法联网，需要进行配置</p>
</div>

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/Linux多节点环境打造/ins14.png" alt="ins1"  />

<div class="note danger flat"><p>输入<code>ifconfig</code>命令查看当前系统的IP地址，显示该命令不存在，可通过 <code>ip addr</code>命令进行查询</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># dhclient //动态分配一个IP地址</span></span><br><span class="line">[root@localhost ~]<span class="comment"># ip addr</span></span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: ens32: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000</span><br><span class="line">    link/ether 00:0c:29:21:60:cf brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 192.168.229.131/24 brd 192.168.229.255 scope global noprefixroute ens32</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::b3fe:4e78:1f73:8d81/64 scope link noprefixroute </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure>
</div>

<div class="note info flat"><p>若最小安装导致<code>ifconfig</code>命令失效的情况下，且能够连接外网情况下，可以下载net-tools，重新获取该命令，若该命令未失效可忽略该提示</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># yum install net-tools -y </span></span><br></pre></td></tr></table></figure>
</div>

<h2 id="设置固定IP"><a href="#设置固定IP" class="headerlink" title="设置固定IP"></a>设置固定IP</h2><div class="note info flat"><p>通过<code>dhclient</code>获得的是DHCP分配的动态IP，重启系统后IP地址可能会与之前不一样，不利于多设备集群和记忆</p>
</div>

<p><strong>进入“编辑”—“虚拟网络编辑器”</strong></p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/Linux多节点环境打造/new1.png" alt="new1" style="zoom:67%;" />

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/Linux多节点环境打造/new2.png" alt="ins1" />

<p><strong>进入网卡编辑状态</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># vi /etc/sysconfig/network-scripts/ifcfg-ens32 </span></span><br><span class="line">TYPE=Ethernet</span><br><span class="line">PROXY_METHOD=none</span><br><span class="line">BROWSER_ONLY=no</span><br><span class="line">BOOTPROTO=dhcp</span><br><span class="line">DEFROUTE=yes</span><br><span class="line">IPV4_FAILURE_FATAL=no</span><br><span class="line">IPV6INIT=yes</span><br><span class="line">IPV6_AUTOCONF=yes</span><br><span class="line">IPV6_DEFROUTE=yes</span><br><span class="line">IPV6_FAILURE_FATAL=no</span><br><span class="line">IPV6_ADDR_GEN_MODE=stable-privacy</span><br><span class="line">NAME=ens32</span><br><span class="line">UUID=7f2efaef-c748-4180-98e9-384af604b6fc</span><br><span class="line">DEVICE=ens32</span><br><span class="line">ONBOOT=no</span><br></pre></td></tr></table></figure>

<p>按<kbd>i</kbd>进入文本编辑状态</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">修改</span><br><span class="line">BOOTPROTO=static</span><br><span class="line">ONBOOT=yes</span><br><span class="line">添加（根据虚拟网络编辑器NAT设置进行相应修改）</span><br><span class="line">IPADDR=192.168.229.131 //该IP为dhclient获取的IP地址</span><br><span class="line">NETMASK=255.255.255.0</span><br><span class="line">GATEWAY=192.168.229.2 </span><br><span class="line">DNS=119.29.29.29    //腾讯的DNS地址</span><br></pre></td></tr></table></figure>

<p>按<kbd>ESC</kbd>退出文本编辑状态，输入<code>：wq</code>保存退出</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># nmcli c reload  //CentOS 8 重启网卡</span></span><br><span class="line">[root@localhost ~]<span class="comment"># systemctl restart network-service  //CentOS 7 重启网卡</span></span><br></pre></td></tr></table></figure>



<h2 id="检查是否配置成功"><a href="#检查是否配置成功" class="headerlink" title="检查是否配置成功"></a>检查是否配置成功</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># ping baidu.com   //虚拟机PING通外网</span></span><br><span class="line">PING baidu.com (220.181.38.148) 56(84) bytes of data.</span><br><span class="line">64 bytes from 220.181.38.148 (220.181.38.148): icmp_seq=1 ttl=52 time=36.4 ms</span><br><span class="line">64 bytes from 220.181.38.148 (220.181.38.148): icmp_seq=2 ttl=52 time=35.9 ms</span><br></pre></td></tr></table></figure>

<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line"><span class="function">C:\<span class="title">Users</span>\<span class="title">Labcz</span>&gt;<span class="title">ping</span> 192.168.0.106  //宿主机<span class="title">PING</span>通虚拟机</span></span><br><span class="line"><span class="function">正在 <span class="title">Ping</span> 192.168.0.106 具有 32 字节的数据:</span></span><br><span class="line"><span class="function">来自 192.168.0.106 的回复: 字节=32 时间&lt;1<span class="title">ms</span> <span class="title">TTL</span>=64</span></span><br><span class="line"><span class="function">来自 192.168.0.106 的回复: 字节=32 时间&lt;1<span class="title">ms</span> <span class="title">TTL</span>=64</span></span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># ping 192.168.229.131 //虚拟机PING通宿主机</span></span><br><span class="line">PING 192.168.229.131 (192.168.229.131) 56(84) bytes of data.</span><br></pre></td></tr></table></figure>

<div class="note danger flat"><p>若虚拟机无法PING通宿主机，需要对宿主机进行防火墙设置</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/Linux多节点环境打造/ins16.png" alt="ins1" style="zoom:67%;" />

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/Linux多节点环境打造/ins17.png" alt="ins1" style="zoom:67%;" />

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/Linux多节点环境打造/ins18.png" alt="ins1" style="zoom:67%;" />

<p>运行入站连接</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/Linux多节点环境打造/ins19.png" alt="ins1" style="zoom:67%;" />

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/Linux多节点环境打造/ins20.png" alt="ins1" style="zoom:67%;" />

<p>将否改为是（右侧启用规则）</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># ping 192.168.0.103 //虚拟机成功PING通宿主机</span></span><br><span class="line">PING 192.168.0.103 (192.168.0.103) 56(84) bytes of data.</span><br><span class="line">64 bytes from 192.168.0.103: icmp_seq=1 ttl=128 time=0.208 ms</span><br><span class="line">64 bytes from 192.168.0.103: icmp_seq=2 ttl=128 time=0.224 ms</span><br><span class="line">64 bytes from 192.168.0.103: icmp_seq=3 ttl=128 time=0.268 ms</span><br></pre></td></tr></table></figure>
</div>

<h2 id="虚拟机客克隆-创建"><a href="#虚拟机客克隆-创建" class="headerlink" title="虚拟机客克隆/创建"></a>虚拟机客克隆/创建</h2><p>可通过虚拟机克隆快速完成多节点虚拟机的配置，若希望打造不同系统虚拟机节点，可以重复上述流程进行新建虚拟机</p>
<p>通过右击需要克隆的虚拟机，“管理”—“克隆”</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/Linux多节点环境打造/step17.png" alt="ins1" style="zoom:67%;" />

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/Linux多节点环境打造/step18.png" alt="ins1" style="zoom:67%;" />

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/Linux多节点环境打造/step19.png" alt="ins1" style="zoom:67%;" />

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/Linux多节点环境打造/step20.png" alt="ins1" style="zoom:67%;" />

<h2 id="多节点设置固定IP地址"><a href="#多节点设置固定IP地址" class="headerlink" title="多节点设置固定IP地址"></a>多节点设置固定IP地址</h2><p>进入虚拟机后通过<code>dhclient</code>命令获取系统分配地址后，修改<code>/etc/sysconfig/network-scripts/ifcfg-ens32 </code>网卡的IP地址</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# dhclient //动态分配一个IP地址</span><br><span class="line"></span><br><span class="line">[root@localhost ~]# ifconfig</span><br><span class="line">ens32: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span><br><span class="line">        inet 192.168.229.132  netmask 255.255.255.0  broadcast 192.168.229.255</span><br><span class="line">        inet6 fe80::3400:5b95:b6d1:cc3d  prefixlen 64  scopeid 0x20&lt;link&gt;</span><br><span class="line">        inet6 fe80::b3fe:4e78:1f73:8d81  prefixlen 64  scopeid 0x20&lt;link&gt;</span><br><span class="line">        ether 00:0c:29:67:3e:41  txqueuelen 1000  (Ethernet)</span><br><span class="line">        RX packets 69  bytes 8693 (8.4 KiB)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 78  bytes 10266 (10.0 KiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line"></span><br><span class="line">lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt;  mtu 65536</span><br><span class="line">        inet 127.0.0.1  netmask 255.0.0.0</span><br><span class="line">        inet6 ::1  prefixlen 128  scopeid 0x10&lt;host&gt;</span><br><span class="line">        loop  txqueuelen 1000  (Local Loopback)</span><br><span class="line">        RX packets 0  bytes 0 (0.0 B)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 0  bytes 0 (0.0 B)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line">        </span><br><span class="line">[root@localhost ~]# vi /etc/sysconfig/network-scripts/ifcfg-ens32</span><br><span class="line">TYPE=Ethernet</span><br><span class="line">PROXY_METHOD=none</span><br><span class="line">BROWSER_ONLY=no</span><br><span class="line">BOOTPROTO=static</span><br><span class="line">DEFROUTE=yes</span><br><span class="line">IPV4_FAILURE_FATAL=no</span><br><span class="line">IPV6INIT=yes</span><br><span class="line">IPV6_AUTOCONF=yes</span><br><span class="line">IPV6_DEFROUTE=yes</span><br><span class="line">IPV6_FAILURE_FATAL=no</span><br><span class="line">IPV6_ADDR_GEN_MODE=stable-privacy</span><br><span class="line">NAME=ens32</span><br><span class="line">UUID=7f2efaef-c748-4180-98e9-384af604b6fc</span><br><span class="line">DEVICE=ens32</span><br><span class="line">ONBOOT=yes</span><br><span class="line">IPADDR=192.168.229.132 //修改为分配后的IP地址</span><br><span class="line">NETMASK=255.255.255.0</span><br><span class="line">GATEWAY=192.168.229.2</span><br><span class="line">DNS1=119.29.29.29        </span><br></pre></td></tr></table></figure>

<p>网络连接测试</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# ping www.baidu.com  //外网PING测试</span><br><span class="line">PING www.a.shifen.com (14.215.177.38) 56(84) bytes of data.</span><br><span class="line">64 bytes from 14.215.177.38 (14.215.177.38): icmp_seq=1 ttl=128 time=25.9 ms</span><br><span class="line">64 bytes from 14.215.177.38 (14.215.177.38): icmp_seq=2 ttl=128 time=24.9 ms</span><br><span class="line"></span><br><span class="line">[root@localhost ~]# ping 192.168.229.131  //另一部虚拟机PING测试</span><br><span class="line">PING 192.168.229.131 (192.168.229.131) 56(84) bytes of data.</span><br><span class="line">64 bytes from 192.168.229.131: icmp_seq=1 ttl=64 time=1.16 ms</span><br><span class="line">64 bytes from 192.168.229.131: icmp_seq=2 ttl=64 time=0.362 ms</span><br></pre></td></tr></table></figure>













]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux软件安装管理</title>
    <url>/ckhnafzrt0007etfpeudkb8b9.html</url>
    <content><![CDATA[<h2 id="软件包的分类"><a href="#软件包的分类" class="headerlink" title="软件包的分类"></a>软件包的分类</h2><ul>
<li><strong>源码包（.tar.gz)</strong><ul>
<li>源码包的<strong>优点</strong><ul>
<li>1）开源，如果有足够的能力，可以修改源代码</li>
<li>2）可以自由选择所需的功能</li>
<li>3）软件是编译安装，所有更加适合自己的系统，更加稳定也效率更高</li>
<li>4）卸载方便</li>
</ul>
</li>
<li>源码包的<strong>缺点</strong><ul>
<li>1）安装过程步骤较多，尤其安装较大的软件集合是（如LAMP环境搭建），容易出现拼写错误</li>
<li>2）编译过程时间较长，安装比二进制安装时间长</li>
<li>3）因为是编译安装，安装过程中一旦报错新手很难解决</li>
</ul>
</li>
</ul>
</li>
<li><strong>二进制包（RPM包，系统默认包）</strong><ul>
<li>RPM包的<strong>优点</strong><ul>
<li>1）包管理系统简单，只通过几个命令就可以实现包的安装、升级、查询和卸载</li>
<li>2）安装速度比源码包安装快的多</li>
</ul>
</li>
<li>RPM包的<strong>缺点</strong><ul>
<li>1）经过编译，不再可以看到源代码</li>
<li>2）功能选择不如源码包灵活</li>
<li>3）依赖性</li>
</ul>
</li>
</ul>
</li>
<li><strong>脚本安装包</strong>（所谓的脚本安装包，就是把复杂的软件包安装过程写成了程序脚本，初学者可以执行程序脚本实现一键安装，但实际安装的还是源码包和二进制包）<ul>
<li><strong>优点</strong>：安装简单快捷</li>
<li><strong>缺点</strong>：完全丧失自定义性</li>
</ul>
</li>
</ul>
<h2 id="RPM包介绍"><a href="#RPM包介绍" class="headerlink" title="RPM包介绍"></a>RPM包介绍</h2><ul>
<li>RPM包命名规则（httpd-2.2.15-15.el6.centos.1.i686.rpm）<ul>
<li>httpd   软件包名</li>
<li>2.2.15  软件版本</li>
<li>15   软件发布的次数</li>
<li>-el6.centos  适合Linux平台</li>
<li>i686  适合的硬件平台</li>
<li>rpm  包拓展名</li>
</ul>
</li>
<li><strong>RPM包依赖性</strong><ul>
<li>树形依赖：a→b→c</li>
<li>环形依赖：a→b→c→a</li>
<li>模块依赖：模块依赖，查询网站：<a href="http://www.rpmfind.net/">www.rpmfind.net</a></li>
</ul>
</li>
<li><strong>包全名</strong>和<strong>包名</strong><ul>
<li><strong>包全名</strong>：操作的包是没有安装的软件包时，使用包全面，而且要注意路径</li>
<li><strong>包名</strong>：操作以及安装的软件包时，使用包命是搜索/var/lib/rpm/中的数据库</li>
</ul>
</li>
</ul>
<p>RPM包一般在光盘镜像中，可以进入/mnt/cdrom/AppSteam/Packages（不同Linux版本Pacakges目录存放位置不同）</p>
<p>查看光盘镜像中RPM包需要挂载光盘，可查看mount命令</p>
<h2 id="RPM包安装"><a href="#RPM包安装" class="headerlink" title="RPM包安装"></a>RPM包安装</h2><blockquote>
<p>格式：<code>rpm –ivh 包全名</code></p>
</blockquote>
<ul>
<li>选项<ul>
<li>-i（install）安装</li>
<li>-v（verbose）显示详细信息</li>
<li>-h（hash）显示进度</li>
<li>–nodeps 不检测依赖性</li>
</ul>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@localhost Packages]$rpm -ivh httpd-2.4.37-11.module_el8.0.0+172+85fc1f40.x86_64.rpm </span><br><span class="line">警告：httpd-2.4.37-11.module_el8.0.0+172+85fc1f40.x86_64.rpm: 头V3 RSA/SHA256 Signature, 密钥 ID 8483c65d: NOKEY</span><br><span class="line">错误：依赖检测失败：</span><br><span class="line">    httpd-filesystem 被 httpd-2.4.37-11.module_el8.0.0+172+85fc1f40.x86_64 需要</span><br><span class="line">    httpd-filesystem = 2.4.37-11.module_el8.0.0+172+85fc1f40 被 httpd-2.4.37-11.module_el8.0.0+172+85fc1f40.x86_64 需要</span><br><span class="line">    httpd-tools = 2.4.37-11.module_el8.0.0+172+85fc1f40 被 httpd-2.4.37-11.module_el8.0.0+172+85fc1f40.x86_64 需要</span><br><span class="line">    libapr-1.so.0()(64bit) 被 httpd-2.4.37-11.module_el8.0.0+172+85fc1f40.x86_64 需要</span><br><span class="line">    libaprutil-1.so.0()(64bit) 被 httpd-2.4.37-11.module_el8.0.0+172+85fc1f40.x86_64 需要</span><br><span class="line">    mod_http2 被 httpd-2.4.37-11.module_el8.0.0+172+85fc1f40.x86_64 需要</span><br><span class="line">    system-logos-httpd 被 httpd-2.4.37-11.module_el8.0.0+172+85fc1f40.x86_64 需要</span><br></pre></td></tr></table></figure>

<p><strong><em>注：安装RPM包会报依赖性错误</em></strong></p>
<p><strong>RPM包默认安装位置</strong></p>
<table>
<thead>
<tr>
<th>安装目录</th>
<th>对应文件</th>
</tr>
</thead>
<tbody><tr>
<td>/etc</td>
<td>配置文件安装目录</td>
</tr>
<tr>
<td>/usr/bin</td>
<td>可执行的目录安装目录</td>
</tr>
<tr>
<td>/usr/lib</td>
<td>程序所使用的函数库保存位置</td>
</tr>
<tr>
<td>/usr/share/doc</td>
<td>基本的软件使用手册保存位置</td>
</tr>
<tr>
<td>/usr/share/man</td>
<td>帮助文件保存位置</td>
</tr>
</tbody></table>
<h2 id="查询RPM包详细信息"><a href="#查询RPM包详细信息" class="headerlink" title="查询RPM包详细信息"></a>查询RPM包详细信息</h2><blockquote>
<p>格式：<code>rpm –qi 包名</code></p>
</blockquote>
<ul>
<li><p>选项：</p>
<ul>
<li><p>-q（query）  查询信息</p>
</li>
<li><p>-i（information）查询软件信息</p>
</li>
<li><p>-p（package）查询**<em>未安装包**</em>信息</p>
</li>
<li><p>-a（all）所有</p>
</li>
<li><p>-f（file）查询系统文件属于哪个软件包</p>
</li>
<li><p>-R（requires）查询软件包的依赖性</p>
</li>
</ul>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">rpm -q 包名 #查询是否安装</span><br><span class="line">rpm -qa #查询所有已经安装的RPM包</span><br><span class="line">rpm -qi httpd  #查看已安装包的信息</span><br><span class="line">rpm -qip zenity-3.28.1-1.el8.x86_64.rpm    #查看未安装包的信息</span><br><span class="line">rpm -ql httpd  #查看RPM包中内容</span><br><span class="line">rpm -qlp zenity-3.28.1-1.el8.x86_64.rpm  #查看未安装包中内容</span><br><span class="line">rpm -qf /usr/share/zenity/zenity.ui #查询系统文件属于哪个RPM包</span><br><span class="line">rpm -qR 包名  #查询软件包的依赖性</span><br></pre></td></tr></table></figure>

<h2 id="RPM包校验"><a href="#RPM包校验" class="headerlink" title="RPM包校验"></a>RPM包校验</h2><blockquote>
<p>格式：<code>rpm –V 已安装的包名</code></p>
</blockquote>
<p>选项：-V（vertify）校验指定的RPM包中的文件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@localhost Packages]# rpm -V gcc  #一般情况下输入该命令不会有提示</span><br><span class="line">[root@localhost Packages]# </span><br></pre></td></tr></table></figure>

<p>但是如果修改了配置文件，将会提示错误</p>
<ul>
<li><p>找到gcc的配置文件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">rpm -ql gcc</span><br></pre></td></tr></table></figure>
</li>
<li><p>随意进入一个配置文件，进行修改</p>
</li>
<li><p>再次执行RPM包校验将会提示错误</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@localhost Packages]# rpm -V gcc</span><br><span class="line">S.5....T.    &#x2F;usr&#x2F;bin&#x2F;c89</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>验证内容中8个信息的具体内容如下：</strong><ul>
<li>S  文件大小是否改变</li>
<li>M  文件的类型或文件的权限（rwx）是否被改变  </li>
<li>5  文件MD5校验和恶是否改变（可以看成文件内容是否改变）</li>
<li>D  设备的主从代码是否改变</li>
<li>L  文件路径是否改变</li>
<li>U  文件的属主（所有者）是否改变</li>
<li>G  文件的属组是否改变</li>
<li>T  文件的修改时间是否改变</li>
</ul>
</li>
<li><strong>文件类型</strong><ul>
<li>c  配置文件（config file）</li>
<li>d  普通文档（documentation）</li>
<li>g  “鬼”文件（ghost file），很少见，就是该文件不应该被这个RPM包包含</li>
<li>L  授权文件（license file）</li>
<li>r  描述文件（read me）</li>
</ul>
</li>
</ul>
<h2 id="RPM包中文件提取"><a href="#RPM包中文件提取" class="headerlink" title="RPM包中文件提取"></a>RPM包中文件提取</h2><blockquote>
<p>格式：<code>rpm2cpio 包全名 | cpio –idv .文件绝对路径</code></p>
</blockquote>
<p>作用：若误删了某个命令，可以进行恢复</p>
<p><strong>rpm2cpio</strong>:将rpm包转换为cpio格式的命令</p>
<p><strong>cpio</strong>:一个标准工具，它用于创建软件档案文档和从档案文件中提取文件</p>
<ul>
<li>选项<ul>
<li>-i  copy-in模式，还原</li>
<li>-d  还原时自动新建目录</li>
<li>-v  显示还原过程</li>
</ul>
</li>
</ul>
<p>1）找到/bin/ls对应的RPM包</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@localhost Packages]# rpm -qf &#x2F;bin&#x2F;ls</span><br><span class="line">coreutils-8.30-6.el8.x86_64</span><br></pre></td></tr></table></figure>

<p>2）误删除ls目录</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@localhost tmp]# mv /bin/ls /tmp/</span><br><span class="line">[root@localhost tmp]# ls</span><br><span class="line">-bash: /usr/bin/ls: 没有那个文件或目录</span><br></pre></td></tr></table></figure>

<p>3）从RPM包提取出对应文件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">rpm2cpio /mnt/cdrom/BaseOS/Packages/coreutils-8.30-6.el8.x86_64.rpm |cpio -idv ./bin/ls</span><br></pre></td></tr></table></figure>

<h2 id="RPM包升级"><a href="#RPM包升级" class="headerlink" title="RPM包升级"></a>RPM包升级</h2><blockquote>
<p>格式：<code>rpm –Uvh 包全名</code></p>
</blockquote>
<p>选项：-U（upgrade）升级</p>
<p><strong>若已安装则升级，若未安装则安装</strong></p>
<h2 id="RPM包卸载"><a href="#RPM包卸载" class="headerlink" title="RPM包卸载"></a>RPM包卸载</h2><blockquote>
<p>格式：<code>rpm –evh 包全名</code></p>
</blockquote>
<ul>
<li>选项<ul>
<li>-e（erase）卸载</li>
<li>–nodeps 不检测依赖性</li>
</ul>
</li>
</ul>
<h2 id="yum在线安装"><a href="#yum在线安装" class="headerlink" title="yum在线安装"></a>yum在线安装</h2><ul>
<li>优点：将所有软件包放到官方服务器上，当进行yum在线安装时，可以自动解决依赖性问题。</li>
</ul>
<p><strong>注意：RedHat的yum在线安装需要收费</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@labcz ~]# cd /etc/yum.repos.d/  #yum配置目录</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@labcz yum.repos.d]# vim CentOS-Base.repo </span><br><span class="line"></span><br><span class="line">[base]</span><br><span class="line">name=CentOS-$releasever</span><br><span class="line">enabled=1</span><br><span class="line">failovermethod=priority</span><br><span class="line">baseurl=http://mirrors.cloud.aliyuncs.com/centos/$releasever/os/$basearch/</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=http://mirrors.cloud.aliyuncs.com/centos/RPM-GPG-KEY-CentOS-7</span><br><span class="line"></span><br><span class="line">[updates]</span><br><span class="line">name=CentOS-$releasever</span><br><span class="line">enabled=1</span><br><span class="line">failovermethod=priority</span><br><span class="line">baseurl=http://mirrors.cloud.aliyuncs.com/centos/$releasever/updates/$basearch/</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=http://mirrors.cloud.aliyuncs.com/centos/RPM-GPG-KEY-CentOS-7</span><br><span class="line"></span><br><span class="line">[extras]</span><br><span class="line">name=CentOS-$releasever</span><br><span class="line">enabled=1</span><br><span class="line">failovermethod=priority</span><br><span class="line">baseurl=http://mirrors.cloud.aliyuncs.com/centos/$releasever/extras/$basearch/</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=http://mirrors.cloud.aliyuncs.com/centos/RPM-GPG-KEY-CentOS-7</span><br></pre></td></tr></table></figure>

<p>默认只有CentO-Base.repo生效，其他的yum源（.repo)不生效</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">gpgkey&#x3D;file:&#x2F;&#x2F;&#x2F;etc&#x2F;pki&#x2F;rpm-gpg&#x2F;RPM-GPG-KEY-centosofficial</span><br></pre></td></tr></table></figure>

<p><code>file://</code>:表示文件的一个协议</p>
<p>/：根目录</p>
<ul>
<li>各属性解释<ul>
<li>[base]      容器名称，一定要放在[ ]中</li>
<li>name       容器说明，可以自己随便填写</li>
<li>mirrorlist   镜像站点，这个可以注释掉</li>
<li>baseurl     我们的yum源服务器的地址，可自行修改</li>
<li>enabled    此容器是否生效，如果不写或写成enable=1都是              生效，写成enable=0就是不生效</li>
<li>gpgcheck   如果是1是指RPM的数字证书生效，如果是0则不生效</li>
<li>pgpkey     数字证数的公钥文件保存位置，不用修改</li>
</ul>
</li>
</ul>
<h2 id="搭建光盘yum源"><a href="#搭建光盘yum源" class="headerlink" title="搭建光盘yum源"></a>搭建光盘yum源</h2><ul>
<li><p>1）挂载光盘</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir /mnt/cdrom  #建立挂载点</span><br><span class="line">mount  /dev/sr0  /mnt/cdrom #挂载光盘</span><br></pre></td></tr></table></figure>
</li>
<li><p>2）使网络yum源失效</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /etc/yum.repos.d/  #进入yum源目录</span><br><span class="line">mv CentOS-Base.repo  CentOS-Base.repo.bak</span><br><span class="line"><span class="meta">#</span><span class="bash">修改yum源文件后缀名，使其失效</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>3）修改CentOS-Media.repo文件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">base=file:///mnt/cdrom #改为自己的光盘挂载点</span><br><span class="line">enabled=1  #改为1使其有效</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h2 id="常用yum命令"><a href="#常用yum命令" class="headerlink" title="常用yum命令"></a>常用yum命令</h2><ul>
<li><p><strong>查询</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum list #查询所有可用的软件包列表</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum search 关键字 #搜索服务器上所有和关键字相关的包</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>安装</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum –y install 包名 #-y 自动应答，install 安装</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>升级</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum –y update 包名  #-y 自动应答，update 升级</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>卸载</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum –y remove 包名  #-y 自动应答，remove 卸载</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>yum软件组管理</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@labcz yum.repos.d]# yum grouplist #列出所有可用的软件组列表</span><br><span class="line">Loaded plugins: fastestmirror</span><br><span class="line">There is no installed groups file.</span><br><span class="line">Maybe run: yum groups mark convert (see man yum)</span><br><span class="line">Loading mirror speeds from cached hostfile</span><br><span class="line">Available Environment Groups:</span><br><span class="line">   Minimal Install</span><br><span class="line">   Compute Node</span><br><span class="line">   Infrastructure Server</span><br><span class="line">   File and Print Server</span><br><span class="line">   Cinnamon Desktop</span><br><span class="line">   MATE Desktop</span><br><span class="line">   Basic Web Server</span><br><span class="line">   Virtualization Host</span><br><span class="line">   Server with GUI</span><br><span class="line">   GNOME Desktop</span><br><span class="line">   KDE Plasma Workspaces</span><br><span class="line">   Development and Creative Workstation</span><br><span class="line">Available Groups:</span><br><span class="line">   Cinnamon</span><br><span class="line">   Compatibility Libraries</span><br><span class="line">   Console Internet Tools</span><br><span class="line">   Development Tools</span><br><span class="line">   Educational Software</span><br><span class="line">   Electronic Lab</span><br><span class="line">   Fedora Packager</span><br><span class="line">   General Purpose Desktop</span><br><span class="line">   Graphical Administration Tools</span><br><span class="line">   Haskell</span><br><span class="line">   LXQt Desktop</span><br><span class="line">   Legacy UNIX Compatibility</span><br><span class="line">   MATE</span><br><span class="line">   Milkymist</span><br><span class="line">   Scientific Support</span><br><span class="line">   Security Tools</span><br><span class="line">   Smart Card Support</span><br><span class="line">   System Administration Tools</span><br><span class="line">   System Management</span><br><span class="line">   TurboGears application framework</span><br><span class="line">   Xfce</span><br><span class="line">Done</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum groupinstall 软件组名</span><br><span class="line"><span class="meta">#</span><span class="bash">安装指定软件组，组名可以由grouplist查询出来(组名需要使用英文)</span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum groupremove 软件组名  #卸载指定的软件组</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">LANG=en_US  #切换为英语查看软件组名</span><br><span class="line">LANG=zh_CN.utf8 #切换回中文</span><br><span class="line">(只是临时修改，永久修改需要修改环境变量)</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h2 id="源码包简介"><a href="#源码包简介" class="headerlink" title="源码包简介"></a>源码包简介</h2><ul>
<li><p><strong>源码包与RPM包的区别</strong></p>
<ul>
<li>安装之前的区别：概念上的区别</li>
<li>安装之后的区别：安装位置不同</li>
</ul>
</li>
<li><p><strong>安装位置不同带来的影响</strong></p>
<p>RPM包安装的服务可以使用系统服务管理命令（service）来管理，例如RPM包安装的Apache的启动方式是：</p>
<p><code>etc/rc.d/init.d/httpd start</code></p>
<p><code>service httpd start</code></p>
</li>
<li><p><strong>源码包安装位置</strong></p>
<p>安装在指定位置当中，一般是：<code>/usr/local/软件名/</code></p>
<p>源码包安装的服务不能被服务管理命令管理，因为没有安装到默认路径中，所以只能用绝对路径进行服务的管理</p>
<p>如：<code>usr/local/apache2/bin/apachectl start</code></p>
</li>
</ul>
<h2 id="源码包安装"><a href="#源码包安装" class="headerlink" title="源码包安装"></a>源码包安装</h2><ul>
<li><p>1）下载源码包</p>
</li>
<li><p>2）解压缩源码包</p>
</li>
<li><p>3）进入解压缩目录</p>
</li>
<li><p>4）<code>./configure</code> 软件配置与检查</p>
<ul>
<li>定义需要的功能选项</li>
<li>检测系统环境是否符合安装要求</li>
<li>把定义好的功能选项和检测系统环境的信息都写入Makefile文件，用于后续的编辑</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">./configure --prefix=/usr/local/apache #自定义安装目录</span><br></pre></td></tr></table></figure>
</li>
<li><p>5）<code>make</code>编译（若编译错误，使用<code>make clean</code>)</p>
</li>
<li><p>6）<code>make install</code>编译安装</p>
</li>
</ul>
<h2 id="源码包卸载"><a href="#源码包卸载" class="headerlink" title="源码包卸载"></a>源码包卸载</h2><p>不需要卸载命令，直接删除安装目录即可，不会遗留任何垃圾文件</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop安装</title>
    <url>/ckhnafzsj000oetfpb4ks37p4.html</url>
    <content><![CDATA[<h1 id="安装前准备"><a href="#安装前准备" class="headerlink" title="安装前准备"></a>安装前准备</h1><h2 id="虚拟机联网"><a href="#虚拟机联网" class="headerlink" title="虚拟机联网"></a>虚拟机联网</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# ping www.baidu.com  //PING外网测试</span><br><span class="line">PING www.a.shifen.com (14.215.177.38) 56(84) bytes of data.</span><br><span class="line">64 bytes from 14.215.177.38 (14.215.177.38): icmp_seq=1 ttl=128 time=25.4 ms</span><br></pre></td></tr></table></figure>

<h2 id="关闭防火墙"><a href="#关闭防火墙" class="headerlink" title="关闭防火墙"></a>关闭防火墙</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# systemctl stop iptables.service  //关闭防火墙</span><br><span class="line">[root@localhost ~]# systemctl status iptables.service  //检查防火墙状态</span><br><span class="line">● iptables.service - IPv4 firewall with iptables</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/iptables.service; disabled; vendor preset&gt;</span><br><span class="line">   Active: inactive (dead)</span><br><span class="line">lines 1-3/3 (END)...skipping...</span><br><span class="line">● iptables.service - IPv4 firewall with iptables</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/iptables.service; disabled; vendor preset: disabled)</span><br><span class="line">   Active: inactive (dead)</span><br></pre></td></tr></table></figure>

<div class="note warning flat"><p>若<strong>未安装防火墙</strong>会出现以下提示</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# systemctl stop iptables.service</span><br><span class="line">Failed to stop iptables.service: Unit iptables.service not loaded.</span><br><span class="line"></span><br><span class="line">[root@localhost ~]# yum install -y iptables-services //在线安装防火墙</span><br></pre></td></tr></table></figure>
</div>

<h2 id="关闭SELINUX"><a href="#关闭SELINUX" class="headerlink" title="关闭SELINUX"></a>关闭SELINUX</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# vi /etc/selinux/config  //进入SELINUX配置文件</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> This file controls the state of SELinux on the system.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> SELINUX= can take one of these three values:</span></span><br><span class="line"><span class="meta">#</span><span class="bash">     enforcing - SELinux security policy is enforced.</span></span><br><span class="line"><span class="meta">#</span><span class="bash">     permissive - SELinux prints warnings instead of enforcing.</span></span><br><span class="line"><span class="meta">#</span><span class="bash">     disabled - No SELinux policy is loaded.</span></span><br><span class="line">SELINUX=enforcing</span><br><span class="line"><span class="meta">#</span><span class="bash"> SELINUXTYPE= can take one of these three values:</span></span><br><span class="line"><span class="meta">#</span><span class="bash">     targeted - Targeted processes are protected,</span></span><br><span class="line"><span class="meta">#</span><span class="bash">     minimum - Modification of targeted policy. Only selected processes are protected.</span></span><br><span class="line"><span class="meta">#</span><span class="bash">     mls - Multi Level Security protection.</span></span><br><span class="line">SELINUXTYPE=targeted</span><br></pre></td></tr></table></figure>

<p>将<code>SELINUX=enforcing</code>改为<code>SELINUX=disabled</code></p>
<p>系统重启后，再次查看SELINUX状态</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# getenforce  //检查SELINUX状态</span><br><span class="line">Disabled</span><br></pre></td></tr></table></figure>

<h2 id="安装JDK"><a href="#安装JDK" class="headerlink" title="安装JDK"></a>安装JDK</h2><p>JDK下载：<a href="https://www.oracle.com/java/technologies/javase/javase-jdk8-downloads.html">https://www.oracle.com/java/technologies/javase/javase-jdk8-downloads.html</a></p>
<p>新建一个目录</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir /usr/local/java</span><br></pre></td></tr></table></figure>

<p>将JDK解压到/usr/java目录下</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /home/installation/</span><br><span class="line">tar -zxvf jdk-13.0.2_linux-x64_bin.tar.gz -C /usr/local/java/</span><br></pre></td></tr></table></figure>

<p>配置环境变量</p>
<ul>
<li><code>vi /etc/profile</code>  打开/etc/profile文件</li>
<li>添加以下内容</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">set</span> java environment</span></span><br><span class="line">export JAVA_HOME=/usr/local/java</span><br><span class="line">export PATH=$JAVA_HOME/bin:$PATH</span><br></pre></td></tr></table></figure>

<ul>
<li>刷新 <code>source /etc/profile</code>执行修改后的配置文件</li>
<li>查看是否配置成功</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@localhost java]# java -version</span><br><span class="line">java version &quot;13.0.2&quot; 2020-01-14</span><br><span class="line">Java(TM) SE Runtime Environment (build 13.0.2+8)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 13.0.2+8, mixed mode, sharing)</span><br></pre></td></tr></table></figure>

<h2 id="配置主机名"><a href="#配置主机名" class="headerlink" title="配置主机名"></a>配置主机名</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@localhost /]# hostnamectl set-hostname hadoop01  //修改主机名字为hadoop01</span><br><span class="line">[root@localhost /]# hostname  //查看主机名</span><br><span class="line">hadoop01</span><br><span class="line">[root@localhost /]# reboot  //重新启动</span><br><span class="line"></span><br><span class="line">WARNING! The remote SSH server rejected X11 forwarding request.</span><br><span class="line">Last login: Thu Sep 17 22:09:43 2020</span><br><span class="line">[root@hadoop01 ~]#       //重启后修改成功</span><br></pre></td></tr></table></figure>

<h2 id="添加主机映射"><a href="#添加主机映射" class="headerlink" title="添加主机映射"></a>添加主机映射</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hadoop01 ~]# vim /etc/hosts</span><br><span class="line"></span><br><span class="line">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line">192.168.229.131 hadoop01</span><br><span class="line">192.168.229.132 hadoop02</span><br><span class="line">192.168.229.133 hadoop03</span><br></pre></td></tr></table></figure>

<h2 id="新建用户并赋予root权限"><a href="#新建用户并赋予root权限" class="headerlink" title="新建用户并赋予root权限"></a>新建用户并赋予root权限</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hadoop02 ~]# useradd -m liujiazhao  //新建用户</span><br><span class="line">[root@hadoop02 ~]# passwd liujiazhao        //设置密码</span><br><span class="line">Changing password for user liujiazhao.</span><br><span class="line">New password: </span><br><span class="line">BAD PASSWORD: The password is shorter than 8 characters</span><br><span class="line">Retype new password: </span><br><span class="line">passwd: all authentication tokens updated successfully.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@hadoop01 /]# vim /etc/sudoers        //编辑用户配置文件</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># Next comes the main part: which users can run what software on </span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># which machines (the sudoers file can be shared between multiple</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># systems).</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># Syntax:</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#      user    MACHINE=COMMANDS</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># The COMMANDS section may have other options added to it.</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># Allow root to run any commands anywhere </span></span></span><br><span class="line">root    ALL=(ALL)       ALL</span><br><span class="line">liujiazhao ALL=(ALL)   ALL   //新增加内容</span><br></pre></td></tr></table></figure>

<h2 id="设置免密登录"><a href="#设置免密登录" class="headerlink" title="设置免密登录"></a>设置免密登录</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hadoop01 /]# su liujiazhao //切换到普通用户</span><br><span class="line"></span><br><span class="line">[liujiazhao@hadoop01 /]$ ssh-keygen  //生成密钥</span><br><span class="line">Generating public/private rsa key pair.</span><br><span class="line">Enter file in which to save the key (/home/liujiazhao/.ssh/id_rsa):   //回车</span><br><span class="line">Created directory &#x27;/home/liujiazhao/.ssh&#x27;.</span><br><span class="line">Enter passphrase (empty for no passphrase):             //回车</span><br><span class="line">Enter same passphrase again:             //回车</span><br><span class="line">Your identification has been saved in /home/liujiazhao/.ssh/id_rsa.</span><br><span class="line">Your public key has been saved in /home/liujiazhao/.ssh/id_rsa.pub.</span><br><span class="line">The key fingerprint is:</span><br><span class="line">SHA256:fkNUlUXcIwLVFaqgJS8kdrd0gTAVRv84gorzEbiJmo8 liujiazhao@hadoop01</span><br><span class="line">The key&#x27;s randomart image is:</span><br><span class="line">+---[RSA 2048]----+</span><br><span class="line">|       o+*=oo.oB=|</span><br><span class="line">|        o..o.oo.o|</span><br><span class="line">|     o + =.o... .|</span><br><span class="line">|    o + O.+ +    |</span><br><span class="line">|   . . +S+.+ .   |</span><br><span class="line">|  . + o.... .    |</span><br><span class="line">| . = o  . o      |</span><br><span class="line">|.o  o .  . .     |</span><br><span class="line">|E..  .           |</span><br><span class="line">+----[SHA256]-----+</span><br></pre></td></tr></table></figure>

<div class="note danger flat"><p>各个节点重复以上步骤</p>
</div>

<h2 id="各个节点之间发送公钥（所有节点都需执行）"><a href="#各个节点之间发送公钥（所有节点都需执行）" class="headerlink" title="各个节点之间发送公钥（所有节点都需执行）"></a>各个节点之间发送公钥（所有节点都需执行）</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[liujiazhao@hadoop01 /]$ ssh-copy-id hadoop01</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: &quot;/home/liujiazhao/.ssh/id_rsa.pub&quot;</span><br><span class="line">The authenticity of host &#x27;hadoop01 (192.168.229.131)&#x27; can&#x27;t be established.</span><br><span class="line">ECDSA key fingerprint is SHA256:Y/EMBdRyFdk3GwKQZwY01nCVkoVF7Isze5AtXymcuMc.</span><br><span class="line">Are you sure you want to continue connecting (yes/no)? yes</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys</span><br><span class="line">liujiazhao@hadoop01&#x27;s password: </span><br><span class="line"></span><br><span class="line">Number of key(s) added: 1</span><br><span class="line"></span><br><span class="line">Now try logging into the machine, with:   &quot;ssh &#x27;hadoop01&#x27;&quot;</span><br><span class="line">and check to make sure that only the key(s) you wanted were added.</span><br><span class="line"></span><br><span class="line">[liujiazhao@hadoop01 /]$ ssh-copy-id hadoop02</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: &quot;/home/liujiazhao/.ssh/id_rsa.pub&quot;</span><br><span class="line">The authenticity of host &#x27;hadoop02 (192.168.229.132)&#x27; can&#x27;t be established.</span><br><span class="line">ECDSA key fingerprint is SHA256:Y/EMBdRyFdk3GwKQZwY01nCVkoVF7Isze5AtXymcuMc.</span><br><span class="line">Are you sure you want to continue connecting (yes/no)? yes</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys</span><br><span class="line">liujiazhao@hadoop02&#x27;s password: </span><br><span class="line"></span><br><span class="line">Number of key(s) added: 1</span><br><span class="line"></span><br><span class="line">Now try logging into the machine, with:   &quot;ssh &#x27;hadoop02&#x27;&quot;</span><br><span class="line">and check to make sure that only the key(s) you wanted were added.</span><br><span class="line"></span><br><span class="line">[liujiazhao@hadoop01 /]$ ssh-copy-id hadoop03</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: &quot;/home/liujiazhao/.ssh/id_rsa.pub&quot;</span><br><span class="line">The authenticity of host &#x27;hadoop03 (192.168.229.133)&#x27; can&#x27;t be established.</span><br><span class="line">ECDSA key fingerprint is SHA256:Y/EMBdRyFdk3GwKQZwY01nCVkoVF7Isze5AtXymcuMc.</span><br><span class="line">Are you sure you want to continue connecting (yes/no)? yes</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys</span><br><span class="line">liujiazhao@hadoop03&#x27;s password: </span><br><span class="line"></span><br><span class="line">Number of key(s) added: 1</span><br><span class="line"></span><br><span class="line">Now try logging into the machine, with:   &quot;ssh &#x27;hadoop03&#x27;&quot;</span><br><span class="line">and check to make sure that only the key(s) you wanted were added.</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="测试SSH连接"><a href="#测试SSH连接" class="headerlink" title="测试SSH连接"></a>测试SSH连接</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[liujiazhao@hadoop01 /]$ ssh hadoop01   //hadoop01 SSH连接测试</span><br><span class="line">Last login: Fri Sep 18 02:07:39 2020</span><br><span class="line">[liujiazhao@hadoop01 ~]$ exit            //关闭连接</span><br><span class="line">logout</span><br><span class="line">Connection to hadoop01 closed.</span><br><span class="line">[liujiazhao@hadoop01 /]$ ssh hadoop02    //hadoop02 SSH连接测试</span><br><span class="line">Last login: Fri Sep 18 02:11:56 2020</span><br><span class="line">[liujiazhao@hadoop02 ~]$ exit            //关闭连接</span><br><span class="line">logout</span><br><span class="line">Connection to hadoop02 closed.</span><br><span class="line">[liujiazhao@hadoop01 /]$ ssh hadoop03    //hadoop03 SSH连接测试</span><br><span class="line">Last login: Fri Sep 18 02:12:24 2020</span><br><span class="line">[liujiazhao@hadoop03 ~]$ exit            //关闭连接</span><br><span class="line">logout</span><br><span class="line">Connection to hadoop03 closed.</span><br></pre></td></tr></table></figure>

<h2 id="各节点时间同步"><a href="#各节点时间同步" class="headerlink" title="各节点时间同步"></a>各节点时间同步</h2><div class="note info flat"><p>CentOS8使用Chrony实现节点时间同步</p>
</div>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hadoop01 /]# yum -y install chrony     //安装chrony</span><br><span class="line">[root@hadoop01 /]# systemctl enable chronyd  //启用chrony</span><br><span class="line">[root@hadoop01 /]# systemctl start chronyd     //开启chrony</span><br><span class="line">[root@hadoop01 /]# vim /etc/chrony.conf        //修改chrony</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Record the rate at <span class="built_in">which</span> the system clock gains/losses time.</span></span><br><span class="line">driftfile /var/lib/chrony/drift</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Allow the system clock to be stepped <span class="keyword">in</span> the first three updates</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="keyword">if</span> its offset is larger than 1 second.</span></span><br><span class="line">makestep 1.0 3</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Enable kernel synchronization of the real-time clock (RTC).</span></span><br><span class="line">rtcsync</span><br><span class="line"><span class="meta">#</span><span class="bash"> Please consider joining the pool (http://www.pool.ntp.org/join.html).</span></span><br><span class="line">server s1a.time.edu.cn iburst   //修改一</span><br><span class="line">server ntp.aliyun.com iburst</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Record the rate at <span class="built_in">which</span> the system clock gains/losses time.</span></span><br><span class="line">driftfile /var/lib/chrony/drift</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Allow the system clock to be stepped <span class="keyword">in</span> the first three updates</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="keyword">if</span> its offset is larger than 1 second.</span></span><br><span class="line">makestep 1.0 3</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Enable kernel synchronization of the real-time clock (RTC).</span></span><br><span class="line">rtcsync</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Enable hardware timestamping on all interfaces that support it.</span></span><br><span class="line"><span class="meta">#</span><span class="bash">hwtimestamp *</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Increase the minimum number of selectable sources required to adjust</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> the system clock.</span></span><br><span class="line"><span class="meta">#</span><span class="bash">minsources 2</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Allow NTP client access from <span class="built_in">local</span> network.</span></span><br><span class="line"><span class="meta">#</span><span class="bash">allow 192.168.0.0/16</span></span><br><span class="line">allow 192.168.8.0/24    //修改二</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Serve time even <span class="keyword">if</span> not synchronized to a time <span class="built_in">source</span>.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="built_in">local</span> stratum 10</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Specify file containing keys <span class="keyword">for</span> NTP authentication.</span></span><br><span class="line">keyfile /etc/chrony.keys</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Get TAI-UTC offset and leap seconds from the system tz database.</span></span><br><span class="line">leapsectz right/UTC</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Specify directory <span class="keyword">for</span> <span class="built_in">log</span> files.</span></span><br><span class="line">logdir /var/log/chrony</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Select <span class="built_in">which</span> information is logged.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="built_in">log</span> measurements statistics tracking</span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hadoop01 /]# systemctl enable chronyd   //启用chrony</span><br><span class="line">[root@hadoop01 /]# systemctl restart chronyd  //重启chrony</span><br><span class="line">[root@hadoop01 /]# timedatectl set-ntp true   //开启网络时间同步</span><br><span class="line">[root@hadoop01 /]# timedatectl status         //查看时间同步状态</span><br><span class="line">               Local time: Thu 2020-09-17 19:50:54 CST</span><br><span class="line">           Universal time: Thu 2020-09-17 11:50:54 UTC</span><br><span class="line">                 RTC time: Thu 2020-09-17 11:50:54</span><br><span class="line">                Time zone: Asia/Shanghai (CST, +0800)</span><br><span class="line">System clock synchronized: yes</span><br><span class="line">              NTP service: active</span><br><span class="line">          RTC in local TZ: no</span><br><span class="line">[root@hadoop01 /]# date                      //查看现在的时间</span><br><span class="line">Thu Sep 17 19:52:04 CST 2020</span><br></pre></td></tr></table></figure>

<h1 id="安装Hadoop"><a href="#安装Hadoop" class="headerlink" title="安装Hadoop"></a>安装Hadoop</h1><h2 id="解压压缩包并配置文件"><a href="#解压压缩包并配置文件" class="headerlink" title="解压压缩包并配置文件"></a>解压压缩包并配置文件</h2><p>Hadoop下载：<a href="http://mirror.bit.edu.cn/apache/hadoop/common/">http://mirror.bit.edu.cn/apache/hadoop/common/</a></p>
<p>传到虚拟机后进行解压</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[liujiazhao@localhost installation]# tar -zxvf hadoop-2.9.2.tar.gz -C /home/liujiazhao/software</span><br></pre></td></tr></table></figure>

<p>配置环境变量，添加以下内容</p>
<ul>
<li><code>vi /etc/profile</code>  打开/etc/profile文件</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="built_in">set</span> hadoop environment</span></span><br><span class="line">export HADOOP_HOME=/home/liujiazhao/software/hadoop-2.9.2</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/sbin</span><br></pre></td></tr></table></figure>

<ul>
<li>刷新 <code>source /etc/profile</code>执行修改后的配置文件</li>
</ul>
<p>测试能否正常使用</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[liujiazhao@localhost hadoop-2.9.2]# hadoop</span><br><span class="line">Usage: hadoop [--config confdir] [COMMAND | CLASSNAME]</span><br><span class="line">  CLASSNAME            run the class named CLASSNAME</span><br><span class="line"> or</span><br><span class="line">  where COMMAND is one of:</span><br><span class="line">  fs                   run a generic filesystem user client</span><br><span class="line">  version              print the version</span><br><span class="line">  jar &lt;jar&gt;            run a jar file</span><br><span class="line">                       note: please use &quot;yarn jar&quot; to launch</span><br><span class="line">                             YARN applications, not this command.</span><br><span class="line">  checknative [-a|-h]  check native hadoop and compression libraries availability</span><br><span class="line">  distcp &lt;srcurl&gt; &lt;desturl&gt; copy file or directories recursively</span><br><span class="line">  archive -archiveName NAME -p &lt;parent path&gt; &lt;src&gt;* &lt;dest&gt; create a hadoop archive</span><br><span class="line">  classpath            prints the class path needed to get the</span><br><span class="line">                       Hadoop jar and the required libraries</span><br><span class="line">  credential           interact with credential providers</span><br><span class="line">  daemonlog            get/set the log level for each daemon</span><br><span class="line">  trace                view and modify Hadoop tracing settings</span><br><span class="line"></span><br><span class="line">Most commands print help when invoked w/o parameters.</span><br></pre></td></tr></table></figure>

<h2 id="将配置好的-etc-profile远程发送到其他节点"><a href="#将配置好的-etc-profile远程发送到其他节点" class="headerlink" title="将配置好的/etc/profile远程发送到其他节点"></a>将配置好的/etc/profile远程发送到其他节点</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[liujiazhao@hadoop01 ~]$ sudo scp /etc/profile hadoop02:/etc/profile</span><br><span class="line">[sudo] password for liujiazhao: </span><br><span class="line">The authenticity of host &#x27;hadoop02 (192.168.229.132)&#x27; can&#x27;t be established.</span><br><span class="line">ECDSA key fingerprint is SHA256:Y/EMBdRyFdk3GwKQZwY01nCVkoVF7Isze5AtXymcuMc.</span><br><span class="line">Are you sure you want to continue connecting (yes/no)? yes</span><br><span class="line">Warning: Permanently added &#x27;hadoop02,192.168.229.132&#x27; (ECDSA) to the list of known hosts.</span><br><span class="line">root@hadoop02&#x27;s password: </span><br><span class="line">profile                                            100% 2468   202.9KB/s   00:00    </span><br><span class="line"></span><br><span class="line">[liujiazhao@hadoop01 ~]$ sudo scp /etc/profile hadoop03:/etc/profile</span><br><span class="line">The authenticity of host &#x27;hadoop03 (192.168.229.133)&#x27; can&#x27;t be established.</span><br><span class="line">ECDSA key fingerprint is SHA256:Y/EMBdRyFdk3GwKQZwY01nCVkoVF7Isze5AtXymcuMc.</span><br><span class="line">Are you sure you want to continue connecting (yes/no)? yes</span><br><span class="line">Warning: Permanently added &#x27;hadoop03,192.168.229.133&#x27; (ECDSA) to the list of known hosts.</span><br><span class="line">root@hadoop03&#x27;s password: </span><br><span class="line">profile                                         100% 2468    41.2KB/s   00:00 </span><br></pre></td></tr></table></figure>

<h2 id="修改配置文件-六处"><a href="#修改配置文件-六处" class="headerlink" title="修改配置文件(六处)"></a>修改配置文件(六处)</h2><h3 id="hadoop-env-sh文件"><a href="#hadoop-env-sh文件" class="headerlink" title="hadoop-env.sh文件"></a>hadoop-env.sh文件</h3><p>在hadoop安装目录下<code>etc/hadoop/hadoop-env.sh</code></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> The java implementation to use.</span></span><br><span class="line">export JAVA_HOME=/usr/local/java    //将&#123;JAVA_HOME&#125;改为本机的java环境变量</span><br></pre></td></tr></table></figure>

<h3 id="core-site-xml文件"><a href="#core-site-xml文件" class="headerlink" title="core-site.xml文件"></a>core-site.xml文件</h3><p>在hadoop安装目录下<code>etc/hadoop/core-site.xml</code></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;hdfs://hadoop01:9000&lt;/value&gt;</span><br><span class="line">                &lt;description&gt;指定hdfs文件系统的名称&lt;/description&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;/home/liujiazhao/temp&lt;/value&gt;   #需提前创建数据目录</span><br><span class="line">                &lt;description&gt;配置Hadoop运行产生的临时数据存储目录（一定要配置在有限权的目录下）&lt;/description&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;io.file.buffer.size&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;4096&lt;/value&gt;</span><br><span class="line">                &lt;description&gt;配置操作HDFS的缓存大小&lt;/description&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>

<h3 id="hdfs-site-xml文件"><a href="#hdfs-site-xml文件" class="headerlink" title="hdfs-site.xml文件"></a>hdfs-site.xml文件</h3><p>在hadoop安装目录下<code>etc/hadoop/hdfs-site.xml</code></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;/home/liujiazhao/hadoopdata/name&lt;/value&gt;</span><br><span class="line">                &lt;description&gt;namenode的数据存储目录&lt;/description&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;/home/liujiazhao/hadoopdata/data&lt;/value&gt;  </span><br><span class="line">                &lt;description&gt;datanode的数据存储目录&lt;/description&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;2&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;dfs.secondary.http.address&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;hadoop02:50090&lt;/value&gt;</span><br><span class="line">                &lt;description&gt;secondarynamenode的运行节点，和namenode不同节点 &lt;/description&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>

<h3 id="yarn-site-xml文件"><a href="#yarn-site-xml文件" class="headerlink" title="yarn-site.xml文件"></a>yarn-site.xml文件</h3><p>在hadoop安装目录下<code>etc/hadoop/yarn-site.xml</code></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">&lt;!-- Site specific YARN configuration properties --&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;hadoop03&lt;/value&gt;</span><br><span class="line">                &lt;description&gt;YARN集群的主节点&lt;/description&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">                &lt;description&gt;YARN集群为MapReduce程序提供shuffle服务&lt;/description&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>

<h3 id="mapred-site-xml文件"><a href="#mapred-site-xml文件" class="headerlink" title="mapred-site.xml文件"></a>mapred-site.xml文件</h3><p>先将hadoop安装目录<code>etc/hadoop/mapred-site.xml.template</code> 转为<code>mapred-site.xml</code>文件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hadoop01 hadoop]$ cp mapred-site.xml.template mapred-site.xml</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">                &lt;description&gt;指定MapReduce跑在yarn上&lt;/description&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>

<h3 id="slaves文件"><a href="#slaves文件" class="headerlink" title="slaves文件"></a>slaves文件</h3><p><strong>将从节点的主机名填写在该文件中，注意不能有空格，一行一个主机名</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[liujiazhao@hadoop01 hadoop]# vim slaves </span><br><span class="line"></span><br><span class="line">localhost</span><br><span class="line">hadoop01</span><br><span class="line">hadoop02</span><br><span class="line">hadoop03</span><br></pre></td></tr></table></figure>

<h2 id="远程发送到其他节点"><a href="#远程发送到其他节点" class="headerlink" title="远程发送到其他节点"></a>远程发送到其他节点</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[liujiazhao@hadoop01 hadoop]$ sudo scp -r /home/liujiazhao/software/hadoop-2.9.2/* hadoop02:/home/liujiazhao/software/hadoop-2.9.2/</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[liujiazhao@hadoop01 hadoop]$ sudo scp -r /home/liujiazhao/software/hadoop-2.9.2/* hadoop03:/home/liujiazhao/software/hadoop-2.9.2/</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hadoop02 home]# chown -R liujiazhao:liujiazhao liujiazhao //在hadoop02上为文件赋权</span><br><span class="line"></span><br><span class="line">[root@hadoop03 home]# chown -R liujiazhao:liujiazhao liujiazhao //在hadoop03上为文件赋权</span><br></pre></td></tr></table></figure>

<p>在hadoop02和hadoop03主机上执行<code>source /etc/profile</code>刷新配置</p>
<h2 id="进行格式化（必须在namenode的节点操作）"><a href="#进行格式化（必须在namenode的节点操作）" class="headerlink" title="进行格式化（必须在namenode的节点操作）"></a>进行格式化（必须在namenode的节点操作）</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hadoop01 /]# hdfs namenode  -format</span><br><span class="line"></span><br><span class="line">20/09/18 00:00:02 INFO common.Storage: Storage directory /home/liujiazhao/hadoopdata/name has been successfully formatted.    //出现successfully formatted即为成功</span><br><span class="line">20/09/18 00:00:02 INFO namenode.FSImageFormatProtobuf: Saving image file /home/liujiazhao/hadoopdata/name/current/fsimage.ckpt_0000000000000000000 using no compression</span><br><span class="line">20/09/18 00:00:02 INFO namenode.FSImageFormatProtobuf: Image file /home/liujiazhao/hadoopdata/name/current/fsimage.ckpt_0000000000000000000 of size 323 bytes saved in 0 seconds .</span><br><span class="line">20/09/18 00:00:02 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid &gt;= 0</span><br><span class="line">20/09/18 00:00:03 INFO namenode.NameNode: SHUTDOWN_MSG: </span><br><span class="line">/************************************************************</span><br><span class="line">SHUTDOWN_MSG: Shutting down NameNode at hadoop01/192.168.229.131</span><br><span class="line">************************************************************/</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h2><h3 id="启动HDFS（可以在任意节点执行）"><a href="#启动HDFS（可以在任意节点执行）" class="headerlink" title="启动HDFS（可以在任意节点执行）"></a>启动HDFS（可以在任意节点执行）</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[liujiazhao@hadoop01 ~]$ start-dfs.sh</span><br><span class="line"></span><br><span class="line">启动完成后查看个节点进程</span><br><span class="line">[liujiazhao@hadoop01 ~]$ jps</span><br><span class="line">7377 Jps</span><br><span class="line">2151 NodeManager</span><br><span class="line">6600 DataNode</span><br><span class="line">6445 NameNode</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[liujiazhao@hadoop02 ~]$ jps</span><br><span class="line">7825 SecondaryNameNode</span><br><span class="line">7736 DataNode</span><br><span class="line">7915 NodeManager</span><br><span class="line">8092 Jps</span><br><span class="line"></span><br><span class="line">[liujiazhao@hadoop03 ~]$ jps</span><br><span class="line">5936 Jps</span><br><span class="line">5667 DataNode</span><br><span class="line">5779 NodeManager</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[liujiazhao@hadoop01 ~]$ stop-dfs.sh  &#x2F;&#x2F;关闭HDSF</span><br></pre></td></tr></table></figure>

<div class="note warning flat"><p>若输入<code>jps</code>未出现DateNode进程则需要进入hdfs-site.xml找到datanode的数据存储目录，将其删除重新格式化即可</p>
</div>

<h3 id="启动YARN-在yarn的主节点执行"><a href="#启动YARN-在yarn的主节点执行" class="headerlink" title="启动YARN (在yarn的主节点执行)"></a>启动YARN (在yarn的主节点执行)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[liujiazhao@hadoop03 ~]$ start-yarn.sh</span><br><span class="line"></span><br><span class="line">启动完成后查看个节点进程</span><br><span class="line">[liujiazhao@hadoop03 ~]$ jps</span><br><span class="line">5667 DataNode</span><br><span class="line">5779 NodeManager        //必需</span><br><span class="line">5989 ResourceManager    //必需</span><br><span class="line">6333 Jps</span><br><span class="line"></span><br><span class="line">[liujiazhao@hadoop01 ~]$ jps</span><br><span class="line">7445 NodeManager        //必需</span><br><span class="line">6600 DataNode</span><br><span class="line">7579 Jps</span><br><span class="line">6445 NameNode</span><br><span class="line"></span><br><span class="line">[liujiazhao@hadoop02 ~]$ jps</span><br><span class="line">7825 SecondaryNameNode    </span><br><span class="line">7736 DataNode</span><br><span class="line">7915 NodeManager        //必需</span><br><span class="line">8172 Jps</span><br></pre></td></tr></table></figure>

<h2 id="网页访问"><a href="#网页访问" class="headerlink" title="网页访问"></a>网页访问</h2><p>进入:192.168.229.131:50070 (hadoop01:50070)</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/Hadoop安装/step01.png" style="zoom:67%;" />

<p>进入:192.168.229.133:8088 (hadoop03:8088)</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/Hadoop安装/step02.png" style="zoom:67%;" />

<h2 id="关闭"><a href="#关闭" class="headerlink" title="关闭"></a>关闭</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[liujiazhao@hadoop03 ~]$ stop-yarn.sh  //在hadoop03上关闭yarn</span><br><span class="line"></span><br><span class="line">[liujiazhao@hadoop01 ~]$ stop-dfs.sh    //在hadoop01上关闭hdfs</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux常用命令合集</title>
    <url>/ckhnafzsk000petfp7cdc2gfa.html</url>
    <content><![CDATA[<h2 id="ls（查询目录中内容）"><a href="#ls（查询目录中内容）" class="headerlink" title="ls（查询目录中内容）"></a>ls（查询目录中内容）</h2><blockquote>
<p><strong>格式：</strong><code>ls [选项] [文件或目录]</code></p>
</blockquote>
<div class="note success no-icon flat"><p><strong>选项:</strong></p>
<p>-a  显示所有文件，包括隐藏文件（All）</p>
<p>-l   显示详细信息（Long List）<code>ll命令</code>=<code>ls -l</code></p>
<p>-d  查看目录属性 </p>
<p>-h  人性化显示文件大小（Human） </p>
<p>-i  显示inode</p>
</div>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">-rw-r--r--.  1 root root     1518 Jun  7  2013 aliases</span><br><span class="line">-rw-r--r--   1 root root    12288 Aug 18  2017 aliases.db</span><br><span class="line">drwxr-xr-x.  2 root root     4096 Aug 18  2017 alternatives</span><br><span class="line">-rw-------.  1 root root      541 Mar 31  2016 anacrontab</span><br></pre></td></tr></table></figure>

<p>文件权限 / 引用计数 / 所有者 / 所属组 /文件大小(字节) /最后一次修改日期 / 文件名称</p>
<div class="note primary no-icon flat"><p><strong>文件类型</strong>：</p>
<p><code>-</code>：文件        <code>d</code>：目录        <code>l</code>：软链接文件</p>
<p><code>-rw-r--r--</code>：<code>-rw</code>：所有者        <code>r--</code>：所属组        <code>r--</code>：其他人</p>
<p><strong>文件权限</strong>：</p>
<p><code>r</code>：read，读权限，代表数字<code>4</code></p>
<p><code>w</code>：write，写权限，代表数字<code>2</code></p>
<p><code>x</code>：excute，执行权限，代表数字<code>1</code></p>
</div>

<h2 id="mkdir（创建目录）"><a href="#mkdir（创建目录）" class="headerlink" title="mkdir（创建目录）"></a>mkdir（创建目录）</h2><blockquote>
<p><strong>格式：</strong><code>mkdir -p [目录名] </code></p>
</blockquote>
<div class="note success no-icon flat"><p><strong>选项:</strong></p>
<p>-p  递归创建（若上级目录不存在，则进行递归创建）</p>
</div>

<h2 id="cd（切换所在目录）"><a href="#cd（切换所在目录）" class="headerlink" title="cd（切换所在目录）"></a>cd（切换所在目录）</h2><blockquote>
<p><strong>格式:</strong></p>
<p><code>cd ~</code>     进入当前用户的家目录 </p>
<p><code>cd -</code>     进入上次目录</p>
<p><code>cd ..</code>   进入上一级目录</p>
<p><code>cd . </code>     进入当前目录</p>
<p><code>cd </code>         进入当前用户的家目录</p>
</blockquote>
<div class="note primary no-icon flat"><p><strong>相对路径</strong>：参照当前所在目录，进行查找，如:<code>[root@localhost /]# cd ../usr/local/src/ </code></p>
<p><strong>绝对路径</strong>：从根目录开始指定，一级一级递归查找。在任何目录下，都能进入指定位置，如：<code>cd /etc/</code></p>
</div>

<h2 id="cat（查看文件内容）"><a href="#cat（查看文件内容）" class="headerlink" title="cat（查看文件内容）"></a>cat（查看文件内容）</h2><blockquote>
<p><strong>格式：</strong><code>cat [文件名] </code></p>
</blockquote>
<div class="note success no-icon flat"><p><strong>选项:</strong></p>
<p>-n  给输出的所有行加上编号</p>
</div>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@iZbp1b93sucih6jytwvguzZ mysql]# cat -n /proc/cpuinfo </span><br><span class="line">     1    processor    : 0</span><br><span class="line">     2    vendor_id    : GenuineIntel</span><br><span class="line">     3    cpu family    : 6</span><br><span class="line">     4    model        : 79</span><br><span class="line">     5    model name    : Intel(R) Xeon(R) CPU E5-2682 v4 @ 2.50GHz</span><br><span class="line">     6    stepping    : 1</span><br><span class="line">     7    microcode    : 0x1</span><br><span class="line">     8    cpu MHz        : 2494.220</span><br><span class="line">     9    cache size    : 40960 KB</span><br><span class="line">    10    physical id    : 0</span><br><span class="line">    11    siblings    : 1</span><br><span class="line">    12    core id        : 0</span><br><span class="line">    13    cpu cores    : 1</span><br><span class="line">    14    apicid        : 0</span><br><span class="line">    15    initial apicid    : 0</span><br><span class="line">    16    fpu        : yes</span><br><span class="line">    17    fpu_exception    : yes</span><br><span class="line">    18    cpuid level    : 13</span><br><span class="line">    19    wp        : yes</span><br><span class="line">    20    flags        : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl eagerfpu pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt spec_ctrl intel_stibp</span><br><span class="line">    21    bogomips    : 4988.44</span><br><span class="line">    22    clflush size    : 64</span><br><span class="line">    23    cache_alignment    : 64</span><br><span class="line">    24    address sizes    : 46 bits physical, 48 bits virtual</span><br><span class="line">    25    power management:</span><br><span class="line">    26    </span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat 1 2 &gt; 3 #将1，2的文件内容合并到3（可进行多个文件的合并）</span><br></pre></td></tr></table></figure>

<h2 id="wc（统计文件内容）"><a href="#wc（统计文件内容）" class="headerlink" title="wc（统计文件内容）"></a>wc（统计文件内容）</h2><blockquote>
<p><strong>格式：</strong><code>wc [文件名] </code></p>
</blockquote>
<div class="note success no-icon flat"><p><strong>选项:</strong></p>
<p>-l    统计行数</p>
<p>-w  统计单词数</p>
<p>-c   统计字符数</p>
</div>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@iZbp1b93sucih6jytwvguzZ test]# wc asd 行数,单词数,字符数</span><br><span class="line"> 5  7 30 asd</span><br><span class="line">[root@iZbp1b93sucih6jytwvguzZ test]# cat asd</span><br><span class="line">ha</span><br><span class="line">asdas</span><br><span class="line">as </span><br><span class="line">this is 1 file</span><br></pre></td></tr></table></figure>

<h2 id="rmdir（删除空目录）"><a href="#rmdir（删除空目录）" class="headerlink" title="rmdir（删除空目录）"></a>rmdir（删除空目录）</h2><blockquote>
<p> <strong>格式：</strong><code>mkdir [目录名] </code></p>
</blockquote>
<h2 id="rm（删除文件或目录）"><a href="#rm（删除文件或目录）" class="headerlink" title="rm（删除文件或目录）"></a>rm（删除文件或目录）</h2><blockquote>
<p><strong>格式：</strong><code>rm -rf [文件或目录] </code></p>
</blockquote>
<div class="note success no-icon flat"><p><strong>选项:</strong></p>
<p>-r    删除目录</p>
<p>-f    强制（False） </p>
</div>

<h2 id="cp（复制命令）"><a href="#cp（复制命令）" class="headerlink" title="cp（复制命令）"></a>cp（复制命令）</h2><blockquote>
<p><strong>格式：</strong><code>cp [选项] [原文件或目录] [目标目录] </code></p>
</blockquote>
<div class="note success no-icon flat"><p><strong>选项:</strong></p>
<p>-r    复制目录 </p>
<p>-p   连带文件属性复制 </p>
<p>-d   若源文件是链接文件，这复制链接属性 </p>
<p>-h   相当于-pdr </p>
</div>

<h2 id="mv（剪切或改名）"><a href="#mv（剪切或改名）" class="headerlink" title="mv（剪切或改名）"></a>mv（剪切或改名）</h2><blockquote>
<p><strong>格式：</strong><code>mv [原文件或目录] [目标目录]</code></p>
</blockquote>
<h2 id="ln（链接命令）"><a href="#ln（链接命令）" class="headerlink" title="ln（链接命令）"></a>ln（链接命令）</h2><blockquote>
<p><strong>格式：</strong><code>ln  [选项]  [原文件]  [目标文件]</code></p>
</blockquote>
<div class="note success no-icon flat"><p><strong>选项:</strong></p>
<p>-s  创建软链接</p>
</div>

<div class="note primary no-icon flat"><ul>
<li><strong>软链接特征</strong><ul>
<li><strong>类似Windows快捷方式</strong></li>
<li>软链接拥有自己的i节点和Block块，但是数据块只保 存原文件的文件名和i节点号，并没有实际的文件数据</li>
<li><code>lrwxrwxrwx</code>  <code>l</code>软链接(软链接文件权限都为rwxrwxrwx)</li>
<li>修改任意文件，另一个都改变 </li>
<li>删除原文件，软链接不能使用</li>
</ul>
</li>
<li><strong>硬链接特征</strong><ul>
<li>用于相同的i节点和存储block块，可以看做是同一个文件 </li>
<li>可通过i节点识别 </li>
<li>不能跨分区 </li>
<li>不能针对目录使用</li>
<li><strong>原文件修改后硬链接文件也会随之修改， 通过硬链接修改文件原文件也会被修改</strong></li>
<li>若删除原文件文件，也依然可以通过硬链接来访问文件</li>
</ul>
</li>
</ul>
</div>

<h2 id="locate（文件搜索命令）"><a href="#locate（文件搜索命令）" class="headerlink" title="locate（文件搜索命令）"></a>locate（文件搜索命令）</h2><blockquote>
<p><strong>格式：</strong><code>locate  文件名</code></p>
</blockquote>
<div class="note success no-icon flat"><p><strong>选项:</strong></p>
<p>-r    复制目录 </p>
<p>-p   连带文件属性复制 </p>
<p>-d   若源文件是链接文件，这复制链接属性 </p>
<p>-h   相当于-pdr </p>
</div>

<div class="note primary no-icon flat"><p>在<strong>后台数据库</strong>中按文件名搜索，搜索速度更快</p>
<p><strong>/var/lib/mlocate</strong>是locate命令搜索的后台数据库 </p>
<p>mlocate一天一更新，最新创建的文件无法搜索到，可使用<code>updatedb</code>命令进行强制更新数据库 </p>
<p><strong>限制：只能按照文件名进行搜索(无法按照大小，日期）</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/etc/updatedb.conf配置文件:</span><br><span class="line">PRUNE_BIND_MOUNTS = <span class="string">&quot;yes&quot;</span> <span class="comment">#开启搜索限制 </span></span><br><span class="line">PRUNEFS = <span class="comment">#搜索时，不搜索的文件系统 </span></span><br><span class="line">PRUNENAMES = <span class="comment">#搜索时，不搜索的文件类型 </span></span><br><span class="line">PRUNEPATHS = <span class="comment">#搜索时，不搜索的路径</span></span><br></pre></td></tr></table></figure>
</div>

<h2 id="whereis（命令搜索命令）"><a href="#whereis（命令搜索命令）" class="headerlink" title="whereis（命令搜索命令）"></a>whereis（命令搜索命令）</h2><blockquote>
<p><strong>格式：</strong><code>whereis 命令名</code> </p>
</blockquote>
<div class="note success no-icon flat"><p><strong>选项:</strong></p>
<p>-b    只查找可执行文件 </p>
<p>-m   只查找帮助文件 </p>
</div>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@iZbp1etbb1rzfgZ ~]# whereis ls</span><br><span class="line">ls: /usr/bin/ls /usr/share/man/man1/ls.1.gz</span><br></pre></td></tr></table></figure>

<h2 id="which（命令搜索命令）"><a href="#which（命令搜索命令）" class="headerlink" title="which（命令搜索命令）"></a>which（命令搜索命令）</h2><blockquote>
<p>格式：<code>which 命令名 </code></p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@iZbp1etbb1qr3hzfgZ ~]# which ls</span><br><span class="line">alias ls=&#x27;ls --color=auto&#x27;</span><br><span class="line">    /usr/bin/ls</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@iZbp1etbb1qarzfgZ ~]# echo $PATH</span><br><span class="line">/opt/jdk13.0.2/bin:/usr/local/mysql/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin</span><br></pre></td></tr></table></figure>

<div class="note warning flat"><p>:号为分隔符，执行命令时会在这些路径中逐个寻找，看该目录下是否有对应的可执行命令，如果自己写的程序需要执行需要写绝对路径，或是放在PATH环境变量下</p>
</div>

<h2 id="find（文件搜索命令）"><a href="#find（文件搜索命令）" class="headerlink" title="find（文件搜索命令）"></a>find（文件搜索命令）</h2><blockquote>
<p>格式：<code>find [搜索范围] [搜索条件] </code></p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">find / -name install.log #在/下查找install.log文件</span><br></pre></td></tr></table></figure>

<div class="note warning flat"><p>避免大范围搜索，会非常耗费系统资源 </p>
</div>

<div class="note success no-icon flat"><p>find是在系统当中搜索符合条件的文件名， 如果需要匹配，使用通配符匹配，通配符是完全匹配</p>
<p><strong>Linux中通配符:</strong></p>
<p>*匹配任意内容</p>
<p>？匹配任意字符</p>
<p>[ ] 匹配任意一个中括号内的字符（<code>[cd]</code>匹配的是c或d）</p>
</div>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">find /root -iname install.log #不区分大小写</span><br><span class="line">find /root -user root  #按照所有者搜索</span><br><span class="line">find /root -nouser #查找没有所有者的文件</span><br><span class="line">find /var/log/ -mtime +10 #查找10天前修改的文件</span><br></pre></td></tr></table></figure>

<div class="note primary no-icon flat"><p><code>-atime</code>  文件访问时间</p>
<p> <code>-ctime</code>  修改文件属性</p>
<p>  <code>-mtime</code> 修改文件内容</p>
<p><code>-10</code>  10天内修改文件  </p>
<p><code>10</code> 10天当天修改的文件</p>
<p><code>+10</code> 10天前修改的文件</p>
</div>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">find . -size 25k #查找文件大小是25kb的文件</span><br></pre></td></tr></table></figure>

<div class="note primary no-icon flat"><p><code>-25k</code> 小于25KB的文件 </p>
<p><code>25k </code>  等于25KB的文件 </p>
<p><code>+25k</code> 大于25KB的文件</p>
</div>

<div class="note warning flat"><p><strong>千字节是小写k，兆字节是大写M</strong></p>
</div>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">find . -inum 262422 #查找i节点是262422的文件</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">find /etc -size +20k -a -size -50k #查找/etc/目录下，大于20KB并且小于50KB的文件  </span><br></pre></td></tr></table></figure>

<div class="note success no-icon flat"><p><strong>选项:</strong></p>
<p>-a     and  逻辑与，两个条件都满足</p>
<p>-o     or    逻辑或，两个条件满足一个即可</p>
</div>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">find /etc -size +20k -a -size -50k -exec ls -lh &#123;&#125; \; #查找/etc目录下，大于20KB并且小于50KB的文件,并显示详细信息</span><br></pre></td></tr></table></figure>

<p><code>-exec/-ok 命令 &#123;&#125;\;</code>对搜索结果执行操作</p>
<h2 id="grep（搜索字符命令）"><a href="#grep（搜索字符命令）" class="headerlink" title="grep（搜索字符命令）"></a>grep（搜索字符命令）</h2><blockquote>
<p><strong>格式：</strong><code>grep [选项] 字符串 文件名 </code></p>
</blockquote>
<div class="note success no-icon flat"><p><strong>选项:</strong></p>
<p>-i   忽略大小写 </p>
<p>-v  排除指定的字符串（取反）</p>
</div>

<div class="note primary no-icon flat"><p><strong>find命令和grep命令的区别:</strong></p>
<p>find命令：在系统当中搜索符合条件的文件名，如果需要匹配，使用通配符匹配，通配符是完全匹配 。</p>
<p>grep命令：在文件当中搜索符合条件的字符串，如果需要匹配，使用正则表达式进行匹配， 正则表达式时包含匹配。</p>
</div>

<h2 id="man（帮助命令）"><a href="#man（帮助命令）" class="headerlink" title="man（帮助命令）"></a>man（帮助命令）</h2><blockquote>
<p><strong>格式：</strong><code>man 命令 </code></p>
</blockquote>
<div class="note success no-icon flat"><p><strong>选项:</strong></p>
<p>-f    相当于<code>whatis 命令</code></p>
<p>-k   相当于<code>apropos 命令</code></p>
</div>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@iZbp1etbb1qr3hmgqarzfgZ ~]# man ls   #查看ls命令的帮助</span><br><span class="line">[root@iZbp1etbb1qr3hmgqarzfgZ ~]# man -f ls</span><br></pre></td></tr></table></figure>

<div class="note primary no-icon flat"><p><strong>man的级别（可通过<code>man man</code>命令找到）:</strong></p>
<ul>
<li>1 ：查看命令的帮助</li>
<li>2 ：查看可被内核调用的函数的帮助 </li>
<li>3 ：查看函数和函数库的帮助 </li>
<li>4 ：查看特殊文件的帮助(主要是/dev目录下的文件) </li>
<li>5 ：查看配置文件的帮助 </li>
<li>6 ：查看游戏的帮助</li>
<li>7 ：查看其它杂项的帮助 </li>
<li>8 ：查看系统管理员可用命令的帮助 </li>
<li>9 ：查看和内核相关文件的帮助</li>
</ul>
<p><strong>使用man命令阅读手册页</strong></p>
<ul>
<li><p>使用↑↓方向键滚动文本</p>
</li>
<li><p>使用Page Up和Page Down键翻页</p>
</li>
<li><p>按Q或q退出阅读环境</p>
</li>
<li><p>按“/”后查找内容</p>
</li>
</ul>
</div>

<h2 id="info（详细目录帮助）"><a href="#info（详细目录帮助）" class="headerlink" title="info（详细目录帮助）"></a>info（详细目录帮助）</h2><blockquote>
<p><strong>格式：</strong><code>info 命令</code></p>
</blockquote>
<div class="note primary no-icon flat"><p><kbd>Enter</kbd>：进入子帮助页面（带有*号标记）</p>
<p><kbd>u</kbd>：进入上层页面</p>
<p><kbd>n</kbd>：进入下一个帮助小节 </p>
<p><kbd>p</kbd>：进入上一个帮助小节 </p>
<p><kbd>q</kbd>： 退出</p>
</div>

<div class="note info flat"><p>可以在命令后添加<code>--help</code>选项查询命令选项帮助 </p>
</div>

<h2 id="chmod（修改权限）"><a href="#chmod（修改权限）" class="headerlink" title="chmod（修改权限）"></a>chmod（修改权限）</h2><blockquote>
<p><strong>格式：</strong><code>chmod [选项][权限设定字符串] 文件</code></p>
</blockquote>
<div class="note success no-icon flat"><p><strong>选项:</strong></p>
<p>-c   若该文件权限确实已经更改，才显示其更改动作</p>
<p>-f    若该文件权限无法被更改也不要显示错误讯息</p>
<p>-v   显示权限变更的详细资料</p>
<p>-R  对目前目录下的所有文件与子目录进行相同的权限变更</p>
<p><strong>权限设定字符串:</strong></p>
<p>格式：<code>[ugoa...][[+-=][rwx]...]</code></p>
<p>u  表示该文件的拥有者</p>
<p>g  表示与该文件的拥有者属于同一个群体(group)者</p>
<p>o  表示其他以外的人</p>
<p>a  表示这三者皆是</p>
<p>+  表示增加权限、- 表示取消权限、= 表示唯一设定权限</p>
<p>r  表示可读取，w 表示可写入，x 表示可执行</p>
</div>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">chmod ugo+r file1 #将文件 file1设为所有人皆可读取</span><br><span class="line">chmod a+r file1  #将文件 file1设为所有人皆可读取</span><br><span class="line">chmod -R a+r file1 #将目录下的所有文件与子目录皆设为任何人可读取</span><br><span class="line">chmod 777 file #用数字表示权限</span><br></pre></td></tr></table></figure>

<div class="note primary no-icon flat"><p>文件权限： <code>r</code>：read，读权限，代表数字<code>4</code></p>
<p>​                    <code>w</code>：write,写权限，代表数字<code>2</code></p>
<p>​                    <code>x</code>：excute,执行权限，代表数字<code>1</code></p>
<p>分别表示User、Group、及Other的权限</p>
</div>

<h2 id="chown（修改文件拥有）"><a href="#chown（修改文件拥有）" class="headerlink" title="chown（修改文件拥有）"></a>chown（修改文件拥有）</h2><blockquote>
<p><strong>格式：</strong><code>chown [选项] user[:group] 文件</code></p>
</blockquote>
<div class="note success no-icon flat"><p><strong>选项:</strong></p>
<p>-c   显示更改的部分的信息</p>
<p>-f    忽略错误信息</p>
<p>-h   修复符号链接</p>
<p>-v   显示详细的处理信息</p>
<p>-R   处理指定目录以及其子目录下的所有文件</p>
</div>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">chown www:www file1 #将file1拥有者设为www，群体的使用者 www</span><br><span class="line">chown -R www:www tomcat #将tomcat目录下所有文件和子目录</span><br></pre></td></tr></table></figure>

<h2 id="zip（-zip格式压缩）"><a href="#zip（-zip格式压缩）" class="headerlink" title="zip（.zip格式压缩）"></a>zip（.zip格式压缩）</h2><blockquote>
<p><strong>格式：</strong><code>zip 压缩文件名 源文件   </code> #压缩文件</p>
<p><strong>格式：</strong><code>zip –r 压缩文件名 源文件 </code>   #压缩目录</p>
</blockquote>
<h2 id="unzip（解压-zip文件）"><a href="#unzip（解压-zip文件）" class="headerlink" title="unzip（解压.zip文件）"></a>unzip（解压.zip文件）</h2><blockquote>
<p><strong>格式：</strong><code>unzip 压缩文件</code></p>
</blockquote>
<h2 id="gzip-gz格式压缩"><a href="#gzip-gz格式压缩" class="headerlink" title="gzip(.gz格式压缩)"></a>gzip(.gz格式压缩)</h2><blockquote>
<p><strong>格式：</strong><code>gzip 源文件</code>  #压缩为.gz格式的压缩文件，源文件会消失</p>
<p><strong>格式：</strong><code>gzip -c 源文件 &gt; 压缩文件 </code>#压缩为.gz格式的压缩文件，源文件会保留 </p>
<p>​            例如：gzip –c canls &gt; canls.gz</p>
<p><strong>格式：</strong><code>gzip -d 压缩文件  </code>  #解压缩文件</p>
<p><strong>格式：</strong><code>gunzip 压缩文件 </code>  #解压缩文件</p>
<p><strong>格式：</strong><code>gzip -r 目录 </code> #压缩目录下的所有子文件，但是不能压缩目录,<strong>目录下的文件全变成.gz格式</strong></p>
</blockquote>
<h2 id="bzip2（-bz2格式压缩）"><a href="#bzip2（-bz2格式压缩）" class="headerlink" title="bzip2（.bz2格式压缩）"></a>bzip2（.bz2格式压缩）</h2><blockquote>
<p><strong>格式：</strong><code>bzip2 源文件</code>  #压缩为.bz2格式，不保留源文件 </p>
<p><strong>格式：</strong><code>bzip2 -k 源文件 </code>  #压缩之后保留源文件 </p>
<p><strong>格式：</strong><code>bzip2 –d 压缩文件 </code>  #解压缩,-k保留压缩文件</p>
<p><strong>格式：</strong><code>bunzip2 压缩文件 </code>  #解压缩,-k保留压缩文件</p>
</blockquote>
<h2 id="tar（打包命令）"><a href="#tar（打包命令）" class="headerlink" title="tar（打包命令）"></a>tar（打包命令）</h2><blockquote>
<p><strong>格式：</strong><code>tar –cvf 打包文件名 源文件 </code>  **</p>
</blockquote>
<div class="note success no-icon flat"><p><strong>选项:</strong></p>
<p>-c   打包 </p>
<p>-x   解打包</p>
<p>-v   显示过程 </p>
<p>-f   指定打包后的文件名</p>
<p>-t    查看压缩文件内容  </p>
</div>

<p><strong>.tar.gz格式压缩（tar.gz格式是先打包为.tar格式，再解压为.gz格式 ）:</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar –zcvf 压缩包名.tar.gz 源文件     #压缩为.tar.gz格式 </span><br><span class="line">tar –zxvf 压缩包名.tar.gz           #解压缩.tar.gz格式</span><br></pre></td></tr></table></figure>

<p><strong>.tar.bz2格式压缩:</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar –jcvf 压缩包名.tar.bz2 源文件  #压缩为.tar.bz2格式</span><br><span class="line">tar –jxvf 压缩包名.tar.bz2        #解压缩.tar.bz2格式</span><br></pre></td></tr></table></figure>

<h2 id="shutdown（关机与重启）"><a href="#shutdown（关机与重启）" class="headerlink" title="shutdown（关机与重启）"></a>shutdown（关机与重启）</h2><blockquote>
<p><strong>格式：</strong><code>shutdown [选项] 时间 </code></p>
</blockquote>
<div class="note success no-icon flat"><p><strong>选项:</strong></p>
<p>-c    取消前一个关机命令 </p>
<p>-h   关机 </p>
<p>-r    重启 </p>
</div>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">shutdown –h now #关机命令</span><br><span class="line">shutdown –r now #重启命令</span><br></pre></td></tr></table></figure>

<div class="note primary no-icon flat"><p>其他关机命令：<code>halt</code>    <code>poweroff</code>    <code>init 0</code></p>
<p>其他重启命令：<code>reboot</code>    <code>init 6</code></p>
<p><strong>退出登录命令</strong>：<code>logout</code></p>
</div>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@iZbp1etbb1qZ ~]# runlevel #查询当前系统所处级别</span><br><span class="line">N 3</span><br></pre></td></tr></table></figure>

<div class="note primary no-icon flat"><p><strong>系统运行级别:</strong></p>
<p>0 ：关机 </p>
<p>1 ：单用户（最小安装，用于系统修复）</p>
<p>2 ：不完全多用户，不含NFS服务（文件共享服务） </p>
<p>3 ：完全多用户（字符界面） </p>
<p>4 ：未分配 </p>
<p>5 ：图形界面 </p>
<p>6 ：重启 </p>
<p>使用<code>cat /etc/inittab</code>设置系统默认启动级别</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># multi-user.target: analogous to runlevel 3</span></span><br><span class="line"><span class="comment"># graphical.target: analogous to runlevel 5</span></span><br></pre></td></tr></table></figure>

<p>执行命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># To view current default target, run:</span></span><br><span class="line"><span class="comment"># systemctl get-default</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># To set a default target, run:</span></span><br><span class="line"><span class="comment"># systemctl set-default TARGET.target</span></span><br></pre></td></tr></table></figure>
</div>

<h2 id="mount（查询与自动挂载）"><a href="#mount（查询与自动挂载）" class="headerlink" title="mount（查询与自动挂载）"></a>mount（查询与自动挂载）</h2><blockquote>
<p>格式：<code>mount [-t 文件系统] [-o 特殊选项] 设备文件名 挂载点</code></p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[labcz@localhost ~]$ mount #查询系统中已经挂载的设备 </span><br><span class="line">[labcz@localhost ~]$ mount -a #依据配置文件/etc/fstab的内容，自动挂载</span><br></pre></td></tr></table></figure>

<div class="note warning flat"><p>若自己添加了光盘挂载，若启动时未放入光 盘，会导致系统启动失败 </p>
</div>

<div class="note success no-icon flat"><p><strong>选项:</strong></p>
<p>-t 文件系统：加入文件系统类型来指定挂载的类型，可以ext3、ext4、iso9660等文件系统(Linux默认是不支持NTFS文件系统)</p>
<p>-o 特殊选项：可以指定挂载的额外选项</p>
</div>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[labcz@localhost ~]$ mkdir /mnt/cdrom #建立挂载点 </span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[labcz@localhost ~]$ mount –t iso9660 /dev/sr0  /mnt/cdrom/ #挂载光盘</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[labcz@localhost ~]$ mount  /dev/sr0  /mnt/cdrom/ #系统默认iso9660（因此-t iso9660可以不加）</span><br></pre></td></tr></table></figure>

<div class="note info flat"><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mount: /mnt/cdrom: WARNING device write-protected, mounted read-only</span><br></pre></td></tr></table></figure>

<p>警告是挂载是默认挂载读写权限，但是光盘一旦制作完成将无法写入数据，被迫挂为只读选项可以将这条警告当做<code>成功的标志</code></p>
</div>

<h2 id="umount（卸载光盘）"><a href="#umount（卸载光盘）" class="headerlink" title="umount（卸载光盘）"></a>umount（卸载光盘）</h2><blockquote>
<p><strong>格式：</strong><code>umount 设备文件名或挂载点 </code></p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[labcz@localhost ~]$ umount /mnt/cdrom</span><br></pre></td></tr></table></figure>

<div class="note warning flat"><p>当出现mount ：/mnt/cdrom ：target is busy</p>
<p>因为当前处于mnt/cdrom下，所以目标正忙， 退出该目录就可以</p>
</div>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[labcz@localhost ~]$ fdisk -l #查看U盘设备文件名</span><br></pre></td></tr></table></figure>

<h2 id="w（查看用户登录信息）"><a href="#w（查看用户登录信息）" class="headerlink" title="w（查看用户登录信息）"></a>w（查看用户登录信息）</h2><blockquote>
<p>格式：<code>userdel [-r] 用户名</code></p>
</blockquote>
<div class="note primary no-icon flat"><p><strong>命令输出:</strong></p>
<p>USER：登录的用户名 </p>
<p>TTY：登录终端 </p>
<p>FROM：从那个IP地址登录 </p>
<p>LOGIN@：登录时间 </p>
<p>IDEL：用户配置时间 </p>
<p>JCPU：指的是和该终端连接的所有进程占用的时间。这个时间里并不包括过去的 后台作业时间，但却包括当前正在运行的后台作业所占用的时间。 </p>
<p>PCPU ：是指当前进程所占用的时间 </p>
<p>WHAT：当前正在运行的命令 </p>
</div>

<h2 id="useradd（添加用户）"><a href="#useradd（添加用户）" class="headerlink" title="useradd（添加用户）"></a>useradd（添加用户）</h2><blockquote>
<p>格式：<code>useradd 用户名</code></p>
</blockquote>
<div class="note success no-icon flat"><p><strong>选项:</strong></p>
<p>-u  指定UID标记号</p>
<p>-d  指定宿主目录，缺省为/home/用户名</p>
<p>-e  指定账号失效时间</p>
<p>-g  指定用户的基本组名（或UID号）</p>
<p>-G 指定用户的附加组名（或GID号）</p>
<p>-M 不为用户创建并初始化宿主目录</p>
<p>-s 指定用户的登录shell</p>
</div>

<h2 id="userdel（删除用户）"><a href="#userdel（删除用户）" class="headerlink" title="userdel（删除用户）"></a>userdel（删除用户）</h2><blockquote>
<p><strong>格式：</strong><code>userdel [-r] 用户名</code></p>
</blockquote>
<div class="note warning flat"><p>添加-r选项时，表示连用户的宿主目录一并删除</p>
</div>

<h2 id="last（查询当前登录用户信息）"><a href="#last（查询当前登录用户信息）" class="headerlink" title="last（查询当前登录用户信息）"></a>last（查询当前登录用户信息）</h2><blockquote>
<p> <strong>格式：</strong><code>last</code></p>
</blockquote>
<div class="note info flat"><p>last命令默认是读取/var/log/wtmp文件数据</p>
</div>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@iZbp1etbb1qr3hmgqarzfgZ ~]# last</span><br><span class="line">root     pts/1        111.79.65.176    Fri Mar 13 18:27   still logged in   </span><br><span class="line">root     pts/1        111.79.65.176    Fri Mar 13 13:01 - 13:38  (00:37)    </span><br><span class="line">root     pts/1        111.79.65.47     Wed Mar  4 12:43 - 17:02  (04:18)    </span><br><span class="line">root     pts/2        182.109.122.146  Mon Mar  2 13:58 - 14:06  (00:07)    </span><br><span class="line">root     pts/1        182.109.122.146  Mon Mar  2 10:45 - 13:58  (03:13)    </span><br></pre></td></tr></table></figure>

<p>用户名 / 登录终端 / 登录IP /登录时间 / 退出时间</p>
<h2 id="who（列出所有登陆当前系统中的用户信息）"><a href="#who（列出所有登陆当前系统中的用户信息）" class="headerlink" title="who（列出所有登陆当前系统中的用户信息）"></a>who（列出所有登陆当前系统中的用户信息）</h2><blockquote>
<p> <strong>格式：</strong><code>who</code></p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@iZbp1etbb1qr3hmgqarzfgZ ~]# who</span><br><span class="line">root     pts/1        2020-03-13 18:27 (111.79.65.176)</span><br></pre></td></tr></table></figure>

<p>用户名 / 登录终端 / 登录时间 (登录来源IP地址)</p>
<h2 id="lastlog（查询所有用户最后一次登录时间）"><a href="#lastlog（查询所有用户最后一次登录时间）" class="headerlink" title="lastlog（查询所有用户最后一次登录时间）"></a>lastlog（查询所有用户最后一次登录时间）</h2><blockquote>
<p><strong>格式：</strong><code>lastlog</code></p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@iZbp1etbb1qr3hmgqarzfgZ ~]# lastlog</span><br><span class="line">Username         Port     From             Latest</span><br><span class="line">root             pts/1    111.79.65.176    Fri Mar 13 18:27:54 +0800 2020</span><br><span class="line">bin                                        **Never logged in**</span><br><span class="line">daemon                                     **Never logged in**</span><br><span class="line">adm                                        **Never logged in**</span><br><span class="line">lp                                         **Never logged in**</span><br><span class="line">sync                                       **Never logged in**</span><br></pre></td></tr></table></figure>

<h2 id="uname（查看系统内核信息）"><a href="#uname（查看系统内核信息）" class="headerlink" title="uname（查看系统内核信息）"></a>uname（查看系统内核信息）</h2><blockquote>
<p><strong>格式：</strong><code>uname</code></p>
</blockquote>
<div class="note success no-icon flat"><p><strong>选项：</strong></p>
<p>-a  显示主机名、内核版本、硬件平台等详细信息</p>
<p>-r   显示内核版本</p>
</div>

<div class="note warning flat"><p>last命令默认是读取/var/log/wtmp文件数据</p>
</div>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@iZbp1b93sucih6jytwvguzZ ~]# uname -a</span><br><span class="line">Linux iZbp1b93sucih6jytwvguzZ 3.10.0-1062.12.1.el7.x86_64 #1 SMP Tue Feb 4 23:02:59 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux</span><br></pre></td></tr></table></figure>

<h2 id="ifconfig（查看IP地址）"><a href="#ifconfig（查看IP地址）" class="headerlink" title="ifconfig（查看IP地址）"></a>ifconfig（查看IP地址）</h2><blockquote>
<p> <strong>格式：</strong><code>ipconfig</code></p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@iZbp1b93sucih6jytwvguzZ ~]# ifconfig</span><br><span class="line">eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span><br><span class="line">        inet 172.16.114.189  netmask 255.255.240.0  broadcast 172.16.127.255</span><br><span class="line">        ether 00:16:3e:0b:65:e3  txqueuelen 1000  (Ethernet)</span><br><span class="line">        RX packets 549736  bytes 377625035 (360.1 MiB)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 414934  bytes 899837955 (858.1 MiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line"></span><br><span class="line">lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt;  mtu 65536</span><br><span class="line">        inet 127.0.0.1  netmask 255.0.0.0</span><br><span class="line">        loop  txqueuelen 1000  (Local Loopback)</span><br><span class="line">        RX packets 29  bytes 1548 (1.5 KiB)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 29  bytes 1548 (1.5 KiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th align="center">名称</th>
<th align="center">网卡类型</th>
</tr>
</thead>
<tbody><tr>
<td align="center">eth0</td>
<td align="center">以太网</td>
</tr>
<tr>
<td align="center">lo</td>
<td align="center">（虚拟）回环设备</td>
</tr>
<tr>
<td align="center">ppp0</td>
<td align="center">使用PPP协议的串口设备（通常指调制解调器）</td>
</tr>
<tr>
<td align="center">tr0</td>
<td align="center">令牌环（Token Ring）</td>
</tr>
<tr>
<td align="center">fddi0</td>
<td align="center">光纤</td>
</tr>
</tbody></table>
<h2 id="pwd（查看当前所知目录）"><a href="#pwd（查看当前所知目录）" class="headerlink" title="pwd（查看当前所知目录）"></a>pwd（查看当前所知目录）</h2><blockquote>
<p> <strong>格式：</strong><code>pwd</code></p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@iZbp1b93sucih6jytwvguzZ mysql]# pwd</span><br><span class="line">&#x2F;usr&#x2F;local&#x2F;mysql</span><br></pre></td></tr></table></figure>

<h2 id="du（统计目录大小）"><a href="#du（统计目录大小）" class="headerlink" title="du（统计目录大小）"></a>du（统计目录大小）</h2><div class="note success no-icon flat"><p><strong>选项:</strong></p>
<p>-a  统计时包括所有的文件，而不仅仅只统计目录</p>
<p>-h  以更易读的字节单位（K，M等）显示信息</p>
<p>-s  只统计每个参数所占用空间的总大小</p>
</div>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@iZbp1b93sucih6jytwvguzZ mysql]# du -sh /home</span><br><span class="line">211M    /home</span><br></pre></td></tr></table></figure>

<h2 id="netstat-网络连接情况"><a href="#netstat-网络连接情况" class="headerlink" title="netstat(网络连接情况)"></a>netstat(网络连接情况)</h2><div class="note success no-icon flat"><p><strong>选项:</strong></p>
<p>-a    显示所有活动连接</p>
<p>-n    以数字形式显示</p>
<p>-p    显示进程信息</p>
<p>-t     查看TCP协议相关信息</p>
<p>-u    查看UDP协议相关信息</p>
<p>-r     显示路由表信息</p>
</div>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@iZb mysql]$ netstat -antp    #使用最多</span><br></pre></td></tr></table></figure>

<h2 id="hostname（查看主机名）"><a href="#hostname（查看主机名）" class="headerlink" title="hostname（查看主机名）"></a>hostname（查看主机名）</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@iZbp1b93sucih6jytwvguzZ mysql]# hostname</span><br><span class="line">labcz</span><br></pre></td></tr></table></figure>

<p>永久修改主机名：<code>hostnamectl set-hostname HOSTNAME</code></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title>玩转Git</title>
    <url>/ckhnafzsm000setfp1llfgtcc.html</url>
    <content><![CDATA[<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><h2 id="版本控制"><a href="#版本控制" class="headerlink" title="版本控制"></a>版本控制</h2><p>在实际开发中，我们会对项目进行多次的测试修改，以及将别人开发项目的部分合并，于是就会出现：</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/1.jpg" style="zoom:67%;" />

<p>此时在软件项目开发时就需要一个版本控制工具</p>
<h2 id="常见的版本控制工具"><a href="#常见的版本控制工具" class="headerlink" title="常见的版本控制工具"></a>常见的版本控制工具</h2><ul>
<li>Git（分布式版本控制系统）<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/git.png" style="zoom:67%;" /></li>
</ul>
<ul>
<li>SVN（Subversion）<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/SVN.jpg" style="zoom:35%;" /></li>
</ul>
<ul>
<li>CVS（Concurrent Version System）<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/CVS.jpg" style="zoom:10%;" /></li>
</ul>
<h2 id="版本控制分类"><a href="#版本控制分类" class="headerlink" title="版本控制分类"></a>版本控制分类</h2><ul>
<li><p>本地版本控制系统</p>
<p> 许多人习惯用复制整个项目目录的方式来保存不同的版本，或许还会改名加上备份时间以示区别。这么做唯一的好处就是简单，但是特别容易犯错。有时候会混淆所在的工作目录，一不小心会写错文件或者覆盖意想外的文件。为了解决这个问题，人们就开发了许多种本地版本控制系统，大多都是采用某种简单的数据库来记录文件的历次更新差异。适合个人用，如RCS。</p>
</li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/2.jpg" style="zoom:50%;" />

<ul>
<li><p>集中版本控制 SVN</p>
<p>版本库是集中存放在中央服务器的，工作的时候，用的都是自己的电脑，所以要先从中央服务器取得最新的版本，然后开始干活，干完活了，再把自己的活推送给中央服务器。所有数据都保存在单一的服务器上，有很大的风险这个服务器会损坏，这样就会丢失所有的数据。</p>
</li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/3.jpg" style="zoom:50%;" />

<ul>
<li><p>分布式版本控制 Git</p>
<p>在这类系统中，客户端并不只提取最新版本的文件快照，而是把代码仓库完整地镜像下来，所有版本信息仓库全部同步到本地的每个用户，这样就可以在本地查看所有版本历史，任何一处协同工作用的服务器发生故障，事后都可以用任何一个镜像出来的本地仓库恢复。只要有一个用户的设备没有问题就可以恢复所有的数据。</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/4.jpg" style="zoom:67%;" />

</li>
</ul>
<h1 id="Git介绍"><a href="#Git介绍" class="headerlink" title="Git介绍"></a>Git介绍</h1><ul>
<li><p>Git 是一个开源的分布式版本控制系统，用于敏捷高效地处理任何或小或大的项目。</p>
</li>
<li><p>Git 是 Linus Torvalds 为了帮助管理 Linux 内核开发而开发的一个开放源码的版本控制软件。</p>
</li>
<li><p>Git 与常用的版本控制工具 CVS, SVN等不同，它采用了分布式版本库的方式，不必服务器端软件支持。</p>
</li>
</ul>
<h1 id="Git安装"><a href="#Git安装" class="headerlink" title="Git安装"></a>Git安装</h1><h2 id="Git下载"><a href="#Git下载" class="headerlink" title="Git下载"></a>Git下载</h2><p>官网下载地址：<a href="https://git-scm.com/downloads">https://git-scm.com/downloads</a></p>
<p>淘宝镜像下载地址：<a href="http://npm.taobao.org/mirrors/git-for-windows/">http://npm.taobao.org/mirrors/git-for-windows/</a></p>
<p>下载exe安装文件</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/5.jpg" style="zoom:67%;" />

<h2 id="Git安装-1"><a href="#Git安装-1" class="headerlink" title="Git安装"></a>Git安装</h2><img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/6.jpg" style="zoom:67%;" />

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/7.jpg" style="zoom:67%;" />

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/8.jpg" style="zoom:67%;" />

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/9.jpg" style="zoom:67%;" />

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/10.jpg" style="zoom:67%;" />

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/11.jpg" style="zoom:67%;" />

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/12.jpg" style="zoom:67%;" />

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/13.jpg" style="zoom:67%;" />

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/14.jpg" style="zoom:67%;" />

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/15.jpg" style="zoom:67%;" />

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/16.jpg" style="zoom:67%;" />

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/17.jpg" style="zoom:67%;" />

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/18.jpg" style="zoom:67%;" />

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/19.jpg" style="zoom:67%;" />

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/20.jpg" style="zoom:67%;" />

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/21.jpg" style="zoom:67%;" />

<p>安装完成后可以在cmd中查看Git对应版本</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line"><span class="function">C:\<span class="title">Users</span>\<span class="title">Labcz</span>&gt;<span class="title">git</span> <span class="title">version</span></span></span><br><span class="line"><span class="function"><span class="title">git</span> <span class="title">version</span> 2.29.2.<span class="title">windows</span>.2</span></span><br></pre></td></tr></table></figure>

<h1 id="Git基本理论"><a href="#Git基本理论" class="headerlink" title="Git基本理论"></a>Git基本理论</h1><h2 id="Git三个工作区域"><a href="#Git三个工作区域" class="headerlink" title="Git三个工作区域"></a>Git三个工作区域</h2><ul>
<li>工作目录（Working Directory）</li>
<li>暂存区(Stage/Index)</li>
<li>资源库(Repository</li>
</ul>
<p>如果拥有远程git仓库(Remote Directory)就可以分为四个工作区域。</p>
<p>文件在这三个区域之间的转换关系如下：</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/22.png" style="zoom:67%;" />

<h2 id="工作流程"><a href="#工作流程" class="headerlink" title="工作流程"></a>工作流程</h2><p>1、在工作目录中添加、修改文件</p>
<p>2、将需要进行版本管理的文件放入暂存区域</p>
<p>3、将暂存区域的文件提交到git仓库</p>
<p>4、git仓库提交到远程仓库</p>
<h1 id="Git基本操作"><a href="#Git基本操作" class="headerlink" title="Git基本操作"></a>Git基本操作</h1><p>Git 常用的是以下 6 个命令：<strong>git clone</strong>、<strong>git push</strong>、<strong>git add</strong> 、<strong>git commit</strong>、<strong>git checkout</strong>、<strong>git pull</strong></p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/operation.jpg" style="zoom:100%;" />

<h2 id="Git-配置"><a href="#Git-配置" class="headerlink" title="Git 配置"></a>Git 配置</h2><p>Git 提供了一个叫做 **git config **的工具，专门用来配置或读取相应的工作环境变量</p>
<p>这些环境变量，决定了 Git 在各个环节的具体工作方式和行为。这些变量可以存放在以下三个不同的地方：</p>
<ul>
<li><code>/etc/gitconfig</code> 文件：系统中对所有用户都普遍适用的配置。若使用 <code>git config</code> 时用 <code>--system</code> 选项，读写的就是这个文件。</li>
<li><code>~/.gitconfig</code> 文件：用户目录下的配置文件只适用于该用户。若使用 <code>git config</code> 时用 <code>--global</code> 选项，读写的就是这个文件。</li>
<li>当前项目的 Git 目录中的配置文件（也就是工作目录中的 <code>.git/config</code> 文件）：这里的配置仅仅针对当前项目有效。每一个级别的配置都会覆盖上层的相同配置，所以 <code>.git/config</code> 里的配置会覆盖 <code>/etc/gitconfig</code> 中的同名变量。</li>
</ul>
<h3 id="配置用户信息"><a href="#配置用户信息" class="headerlink" title="配置用户信息"></a>配置用户信息</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> git config --global user.name <span class="string">&quot;Labcz&quot;</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git config --global user.email <span class="string">&quot;Labcz@test.com&quot;</span></span></span><br></pre></td></tr></table></figure>

<h3 id="查看配置信息"><a href="#查看配置信息" class="headerlink" title="查看配置信息"></a>查看配置信息</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> git config --list</span></span><br></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/28.png" style="zoom:100%;" />



<h2 id="本地仓库搭建"><a href="#本地仓库搭建" class="headerlink" title="本地仓库搭建"></a>本地仓库搭建</h2><p>创建全新的仓库</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> git init</span></span><br></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/23.png" style="zoom:100%;" />

<p>执行后可以在项目李看到多出了一个.git目录，所有 Git 需要的数据和资源都存放在这个目录中</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/24.png" style="zoom:100%;" />

<h2 id="远程仓库导入"><a href="#远程仓库导入" class="headerlink" title="远程仓库导入"></a>远程仓库导入</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">克隆仓库的命令格式:</span><br><span class="line"><span class="meta">$</span><span class="bash"> git <span class="built_in">clone</span> &lt;repo&gt;</span></span><br><span class="line">克隆到指定的目录:</span><br><span class="line"><span class="meta">$</span><span class="bash"> git <span class="built_in">clone</span> &lt;repo&gt; &lt;directory&gt;</span></span><br></pre></td></tr></table></figure>

<p>git clone 时，可以所用不同的协议，包括 ssh, git, https 等</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> git <span class="built_in">clone</span> git@github.com:fsliurujie/test.git         --SSH协议</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git <span class="built_in">clone</span> git://github.com/fsliurujie/test.git          --GIT协议</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git <span class="built_in">clone</span> https://github.com/fsliurujie/test.git      --HTTPS协议</span></span><br></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/33.png" style="zoom:67%;" />

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/34.png" style="zoom:100%;" />

<h2 id="查看仓库状态"><a href="#查看仓库状态" class="headerlink" title="查看仓库状态"></a>查看仓库状态</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> git status</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git status -s <span class="comment">#使用-s参数来获得简短的输出结果</span></span></span><br></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/25.png" style="zoom:100%;" />

<h2 id="暂存文件"><a href="#暂存文件" class="headerlink" title="暂存文件"></a>暂存文件</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> git add &lt;file&gt;</span></span><br></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/26.png" style="zoom:100%;" />

<h2 id="提交文件"><a href="#提交文件" class="headerlink" title="提交文件"></a>提交文件</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> git commit -m <span class="string">&quot;提交描述&quot;</span></span></span><br></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/27.png" style="zoom:100%;" />

<h2 id="提交日志"><a href="#提交日志" class="headerlink" title="提交日志"></a>提交日志</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> git <span class="built_in">log</span>    <span class="comment">#查看历史提交记录</span></span></span><br></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/29.png" style="zoom:100%;" />

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> git blame &lt;file&gt;    <span class="comment">#以列表形式查看指定文件的历史修改记录</span></span></span><br></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/30.png" style="zoom:100%;" />

<h2 id="回退版本"><a href="#回退版本" class="headerlink" title="回退版本"></a>回退版本</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> git reset HEAD^            <span class="comment"># 回退所有内容到上一个版本  </span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git reset HEAD^ hello.java  <span class="comment"># 回退 hello.java 文件的版本到上一个版本  </span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git  reset  052e           <span class="comment"># 回退到指定版本</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> git reset –hard HEAD~3  <span class="comment"># 回退上上上一个版本  </span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git reset –hard bae128  <span class="comment"># 回退到某个版本回退点之前的所有信息。 </span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git reset --hard origin/master    <span class="comment"># 将本地的状态回退到和远程的一样 </span></span></span><br></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/31.png" style="zoom:80%;" />

<p><strong>git reset HEAD 可以取消之前 git add 添加到暂缓区的内容</strong></p>
<h2 id="比较文件的不同"><a href="#比较文件的不同" class="headerlink" title="比较文件的不同"></a>比较文件的不同</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> git diff [file]  <span class="comment">#显示暂存区和工作区的差异</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git diff --cached [file] 显示暂存区和上一次提交(commit)的差异</span></span><br></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/32.png" style="zoom:80%;" />

<h2 id="远程操作"><a href="#远程操作" class="headerlink" title="远程操作"></a>远程操作</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> git remote -v <span class="comment">#查看已加载的远程仓库信息</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git remote show name  <span class="comment">#显示某个远程仓库的信息</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git remote rm name  <span class="comment"># 删除远程仓库</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git remote rename old_name new_name  <span class="comment"># 修改仓库名</span></span></span><br></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/35.png" style="zoom:100%;" />

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/36.png" style="zoom:100%;" />

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> git fetch [<span class="built_in">alias</span>]  <span class="comment">#提取远程仓库更新的数据</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git merge  <span class="comment">#从远端仓库提取数据并尝试合并到当前分支</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git merge [<span class="built_in">alias</span>]/[branch]  <span class="comment">#服务器上的任何更新（其他人推送到服务器）合并到你的当前分支</span></span></span><br></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/37.png" style="zoom:50%;" />

<p>远程添加<code>Labcz&#39;s remote Repository first change</code>内容</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/38.png" style="zoom:50%;" />

<p> <code>a448fb0..037d6e5  main       -&gt; origin/main</code>表明已经被修改</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/39.png" style="zoom:100%;" />

<p>进行文件合并</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/40.png" style="zoom:100%;" />

<p>此时查看本地README.md已经被修改</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/41.png" style="zoom:67%;" />

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> git pull &lt;远程主机名&gt; &lt;远程分支名&gt;:&lt;本地分支名&gt; <span class="comment">#从远程获取代码并合并本地的版本</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash">git pull其实就是git fetch和git merge的简写</span></span><br></pre></td></tr></table></figure>

<p>远程修改README.md内容，添加<code>hello world</code></p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/42.png" style="zoom:67%;" />

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/43.png" style="zoom:67%;" />

<p>此时查看本地README.md已经被修改</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/44.png" style="zoom:50%;" />

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> git push &lt;远程主机名&gt; &lt;本地分支名&gt; <span class="comment">#将本地的分支版本上传到远程并合并</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git push --force origin master  <span class="comment">#强制推送</span></span></span><br></pre></td></tr></table></figure>

<p>在本地项目中新建一个test.txt文件</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/45.png" style="zoom:100%;" />

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/46.png" style="zoom:80%;" />

<p>将会在远程仓库上看到刚刚新建的test.txt文本</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/47.png" style="zoom:80%;" />

<h1 id="远程仓库"><a href="#远程仓库" class="headerlink" title="远程仓库"></a>远程仓库</h1><h2 id="设置本机绑定SSH公钥"><a href="#设置本机绑定SSH公钥" class="headerlink" title="设置本机绑定SSH公钥"></a>设置本机绑定SSH公钥</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> ssh-keygen -t rsa -C <span class="string">&quot;youremail@example.com&quot;</span> <span class="comment">#邮箱是GitHub注册的邮箱</span></span></span><br></pre></td></tr></table></figure>

<p>遇到提示一直回车即可</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/48.png" style="zoom:80%;" />

<p>此时将会在~/下生成一个<code>.shh</code>文件夹</p>
<p><img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/49.png" style="zoom:80%;" /><img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/50.png" style="zoom:80%;" /></p>
<p>新建SSH Key</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/51.png" style="zoom:80%;" />

<p>将<code>.ssh/id_rsa.pub</code>内的内容拷贝到key中</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/52.png" style="zoom:67%;" />

<p>添加成功</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/53.png" style="zoom:67%;" />

<p>输入<code>ssh -T git@github.com</code>测试（需要输入yes）</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/54.png" style="zoom:100%;" />

<h2 id="新建远程仓库"><a href="#新建远程仓库" class="headerlink" title="新建远程仓库"></a>新建远程仓库</h2><img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/55.png" style="zoom:100%;" />

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/56.png" style="zoom:50%;" />

<p>创建远程仓库成功</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/57.png" style="zoom:100%;" />

<p>可根据提示在本地的仓库下运行命令</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">echo</span> <span class="string">&quot;# GitTest&quot;</span> &gt;&gt; README.md <span class="comment">#写入`gitTest`到README.md文件中</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git init <span class="comment">#初始化</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git add README.md <span class="comment">#添加到暂缓区</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git commit -m <span class="string">&quot;first commit&quot;</span> <span class="comment">#提交到本地仓库</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git remote add origin https://github.com/Labcz/GitTest.git <span class="comment">#提交到GitHub</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git push -u origin master</span></span><br></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/58.png" style="zoom:70%;" />

<p>查看远程仓库内容提交成功</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/59.png" style="zoom:100%;" />

<h1 id="分支"><a href="#分支" class="headerlink" title="分支"></a>分支</h1><h2 id="分支简介"><a href="#分支简介" class="headerlink" title="分支简介"></a>分支简介</h2><p>分支，是每个版本最终存储的位置。就是一条<strong>时间线</strong>，每次git commit形成一个个版本，一个个版本依次存储在分支的一个个提交点上。</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/60.png" style="zoom:100%;" />

<p>分支由多个提交点组成，分支上会有一个指针，默认总是指向最新的提交点</p>
<ul>
<li><p><code>master</code>主分支应该非常稳定，用来发布新版本，一般情况下不允许在上面工作</p>
</li>
<li><p>工作一般情况下在新建的<code>dev</code>分支上工作</p>
</li>
<li><p><code>dev</code>分支代码稳定后可以合并到主分支master上来</p>
</li>
</ul>
<h2 id="分支操作命令"><a href="#分支操作命令" class="headerlink" title="分支操作命令"></a>分支操作命令</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> git branch  <span class="comment"># 列出所有本地分支</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> git branch -r  <span class="comment"># 列出所有远程分支</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> git branch [branchname]  <span class="comment"># 新建一个分支，但依然停留在当前分支</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> git checkout [branchname] <span class="comment">#切换分支,Git会用该分支的最后提交的快照替换你的工作目录的内容</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> git checkout -b [branchname]  <span class="comment"># 新建一个分支，并切换到该分支</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> git merge [branchname]  <span class="comment"># 合并指定分支到当前分支</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> git branch -d [branchname] <span class="comment"># 删除分支</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> git push origin --delete [branchname]  <span class="comment"># 删除远程分支</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git branch -dr [branchname]  <span class="comment"># 删除远程分支</span></span></span><br></pre></td></tr></table></figure>

<h2 id="分支操作"><a href="#分支操作" class="headerlink" title="分支操作"></a>分支操作</h2><h3 id="设置测试目录"><a href="#设置测试目录" class="headerlink" title="设置测试目录"></a>设置测试目录</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> mkdir <span class="built_in">test</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">cd</span> <span class="built_in">test</span>/</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git init</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> touch hello.txt</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git add hello.txt</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git commit -m <span class="string">&quot;branch test&quot;</span></span></span><br></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/61.png" style="zoom:100%;" />

<h3 id="查看分支及新建分支"><a href="#查看分支及新建分支" class="headerlink" title="查看分支及新建分支"></a>查看分支及新建分支</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> git branch</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git branch dev</span></span><br></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/62.png" style="zoom:100%;" />

<h3 id="在dev分支下工作"><a href="#在dev分支下工作" class="headerlink" title="在dev分支下工作"></a>在dev分支下工作</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> ls</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">echo</span> <span class="string">&#x27;dev branch test&#x27;</span>&gt;dev.txt</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git add *</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git commit -m <span class="string">&quot;add dev.txt&quot;</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> ls</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git checkout dev</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> ls</span></span><br></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/63.png" style="zoom:100%;" />

<h3 id="合并分支"><a href="#合并分支" class="headerlink" title="合并分支"></a>合并分支</h3><p>一旦某分支有了独立内容，你终究会希望将它合并回到你的主分支</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> git checkout master</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> ls</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git checkout dev</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> ls</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git merge master</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> ls</span></span><br></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/64.png" style="zoom:100%;" />

<h3 id="合并冲突"><a href="#合并冲突" class="headerlink" title="合并冲突"></a>合并冲突</h3><p>在Git中如果在不同分支下修改了同一文件，将会出现合并冲突</p>
<ul>
<li>在master分支下新建文件test.txt</li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/65.png" style="zoom:100%;" />

<ul>
<li>在dev分支下进行上述操作</li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/66.png" style="zoom:100%;" />

<p>此时进行<code>git merge</code>会出先合并冲突</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/67.png" style="zoom:100%;" />

<p>手动进行文件内容修改</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/68.png" style="zoom:100%;" />

<p>通过<code>git add</code>告诉冲突已解决</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/69.png" style="zoom:100%;" />

<h3 id="删除分支"><a href="#删除分支" class="headerlink" title="删除分支"></a>删除分支</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> git branch -d dev <span class="comment">#删除dev分支</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git branch </span></span><br></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/70.png" style="zoom:100%;" />

<h1 id="IDEA关联Git"><a href="#IDEA关联Git" class="headerlink" title="IDEA关联Git"></a>IDEA关联Git</h1><h2 id="关联本机Git应用"><a href="#关联本机Git应用" class="headerlink" title="关联本机Git应用"></a>关联本机Git应用</h2><ul>
<li>进入<code>File-&gt;Settings</code></li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/71.png" style="zoom:67%;" />

<ul>
<li>选择本机安装的Git，可以点击<code>Test</code>进行测试</li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/72.png" style="zoom:50%;" />

<h2 id="初始化Git仓库"><a href="#初始化Git仓库" class="headerlink" title="初始化Git仓库"></a>初始化Git仓库</h2><img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/73.png" style="zoom:100%;" />

<ul>
<li>选择项目目录</li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/74.png" style="zoom:100%;" />

<h2 id="提交commit"><a href="#提交commit" class="headerlink" title="提交commit"></a>提交commit</h2><img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/75.png" style="zoom:67%;" />

<ul>
<li>选择提交内容，并填写commit信息</li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/76.png" style="zoom:50%;" />

<h2 id="创建分支"><a href="#创建分支" class="headerlink" title="创建分支"></a>创建分支</h2><ul>
<li>点击右下角<code> master</code></li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/77.png" style="zoom:100%;" />

<ul>
<li>新建dev分支,并切换到dev分支</li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/78.png" style="zoom:70%;" />

<ul>
<li>此时将显示dev分支</li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/79.png" style="zoom:100%;" />

<h2 id="push到远程仓库"><a href="#push到远程仓库" class="headerlink" title="push到远程仓库"></a>push到远程仓库</h2><ul>
<li>选择<code>VCS -&gt; Git -&gt; Push</code></li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/80.png" style="zoom:50%;" />

<ul>
<li>定义远程仓库</li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/81.png" style="zoom:100%;" />

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/82.png" style="zoom:100%;" />

<ul>
<li>Push</li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/83.png" style="zoom:50%;" />

<ul>
<li>将会在底部看到Push的进度条</li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/84.png" style="zoom:100%;" />

<ul>
<li>提交成功</li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/85.png" style="zoom:100%;" />

<h2 id="复制到本地仓库-clone"><a href="#复制到本地仓库-clone" class="headerlink" title="复制到本地仓库(clone)"></a>复制到本地仓库(clone)</h2><ul>
<li>选择<code>VCS -&gt; Git -&gt; Clone</code></li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/86.png" style="zoom:50%;" />

<ul>
<li>填写远程仓库的URL</li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/88.png" style="zoom:50%;" />

<ul>
<li>在新窗口下打开复制下来的项目</li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/89.png" style="zoom:67%;" />

<h2 id="更新本地项目"><a href="#更新本地项目" class="headerlink" title="更新本地项目"></a>更新本地项目</h2><p>如果远程仓库有更新，则你的本地项目也需要一起更新</p>
<ul>
<li>选择<code>VCS -&gt; Git -&gt; Pull</code></li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/90.png" style="zoom:50%;" />

<ul>
<li>选择想要pull的分支</li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/87.png" style="zoom:70%;" />



<h1 id="多人协同开发"><a href="#多人协同开发" class="headerlink" title="多人协同开发"></a>多人协同开发</h1><h2 id="项目管理员"><a href="#项目管理员" class="headerlink" title="项目管理员"></a>项目管理员</h2><ul>
<li>由管理员负责创建一个远程库，初始的库中什么也没有，为裸库。库的名称建议和项目同名</li>
<li>管理员会在idea中创建一个初始项目,其中包含<code>.gitignore</code>文件.并在项目根目录下建立本地库。并建立 <code>dev </code>分支。</li>
<li>管理员将本地库上传到远程库 </li>
<li>将其他开发人员拉入远程库的 开发成员列表中，使得其他开发人员可以访问该远程库。</li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/91.png" style="zoom:70%;" />

<p>邀请成员</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/92.png" style="zoom:70%;" />

<p>成员接受邀请</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/93.png" style="zoom:70%;" />

<p>测试协同合作</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/94.png" style="zoom:70%;" />

<p>可以添加分支保护(设置保护规则),对master进行保护(只能管理员进行push)</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/95.png" style="zoom:70%;" />

<h2 id="团队成员"><a href="#团队成员" class="headerlink" title="团队成员"></a>团队成员</h2><ul>
<li>初始化：在IDEA中clone 远程库，获得项目，建立本地库</li>
<li>后续的开发中，都要在<code>dev</code>分支上进行。开发完一个功能并测试通过后就commit 提交到本地的<code>dev</code>分支 中，然后 上传(push)到远程<code>dev</code>分支中。 </li>
<li>需要更新项目内容时，通过 pull 从远程仓库拉取内容。 </li>
<li>注意：多人协同时，每次在 push 到远程库前，都先做一次pull，一来是把远程最新内容合并到本地，二 来是核实本地内容是否和远程内容有冲突。 </li>
<li>后续的开发，会接到一个个的功能任务，往复前三步操作即可。</li>
</ul>
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title>使用JAVA的API操作HDFS</title>
    <url>/ckhnafztk0013etfp9stkbq8f.html</url>
    <content><![CDATA[<h1 id="创建IDEA新项目"><a href="#创建IDEA新项目" class="headerlink" title="创建IDEA新项目"></a>创建IDEA新项目</h1><h2 id="创建新MAVEN项目"><a href="#创建新MAVEN项目" class="headerlink" title="创建新MAVEN项目"></a>创建新MAVEN项目</h2><img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/使用JAVA的API操作HDFS/1.png" style="zoom:100%;" />

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/使用JAVA的API操作HDFS/2.png" style="zoom:67%;" />

<h2 id="导入pom-xml"><a href="#导入pom-xml" class="headerlink" title="导入pom.xml"></a>导入pom.xml</h2><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0&quot;</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xmlns:xsi</span>=<span class="string">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xsi:schemaLocation</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.labcz<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>HadoopLearning<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>HadoopLearning<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">project.build.sourceEncoding</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">project.build.sourceEncoding</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">maven.compiler.source</span>&gt;</span>1.7<span class="tag">&lt;/<span class="name">maven.compiler.source</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">maven.compiler.target</span>&gt;</span>1.7<span class="tag">&lt;/<span class="name">maven.compiler.target</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 这里对jar包版本做集中管理 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">hadoop.version</span>&gt;</span>2.7.7<span class="tag">&lt;/<span class="name">hadoop.version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">junit.version</span>&gt;</span>4.12<span class="tag">&lt;/<span class="name">junit.version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- Hadoop客户端依赖，该依赖包含HDFS的相关依赖 --&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- hadoop工具类 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-common<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;hadoop.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- hadoop的客户端,用于访问HDFS --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;hadoop.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-hdfs<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;hadoop.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!-- 单元测试的依赖 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;junit.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">pluginManagement</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-clean-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-resources-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.0.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-compiler-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.8.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-surefire-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.22.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-jar-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.0.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-install-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.5.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-deploy-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.8.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-site-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.7.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-project-info-reports-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.0.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">pluginManagement</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>导入完成后，右击项目Maven-&gt;Reload Project进行解决项目jar包依赖</strong></p>
<h1 id="根据URL读取HDFS文件内容"><a href="#根据URL读取HDFS文件内容" class="headerlink" title="根据URL读取HDFS文件内容"></a>根据URL读取HDFS文件内容</h1><ul>
<li><p>提前准备好一个1.txt文本并上传至HDFS</p>
</li>
<li><p>配置好Windows下hadoop主机映射</p>
<div class="note info flat"><p>修改C:\Windows\System32\drivers\etc\hosts文件,写入对应主机映射</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/使用JAVA的API操作HDFS/hosts.png" style="zoom:67%;" />
</div>
</li>
<li><p>在src/mian/java下创建com.labcz的Package</p>
</li>
<li><p>创建HdfsUrlReader类</p>
</li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/使用JAVA的API操作HDFS/3.png" style="zoom:67%;" />

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.labcz;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FsUrlStreamHandlerFactory;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IOUtils;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.io.InputStream;</span><br><span class="line"><span class="keyword">import</span> java.net.URL;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> Labcz</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@ClassName</span> HdfsUrlReader.java</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span> 根据URL读取文件内容</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@createTime</span> 2020年10月30日 15:54:00</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HdfsUrlReader</span> </span>&#123;</span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        <span class="comment">//通过Java的URL类来访问Hdfs内的文件</span></span><br><span class="line">        URL.setURLStreamHandlerFactory(<span class="keyword">new</span> FsUrlStreamHandlerFactory());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//定义一个JAVA的输入流</span></span><br><span class="line">        InputStream inputStream = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//读取HDFS上的1.txt文件（提前上传到HDFS的/目录下）192.168.229.131为HDFS文件系统地址</span></span><br><span class="line">            inputStream = <span class="keyword">new</span> URL(<span class="string">&quot;hdfs://hadoop01:9000/1.txt&quot;</span>).openStream();</span><br><span class="line">            <span class="comment">//获取输入流，输出到控制台，每次拷贝缓冲区buffer大小，最后是否关闭数据流</span></span><br><span class="line">            IOUtils.copyBytes(inputStream,System.out,<span class="number">1024</span>,<span class="keyword">true</span>);</span><br><span class="line">            System.out.print(<span class="string">&quot;打印完成！&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            <span class="comment">//若出现异常，关闭数据流</span></span><br><span class="line">            IOUtils.closeStream(inputStream);</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>输出结果：</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/使用JAVA的API操作HDFS/4.png" style="zoom:67%;" />

<h1 id="使用FileSystem类访问HDFS"><a href="#使用FileSystem类访问HDFS" class="headerlink" title="使用FileSystem类访问HDFS"></a>使用FileSystem类访问HDFS</h1><ul>
<li>创建FileSystemReader类</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.labcz;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IOUtils;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.io.InputStream;</span><br><span class="line"><span class="keyword">import</span> java.net.URI;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> Labcz</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@ClassName</span> FileSystemReader.java</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span> 使用FileSystem类访问HDFS</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@createTime</span> 2020年10月30日 16:21:00</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FileSystemReader</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="comment">// 会默认读取core-site.xml中的fs.default.name来判断文件系统。如果未设置则默认是本地文件系统</span></span><br><span class="line">        Configuration configuration = <span class="keyword">new</span> Configuration();</span><br><span class="line">        <span class="comment">//定义访问路径</span></span><br><span class="line">        String uri = <span class="string">&quot;hdfs://hadoop01:9000/1.txt&quot;</span>;</span><br><span class="line">        <span class="comment">//定义FileSystem</span></span><br><span class="line">        FileSystem fileSystem = FileSystem.get(URI.create(uri), configuration);</span><br><span class="line">        <span class="comment">//定义输入流</span></span><br><span class="line">        InputStream inputStream = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//将String类型的url地址转换为Path类型，也可以直接定义Path类型路径</span></span><br><span class="line">            inputStream = fileSystem.open(<span class="keyword">new</span> Path(uri));</span><br><span class="line">            <span class="comment">//获取输入流，输出到控制台，每次拷贝缓冲区buffer大小，最后不关闭数据流</span></span><br><span class="line">            IOUtils.copyBytes(inputStream, System.out, <span class="number">4096</span>, <span class="keyword">false</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;<span class="keyword">finally</span> &#123;</span><br><span class="line">            <span class="comment">//关闭数据流</span></span><br><span class="line">            IOUtils.closeStream(inputStream);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>输出结果：</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/使用JAVA的API操作HDFS/5.png" style="zoom:67%;" />

<h1 id="查看HDFS文件-目录元信息"><a href="#查看HDFS文件-目录元信息" class="headerlink" title="查看HDFS文件/目录元信息"></a>查看HDFS文件/目录元信息</h1><ul>
<li>提前准备好一个hello.txt文本并上传至HDFS的/test目录下</li>
<li>创建FileStatusMetadata类</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.labcz;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileStatus;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.net.URI;</span><br><span class="line"><span class="keyword">import</span> java.sql.Timestamp;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> Labcz</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@ClassName</span> FileStatusMetadata.java</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span> 查看HDFS文件/目录元信息</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@createTime</span> 2020年10月30日 16:52:00</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FileStatusMetadata</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="comment">//读取hadoop文件系统的配置</span></span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        conf.set(<span class="string">&quot;fs.defaultFS&quot;</span>,<span class="string">&quot;hdfs://hadoop01:9000&quot;</span>);</span><br><span class="line">        <span class="comment">//把HADOOP_USER_NAME设置成系统的全局变量</span></span><br><span class="line">        System.setProperty(<span class="string">&quot;HADOOP_USER_NAME&quot;</span>,<span class="string">&quot;labcz&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;--------查看HDFS中某文件的元信息--------&quot;</span>);</span><br><span class="line">        String fileURI = <span class="string">&quot;/test/hello.txt&quot;</span>;</span><br><span class="line">        FileSystem fileSystem = FileSystem.get(URI.create(fileURI),conf);</span><br><span class="line">        <span class="comment">//获取文件元信息</span></span><br><span class="line">        FileStatus fileStatus = fileSystem.getFileStatus(<span class="keyword">new</span> Path(fileURI));</span><br><span class="line">        <span class="keyword">if</span>(fileStatus.isDirectory()==<span class="keyword">false</span>)&#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;这是个文件&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(<span class="string">&quot;文件路径: &quot;</span>+fileStatus.getPath());</span><br><span class="line">        System.out.println(<span class="string">&quot;文件长度: &quot;</span>+fileStatus.getLen());</span><br><span class="line">        System.out.println(<span class="string">&quot;文件修改日期： &quot;</span>+<span class="keyword">new</span> Timestamp(fileStatus.getModificationTime()).toString());</span><br><span class="line">        System.out.println(<span class="string">&quot;文件上次访问日期： &quot;</span>+<span class="keyword">new</span> Timestamp(fileStatus.getAccessTime()).toString());</span><br><span class="line">        System.out.println(<span class="string">&quot;文件备份数： &quot;</span>+fileStatus.getReplication());</span><br><span class="line">        System.out.println(<span class="string">&quot;文件的块大小： &quot;</span>+fileStatus.getBlockSize());</span><br><span class="line">        System.out.println(<span class="string">&quot;文件所有者：  &quot;</span>+fileStatus.getOwner());</span><br><span class="line">        System.out.println(<span class="string">&quot;文件所在的分组： &quot;</span>+fileStatus.getGroup());</span><br><span class="line">        System.out.println(<span class="string">&quot;文件的 权限： &quot;</span>+fileStatus.getPermission().toString());</span><br><span class="line">        System.out.println();</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">&quot;--------查看HDFS中某文件的元信息--------&quot;</span>);</span><br><span class="line">        String dirURI = <span class="string">&quot;/test&quot;</span>;</span><br><span class="line">        FileSystem dirFS = FileSystem.get(URI.create(dirURI) ,conf);</span><br><span class="line">        FileStatus dirStatus = dirFS.getFileStatus(<span class="keyword">new</span> Path(dirURI));</span><br><span class="line">        <span class="comment">//获取目录的元信息</span></span><br><span class="line">        <span class="keyword">if</span>(dirStatus.isDir()==<span class="keyword">true</span>)&#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;这是个目录&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(<span class="string">&quot;目录路径: &quot;</span>+dirStatus.getPath());</span><br><span class="line">        System.out.println(<span class="string">&quot;目录长度: &quot;</span>+dirStatus.getLen());</span><br><span class="line">        System.out.println(<span class="string">&quot;目录修改日期： &quot;</span>+<span class="keyword">new</span> Timestamp (dirStatus.getModificationTime()).toString());</span><br><span class="line">        System.out.println(<span class="string">&quot;目录上次访问日期： &quot;</span>+<span class="keyword">new</span> Timestamp(dirStatus.getAccessTime()).toString());</span><br><span class="line">        System.out.println(<span class="string">&quot;目录备份数： &quot;</span>+dirStatus.getReplication());</span><br><span class="line">        System.out.println(<span class="string">&quot;目录的块大小： &quot;</span>+dirStatus.getBlockSize());</span><br><span class="line">        System.out.println(<span class="string">&quot;目录所有者：  &quot;</span>+dirStatus.getOwner());</span><br><span class="line">        System.out.println(<span class="string">&quot;目录所在的分组： &quot;</span>+dirStatus.getGroup());</span><br><span class="line">        System.out.println(<span class="string">&quot;目录的 权限： &quot;</span>+dirStatus.getPermission().toString());</span><br><span class="line">        System.out.println(<span class="string">&quot;这个目录下包含以下文件或目录：&quot;</span>);</span><br><span class="line">        FileStatus[] fsList = dirFS.listStatus(<span class="keyword">new</span> Path(dirURI));</span><br><span class="line">        <span class="keyword">for</span>(FileStatus fs : fsList)&#123;</span><br><span class="line">            System.out.println(fs.getPath());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>输出结果：</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/使用JAVA的API操作HDFS/6.png" style="zoom:67%;" />

<h1 id="查找某个文件在HDFS集群的位置"><a href="#查找某个文件在HDFS集群的位置" class="headerlink" title="查找某个文件在HDFS集群的位置"></a>查找某个文件在HDFS集群的位置</h1><ul>
<li>创建BlockLocationTest类</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.labcz;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.BlockLocation;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileStatus;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.net.URI;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> Labcz</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@ClassName</span> BlockLocationTest.java</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span> 查找某个文件在HDFS集群的位置</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@createTime</span> 2020年10月30日 17:40:00</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BlockLocationTest</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        Configuration conf=<span class="keyword">new</span> Configuration();</span><br><span class="line">        conf.set(<span class="string">&quot;fs.defaultFS&quot;</span>,<span class="string">&quot;hdfs://hadoop01:9000&quot;</span>);</span><br><span class="line">        String fileURI = <span class="string">&quot;/test/hello.txt&quot;</span>;</span><br><span class="line">        FileSystem fileSystem = FileSystem.get(URI.create(fileURI),conf);</span><br><span class="line">        <span class="comment">//获取文件元信息</span></span><br><span class="line">        FileStatus fileStatus = fileSystem.getFileStatus(<span class="keyword">new</span> Path(fileURI));</span><br><span class="line">        BlockLocation[] blockLocations = fileSystem.getFileBlockLocations(fileStatus, <span class="number">0</span>, fileStatus.getLen());</span><br><span class="line">        <span class="keyword">int</span> blockLen = blockLocations.length;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;blockLen;i++)&#123;</span><br><span class="line">            String[] hosts = blockLocations[i].getHosts();</span><br><span class="line">            <span class="comment">//其中hosts[0]离自己最近</span></span><br><span class="line">            System.out.println(<span class="string">&quot;block_&quot;</span>+i+<span class="string">&quot;_location hosts[0]:&quot;</span>+hosts[<span class="number">0</span>]);</span><br><span class="line">            System.out.println(<span class="string">&quot;block_&quot;</span>+i+<span class="string">&quot;_location hosts[1]:&quot;</span>+hosts[<span class="number">1</span>]);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>输出结果：</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/使用JAVA的API操作HDFS/7.png" style="zoom:100%;" />

<h1 id="文件上传-下载"><a href="#文件上传-下载" class="headerlink" title="文件上传/下载"></a>文件上传/下载</h1><ul>
<li>创建HdfsDataInput类</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.labcz;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IOUtils;</span><br><span class="line"><span class="keyword">import</span> org.apache.log4j.Logger;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"><span class="keyword">import</span> java.net.URI;</span><br><span class="line"><span class="keyword">import</span> java.net.URL;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> Labcz</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@ClassName</span> HdfsDataInput.java</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span> 本地文件上传到HDFS,以及从HDFS上将文件下载到本地</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@createTime</span> 2020年10月30日 19:13:00</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HdfsDataInput</span> </span>&#123;</span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">final</span> Logger logger = Logger.getLogger(HdfsDataInput.class);</span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        URL.setURLStreamHandlerFactory(<span class="keyword">new</span> FsUrlStreamHandlerFactory());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        HdfsDataInput hdi = <span class="keyword">new</span> HdfsDataInput();</span><br><span class="line">        <span class="comment">//将本地桌面上的2.txt文件上传到HDFS的/2.txt</span></span><br><span class="line">        hdi.createFile(<span class="string">&quot;C:/Users/Labcz/Desktop/2.txt&quot;</span>, <span class="string">&quot;/2.txt&quot;</span>);</span><br><span class="line">        <span class="comment">//将HDFS上的/1.txt文件上获取到本地桌面的1.txt,并且打印1.txt的内容</span></span><br><span class="line">       <span class="comment">// hdi.getFile(&quot;C:/Users/Labcz/Desktop/1.txt&quot;, &quot;/1.txt&quot;,true);</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@function</span> 将本地文件上传到HDFS上</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> localPath 本地文件路径</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> hdfsPath  HDFS目标文件路径</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">createFile</span><span class="params">(String localPath,String hdfsPath)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//定义输入流</span></span><br><span class="line">        InputStream in = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">//通用三步骤</span></span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        conf.set(<span class="string">&quot;fs.defaultFS&quot;</span>,<span class="string">&quot;hdfs://hadoop01:9000&quot;</span>);</span><br><span class="line">        FileSystem fileSystem = FileSystem.get(URI.create(hdfsPath), conf);</span><br><span class="line">        <span class="comment">//在HDFS上创建空文件</span></span><br><span class="line">        FSDataOutputStream out = fileSystem.create(<span class="keyword">new</span> Path(hdfsPath));</span><br><span class="line">        in = <span class="keyword">new</span> BufferedInputStream(<span class="keyword">new</span> FileInputStream(<span class="keyword">new</span> File(localPath)));</span><br><span class="line">        <span class="comment">//将文件进行拷贝，从输入流到输出流</span></span><br><span class="line">        IOUtils.copyBytes(in, out, <span class="number">4096</span>, <span class="keyword">false</span>);</span><br><span class="line">        out.hsync();</span><br><span class="line">        out.close();</span><br><span class="line">        logger.info(<span class="string">&quot;create file in hdfs:&quot;</span> + hdfsPath);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;<span class="keyword">finally</span> &#123;</span><br><span class="line">            IOUtils.closeStream(in);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     *<span class="doctag">@function</span>  从HDFS获取文件，并拷贝到本地localPath</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> localPath 本地目标文件路径</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> hdfsPath  HDFS文件路径</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> print  是否将文件内容同时打印到控制台</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">getFile</span><span class="params">(String localPath,String hdfsPath,<span class="keyword">boolean</span> print)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="comment">//通用三步骤</span></span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        conf.set(<span class="string">&quot;fs.defaultFS&quot;</span>,<span class="string">&quot;hdfs://hadoop01:9000&quot;</span>);</span><br><span class="line">        FileSystem fileSystem = FileSystem.get(URI.create(hdfsPath), conf);</span><br><span class="line">        <span class="comment">//定义输入输出流</span></span><br><span class="line">        FSDataInputStream in = fileSystem.open(<span class="keyword">new</span> Path(hdfsPath));</span><br><span class="line">        OutputStream out = <span class="keyword">new</span> BufferedOutputStream(<span class="keyword">new</span> FileOutputStream(<span class="keyword">new</span> File(localPath)));</span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">            <span class="comment">//进行文件拷贝</span></span><br><span class="line">            IOUtils.copyBytes(in,out,<span class="number">4096</span>,!print);</span><br><span class="line">            logger.info(<span class="string">&quot;get file form hdfs to local: &quot;</span> + hdfsPath + <span class="string">&quot;, &quot;</span> + localPath);</span><br><span class="line">            <span class="keyword">if</span> (print) &#123;</span><br><span class="line">                in.seek(<span class="number">0</span>);  <span class="comment">//输入流从新回到文件开始的位置</span></span><br><span class="line">                IOUtils.copyBytes(in, System.out, <span class="number">4096</span>, <span class="keyword">true</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//关闭输出流，否则文件内容可能为空</span></span><br><span class="line">            out.close();</span><br><span class="line">        &#125;<span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;<span class="keyword">finally</span> &#123;</span><br><span class="line">            IOUtils.closeStream(in);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>输出结果：</p>
<p>（1）通过<code>hdfs dfs -ls /</code>查看HDFS上已存在的文件</p>
<p>（2）下载到本地的文件可以之间查看内容</p>
<h1 id="在Linux上进行文件上传-下载"><a href="#在Linux上进行文件上传-下载" class="headerlink" title="在Linux上进行文件上传/下载"></a>在Linux上进行文件上传/下载</h1><ul>
<li>创建HdfsDataInputOnLinux类</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.labcz;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IOUtils;</span><br><span class="line"><span class="keyword">import</span> org.apache.log4j.Logger;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"><span class="keyword">import</span> java.net.URI;</span><br><span class="line"><span class="keyword">import</span> java.net.URL;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> Labcz</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@ClassName</span> HdfsDataInputOnLinux.java</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span> TODO</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@createTime</span> 2020年10月30日 21:18:00</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HdfsDataInputOnLinux</span> </span>&#123;</span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">final</span> Logger logger = Logger.getLogger(HdfsDataInput.class);</span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        URL.setURLStreamHandlerFactory(<span class="keyword">new</span> FsUrlStreamHandlerFactory());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        HdfsDataInputOnLinux hdiol = <span class="keyword">new</span> HdfsDataInputOnLinux();</span><br><span class="line">        String cmd = args[<span class="number">0</span>];</span><br><span class="line">        String localPath = args[<span class="number">1</span>];</span><br><span class="line">        String hdfsPath = args[<span class="number">2</span>];</span><br><span class="line">        <span class="keyword">if</span> (cmd.equals(<span class="string">&quot;create&quot;</span>)) &#123;</span><br><span class="line">            hdiol.createFile(localPath, hdfsPath);</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (cmd.equals(<span class="string">&quot;get&quot;</span>)) &#123;</span><br><span class="line">            <span class="keyword">boolean</span> print = Boolean.parseBoolean(args[<span class="number">3</span>]);</span><br><span class="line">            hdiol.getFile(localPath, hdfsPath, print);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@function</span> 将本地文件上传到HDFS上</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> localPath 本地文件路径</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> hdfsPath  HDFS目标文件路径</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">createFile</span><span class="params">(String localPath,String hdfsPath)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//定义输入流</span></span><br><span class="line">        InputStream in = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//通用三步骤</span></span><br><span class="line">            Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">            conf.set(<span class="string">&quot;fs.defaultFS&quot;</span>,<span class="string">&quot;hdfs://hadoop01:9000&quot;</span>);</span><br><span class="line">            FileSystem fileSystem = FileSystem.get(URI.create(hdfsPath), conf);</span><br><span class="line">            <span class="comment">//在HDFS上创建空文件</span></span><br><span class="line">            FSDataOutputStream out = fileSystem.create(<span class="keyword">new</span> Path(hdfsPath));</span><br><span class="line">            in = <span class="keyword">new</span> BufferedInputStream(<span class="keyword">new</span> FileInputStream(<span class="keyword">new</span> File(localPath)));</span><br><span class="line">            <span class="comment">//将文件进行拷贝，从输入流到输出流</span></span><br><span class="line">            IOUtils.copyBytes(in, out, <span class="number">4096</span>, <span class="keyword">false</span>);</span><br><span class="line">            out.hsync();</span><br><span class="line">            out.close();</span><br><span class="line">            logger.info(<span class="string">&quot;create file in hdfs:&quot;</span> + hdfsPath);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;<span class="keyword">finally</span> &#123;</span><br><span class="line">            IOUtils.closeStream(in);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     *<span class="doctag">@function</span>  从HDFS获取文件，并拷贝到本地localPath</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> localPath 本地目标文件路径</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> hdfsPath  HDFS文件路径</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> print  是否将文件内容同时打印到控制台</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">getFile</span><span class="params">(String localPath,String hdfsPath,<span class="keyword">boolean</span> print)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="comment">//通用三步骤</span></span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        conf.set(<span class="string">&quot;fs.defaultFS&quot;</span>,<span class="string">&quot;hdfs://hadoop01:9000&quot;</span>);</span><br><span class="line">        FileSystem fileSystem = FileSystem.get(URI.create(hdfsPath), conf);</span><br><span class="line">        <span class="comment">//定义输入输出流</span></span><br><span class="line">        FSDataInputStream in = fileSystem.open(<span class="keyword">new</span> Path(hdfsPath));</span><br><span class="line">        OutputStream out = <span class="keyword">new</span> BufferedOutputStream(<span class="keyword">new</span> FileOutputStream(<span class="keyword">new</span> File(localPath)));</span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">            <span class="comment">//进行文件拷贝</span></span><br><span class="line">            IOUtils.copyBytes(in,out,<span class="number">4096</span>,!print);</span><br><span class="line">            logger.info(<span class="string">&quot;get file form hdfs to local: &quot;</span> + hdfsPath + <span class="string">&quot;, &quot;</span> + localPath);</span><br><span class="line">            <span class="keyword">if</span> (print) &#123;</span><br><span class="line">                in.seek(<span class="number">0</span>);  <span class="comment">//输入流从新回到文件开始的位置</span></span><br><span class="line">                IOUtils.copyBytes(in, System.out, <span class="number">4096</span>, <span class="keyword">true</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//关闭输出流，否则文件内容可能为空</span></span><br><span class="line">            out.close();</span><br><span class="line">        &#125;<span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;<span class="keyword">finally</span> &#123;</span><br><span class="line">            IOUtils.closeStream(in);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>将项目打包成jar包：点击右侧Maven图标，依次点击Lifecycle-&gt;clean,  Lifecycle-&gt;package</strong></p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/使用JAVA的API操作HDFS/8.png" style="zoom:67%;" />

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/使用JAVA的API操作HDFS/9.png" style="zoom:100%;" />

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/使用JAVA的API操作HDFS/10.png" style="zoom:100%;" />

<p><strong>将会在右侧的target目录下看到以打成功的jar包</strong></p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/使用JAVA的API操作HDFS/11.png" style="zoom:78%;" />

<p><strong>将jar包拷贝至Linux的~目录下</strong></p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/使用JAVA的API操作HDFS/12.png" style="zoom:78%;" />

<p><strong>拷贝HdfsDataInputOnLinux的完整路径：右击该类-&gt;Copy-&gt;Copy Reference</strong></p>
<p><strong>获得该类的完整路径：com.labcz.HdfsDataInputOnLinux</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">//创建upload.txt文件用于测试文件上传与下载功能</span><br><span class="line">[liujiazhao@hadoop01 ~]$ echo &quot;Upload On Linux Test&quot; &gt;upload.txt</span><br><span class="line">[liujiazhao@hadoop01 ~]$ cat upload.txt </span><br><span class="line">Upload On Linux Test</span><br></pre></td></tr></table></figure>

<p><strong>执行文件上传命令：</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[liujiazhao@hadoop01 ~]$ hadoop jar HadoopLearning-1.0-SNAPSHOT.jar com.labcz.HdfsDataInputOnLinux create upload.txt /upload.txt</span><br></pre></td></tr></table></figure>

<p><strong>使用<code>hdfs dfs -cat /upload.txt</code>查看文件内容，检查是否上传成功</strong></p>
<p><strong>执行文件下载命令：</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[liujiazhao@hadoop01 ~]$ hadoop jar HadoopLearning-1.0-SNAPSHOT.jar com.labcz.HdfsDataInputOnLinux get /home/liujiazhao/1.txt /1.txt true</span><br></pre></td></tr></table></figure>

<p><strong>使用<code>cat /home/liujiazhao/1.txt</code>查看文件内容，检查是否下载成功</strong></p>
<h1 id="文件上传显示进度条"><a href="#文件上传显示进度条" class="headerlink" title="文件上传显示进度条"></a>文件上传显示进度条</h1><ul>
<li>准备一张较大的图片1.jpg进行实验，便于显示进度条显示过程</li>
<li>创建FileCopyWithProgress类</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.labcz;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IOUtils;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.util.Progressable;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"><span class="keyword">import</span> java.net.URI;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> Labcz</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@ClassName</span> FileCopyWithProgress.java</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span>  文件上传显示进度条</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@createTime</span> 2020年10月30日 21:58:00</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FileCopyWithProgress</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        String localURI = <span class="string">&quot;C:/Users/Labcz/Desktop/1.jpg&quot;</span>;</span><br><span class="line">        String destURI = <span class="string">&quot;/1.jpg&quot;</span>;</span><br><span class="line">        InputStream in =<span class="keyword">new</span> BufferedInputStream(<span class="keyword">new</span> FileInputStream(localURI));</span><br><span class="line">        <span class="comment">//通用三步骤</span></span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        conf.set(<span class="string">&quot;fs.defaultFS&quot;</span>,<span class="string">&quot;hdfs://hadoop01:9000&quot;</span>);</span><br><span class="line">        FileSystem fileSystem = FileSystem.get(URI.create(destURI), conf);</span><br><span class="line">        <span class="comment">//在输出流中定义进度条</span></span><br><span class="line">        OutputStream out = fileSystem.create(<span class="keyword">new</span> Path(destURI), <span class="keyword">new</span> Progressable() &#123;</span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">progress</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                System.out.print(<span class="string">&quot;.&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        IOUtils.copyBytes(in, out, <span class="number">4096</span>, <span class="keyword">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>输出结果：</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/使用JAVA的API操作HDFS/13.png" style="zoom:78%;" />

<h1 id="在Linux上文件上传显示进度条"><a href="#在Linux上文件上传显示进度条" class="headerlink" title="在Linux上文件上传显示进度条"></a>在Linux上文件上传显示进度条</h1><ul>
<li>准备一张较大的图片1.jpg进行实验，便于显示进度条显示过程</li>
<li>创建FileCopyWithProgressOnLinux类</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.labcz;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IOUtils;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.util.Progressable;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.BufferedInputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.FileInputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.InputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.OutputStream;</span><br><span class="line"><span class="keyword">import</span> java.net.URI;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> Labcz</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@ClassName</span> FileCopyWithProgressOnLinux.java</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span> 在Linux上文件上传显示进度条</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@createTime</span> 2020年10月30日 22:19:00</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FileCopyWithProgressOnLinux</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        String localURI = <span class="string">&quot;&quot;</span>;</span><br><span class="line">        String destURI = <span class="string">&quot;&quot;</span>;</span><br><span class="line">        <span class="keyword">if</span>(args.length&gt;=<span class="number">2</span>)&#123;</span><br><span class="line">            localURI = args[<span class="number">0</span>];</span><br><span class="line">            destURI = args[<span class="number">1</span>];</span><br><span class="line">        &#125;</span><br><span class="line">        InputStream in =<span class="keyword">new</span> BufferedInputStream(<span class="keyword">new</span> FileInputStream(localURI));</span><br><span class="line">        <span class="comment">//通用三步骤</span></span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        conf.set(<span class="string">&quot;fs.defaultFS&quot;</span>,<span class="string">&quot;hdfs://hadoop01:9000&quot;</span>);</span><br><span class="line">        FileSystem fileSystem = FileSystem.get(URI.create(destURI), conf);</span><br><span class="line">        <span class="comment">//在输出流中定义进度条</span></span><br><span class="line">        OutputStream out = fileSystem.create(<span class="keyword">new</span> Path(destURI), <span class="keyword">new</span> Progressable() &#123;</span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">progress</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                System.out.print(<span class="string">&quot;.&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        IOUtils.copyBytes(in, out, <span class="number">4096</span>, <span class="keyword">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>遵循之前生成导入jar包过程</strong></p>
<p><strong>执行命令：</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[liujiazhao@hadoop01 ~]$ hadoop jar HadoopLearning-1.0-SNAPSHOT.jar com.labcz.FileCopyWithProgressOnLinux 1.jpg /1.jpg</span><br></pre></td></tr></table></figure>

<p><strong>执行结果：将出现进度条，且文件成功上传</strong></p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/使用JAVA的API操作HDFS/14.png" style="zoom:78%;" />

<h1 id="读取HDFS某个目录下的所有文件"><a href="#读取HDFS某个目录下的所有文件" class="headerlink" title="读取HDFS某个目录下的所有文件"></a>读取HDFS某个目录下的所有文件</h1><ul>
<li>新建ListAllFile类</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.labcz;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileStatus;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileUtil;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.net.URI;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> Labcz</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@ClassName</span> ListAllFile.java</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span> 读取HDFS某个目录下的所有文件</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@createTime</span> 2020年10月30日 23:07:00</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ListAllFile</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="comment">//目标文件夹路径</span></span><br><span class="line">        String uri = <span class="string">&quot;/test&quot;</span>;</span><br><span class="line">        <span class="comment">//通用三步骤</span></span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        conf.set(<span class="string">&quot;fs.defaultFS&quot;</span>,<span class="string">&quot;hdfs://hadoop01:9000&quot;</span>);</span><br><span class="line">        FileSystem fileSystem = FileSystem.get(URI.create(uri), conf);</span><br><span class="line"></span><br><span class="line">        Path[] paths = <span class="keyword">new</span> Path[<span class="number">1</span>];</span><br><span class="line">        paths[<span class="number">0</span>] = <span class="keyword">new</span> Path(uri);</span><br><span class="line">        FileStatus[] status = fileSystem.listStatus(paths);</span><br><span class="line">        <span class="keyword">for</span> (FileStatus p : status) &#123;</span><br><span class="line">            System.out.println(p);</span><br><span class="line">        &#125;</span><br><span class="line">        Path[] listedPaths = FileUtil.stat2Paths(status);</span><br><span class="line">        <span class="keyword">for</span> (Path p : listedPaths) &#123;</span><br><span class="line">            System.out.println(p);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>输出结果：</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/使用JAVA的API操作HDFS/16.png" style="zoom:78%;" />

<h1 id="在Linux上读取HDFS某个目录下的所有文件"><a href="#在Linux上读取HDFS某个目录下的所有文件" class="headerlink" title="在Linux上读取HDFS某个目录下的所有文件"></a>在Linux上读取HDFS某个目录下的所有文件</h1><ul>
<li>新建ListAllFileOnLinux类</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.labcz;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileStatus;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileUtil;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.net.URI;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> Labcz</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@ClassName</span> ListAllFileOnLinux.java</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span> 在Linux上读取HDFS某个目录下的所有文件</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@createTime</span> 2020年10月30日 22:30:00</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ListAllFileOnLinux</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        String uri = args[<span class="number">0</span>];</span><br><span class="line">        <span class="comment">//通用三步骤</span></span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        conf.set(<span class="string">&quot;fs.defaultFS&quot;</span>,<span class="string">&quot;hdfs://hadoop01:9000&quot;</span>);</span><br><span class="line">        FileSystem fileSystem = FileSystem.get(URI.create(uri), conf);</span><br><span class="line"></span><br><span class="line">        Path[] paths = <span class="keyword">new</span> Path[args.length];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; paths.length; i++) &#123;</span><br><span class="line">            paths[i] = <span class="keyword">new</span> Path(args[i]);</span><br><span class="line">        &#125;</span><br><span class="line">        FileStatus[] status = fileSystem.listStatus(paths);</span><br><span class="line">        <span class="keyword">for</span> (FileStatus p : status) &#123;</span><br><span class="line">            System.out.println(p);</span><br><span class="line">        &#125;</span><br><span class="line">        Path[] listedPaths = FileUtil.stat2Paths(status);</span><br><span class="line">        <span class="keyword">for</span> (Path p : listedPaths) &#123;</span><br><span class="line">            System.out.println(p);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>遵循之前生成导入jar包过程</strong></p>
<p><strong>执行命令：</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[liujiazhao@hadoop01 ~]$ hadoop jar HadoopLearning-1.0-SNAPSHOT.jar com.labcz.ListAllFileOnLinux /test</span><br></pre></td></tr></table></figure>

<p><strong>执行结果：显示目标路径下的各文件内容</strong></p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/使用JAVA的API操作HDFS/15.png" style="zoom:78%;" />

<h1 id="编写HDFS的API"><a href="#编写HDFS的API" class="headerlink" title="编写HDFS的API"></a>编写HDFS的API</h1><ul>
<li>创建com.api包</li>
<li>在该包下新建HdfsJavaApi类，并构建该API的基础框架</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.api;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.File;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.net.URI;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> Labcz</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@ClassName</span> HdfsJavaApi.java</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span> 对文件上传下载、修改、删除、查看等等操作</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@createTime</span> 2020年10月30日 23:14:00</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HdfsJavaApi</span> </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@function</span> 从HDFS上获取文件到本地</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> fileSystem    传入DFS文件系统</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> hdfsPathStr   HDFS文件路径</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> localPathStr   本地文件路径</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">getFile</span><span class="params">(FileSystem fileSystem,String hdfsPathStr,String localPathStr)</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@function</span> 将本地文件上传到文件系统</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> fileSystem    传入DFS文件系统</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> hdfsPathStr   HDFS文件路径</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> localPathStr  本地文件路径</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">putFile</span><span class="params">(FileSystem fileSystem,String hdfsPathStr,String localPathStr)</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@function</span> 删除文件</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> fileSystem    传入DFS文件系统</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> hdfsPathStr   HDFS文件路径</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">delFile</span><span class="params">(FileSystem fileSystem,String hdfsPathStr)</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@function</span> 列出路径下全部文件内容</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> fileSystem    传入DFS文件系统</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> hdfsPathStr   HDFS目录</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">listFile</span><span class="params">(FileSystem fileSystem,String hdfsPathStr)</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        String uri = args[<span class="number">0</span>];</span><br><span class="line">        <span class="comment">//通用三步骤</span></span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        conf.set(<span class="string">&quot;fs.defaultFS&quot;</span>,<span class="string">&quot;hdfs://hadoop01:9000&quot;</span>);</span><br><span class="line">        FileSystem fileSystem = FileSystem.get(URI.create(uri), conf);</span><br><span class="line">        HdfsJavaApi hdfsJavaApi =<span class="keyword">new</span> HdfsJavaApi();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>编写getFile下载函数</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">getFile</span><span class="params">(FileSystem fileSystem,String hdfsPathStr,String localPathStr)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    <span class="comment">//定义输入输出流</span></span><br><span class="line">    FSDataInputStream in = fileSystem.open(<span class="keyword">new</span> Path(hdfsPathStr));</span><br><span class="line">    OutputStream out = <span class="keyword">new</span> BufferedOutputStream(<span class="keyword">new</span> FileOutputStream(<span class="keyword">new</span> File(localPathStr)));</span><br><span class="line">    <span class="keyword">try</span>&#123;</span><br><span class="line">        <span class="comment">//进行文件拷贝</span></span><br><span class="line">        IOUtils.copyBytes(in,out,<span class="number">4096</span>,<span class="keyword">false</span>);</span><br><span class="line">        in.seek(<span class="number">0</span>);  <span class="comment">//输入流从新回到文件开始的位置</span></span><br><span class="line">        IOUtils.copyBytes(in, System.out, <span class="number">4096</span>, <span class="keyword">true</span>);</span><br><span class="line">        <span class="comment">//关闭输出流，否则文件内容可能为空</span></span><br><span class="line">        out.close();</span><br><span class="line">    &#125;<span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;<span class="keyword">finally</span> &#123;</span><br><span class="line">        IOUtils.closeStream(in);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>编写putFile上传函数</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">putFile</span><span class="params">(FileSystem fileSystem,String hdfsPathStr,String localPathStr)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="comment">//在HDFS上创建空文件</span></span><br><span class="line">        FSDataOutputStream out = fileSystem.create(<span class="keyword">new</span> Path(hdfsPathStr));</span><br><span class="line">        InputStream in = <span class="keyword">new</span> BufferedInputStream(<span class="keyword">new</span> FileInputStream(<span class="keyword">new</span> File(localPathStr)));</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//将文件进行拷贝，从输入流到输出流</span></span><br><span class="line">            IOUtils.copyBytes(in, out, <span class="number">4096</span>, <span class="keyword">false</span>);</span><br><span class="line">            out.close();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;<span class="keyword">finally</span> &#123;</span><br><span class="line">            IOUtils.closeStream(in);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>编写delFile删除函数</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">delFile</span><span class="params">(FileSystem fileSystem,String hdfsPathStr,<span class="keyword">boolean</span> recursive)</span></span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">//true：开启级联删除，将删除目录下的全部内容</span></span><br><span class="line">        fileSystem.delete(<span class="keyword">new</span> Path(hdfsPathStr),recursive);</span><br><span class="line">        System.out.println(<span class="string">&quot;DELETE SUCCESSFULLY&quot;</span>);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>编写listFile列表函数</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">listFile</span><span class="params">(FileSystem fileSystem,String hdfsPathStr)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    Path[] paths = <span class="keyword">new</span> Path[<span class="number">1</span>];</span><br><span class="line">    paths[<span class="number">0</span>] = <span class="keyword">new</span> Path(hdfsPathStr);</span><br><span class="line">    FileStatus[] status = fileSystem.listStatus(paths);</span><br><span class="line">    <span class="keyword">for</span> (FileStatus p : status) &#123;</span><br><span class="line">        System.out.println(p);</span><br><span class="line">    &#125;</span><br><span class="line">    Path[] listedPaths = FileUtil.stat2Paths(status);</span><br><span class="line">    <span class="keyword">for</span> (Path p : listedPaths) &#123;</span><br><span class="line">        System.out.println(p);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>完整HDFS API</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.api;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IOUtils;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"><span class="keyword">import</span> java.net.URI;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> Labcz</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@ClassName</span> HdfsJavaApi.java</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span> 对文件上传下载、修改、删除、查看等等操作</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@createTime</span> 2020年10月30日 23:14:00</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HdfsJavaApi</span> </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@function</span> 从HDFS上获取文件到本地</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> fileSystem    传入DFS文件系统</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> hdfsPathStr   HDFS文件路径</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> localPathStr   本地文件路径</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">getFile</span><span class="params">(FileSystem fileSystem,String hdfsPathStr,String localPathStr)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="comment">//定义输入输出流</span></span><br><span class="line">        FSDataInputStream in = fileSystem.open(<span class="keyword">new</span> Path(hdfsPathStr));</span><br><span class="line">        OutputStream out = <span class="keyword">new</span> BufferedOutputStream(<span class="keyword">new</span> FileOutputStream(<span class="keyword">new</span> File(localPathStr)));</span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">            <span class="comment">//进行文件拷贝</span></span><br><span class="line">            IOUtils.copyBytes(in,out,<span class="number">4096</span>,<span class="keyword">false</span>);</span><br><span class="line">            in.seek(<span class="number">0</span>);  <span class="comment">//输入流从新回到文件开始的位置</span></span><br><span class="line">            IOUtils.copyBytes(in, System.out, <span class="number">4096</span>, <span class="keyword">true</span>);</span><br><span class="line">            <span class="comment">//关闭输出流，否则文件内容可能为空</span></span><br><span class="line">            out.close();</span><br><span class="line">            System.out.println(<span class="string">&quot;GET SUCCESSFULLY&quot;</span>);</span><br><span class="line">        &#125;<span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;<span class="keyword">finally</span> &#123;</span><br><span class="line">            IOUtils.closeStream(in);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@function</span> 将本地文件上传到文件系统</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> fileSystem    传入DFS文件系统</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> hdfsPathStr   HDFS文件路径</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> localPathStr  本地文件路径</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">putFile</span><span class="params">(FileSystem fileSystem,String hdfsPathStr,String localPathStr)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="comment">//在HDFS上创建空文件</span></span><br><span class="line">        FSDataOutputStream out = fileSystem.create(<span class="keyword">new</span> Path(hdfsPathStr));</span><br><span class="line">        InputStream in = <span class="keyword">new</span> BufferedInputStream(<span class="keyword">new</span> FileInputStream(<span class="keyword">new</span> File(localPathStr)));</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//将文件进行拷贝，从输入流到输出流</span></span><br><span class="line">            IOUtils.copyBytes(in, out, <span class="number">4096</span>, <span class="keyword">false</span>);</span><br><span class="line">            out.close();</span><br><span class="line">            System.out.println(<span class="string">&quot;PUT SUCCESSFULLY&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;<span class="keyword">finally</span> &#123;</span><br><span class="line">            IOUtils.closeStream(in);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@function</span> 删除文件</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> fileSystem    传入DFS文件系统</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> hdfsPathStr   HDFS文件路径</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">delFile</span><span class="params">(FileSystem fileSystem,String hdfsPathStr,<span class="keyword">boolean</span> recursive)</span></span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//true：开启级联删除，将删除目录下的全部内容</span></span><br><span class="line">            fileSystem.delete(<span class="keyword">new</span> Path(hdfsPathStr),recursive);</span><br><span class="line">            System.out.println(<span class="string">&quot;DELETE SUCCESSFULLY&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@function</span> 列出路径下全部文件内容</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> fileSystem    传入DFS文件系统</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> hdfsPathStr   HDFS目录</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">listFile</span><span class="params">(FileSystem fileSystem,String hdfsPathStr)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        Path[] paths = <span class="keyword">new</span> Path[<span class="number">1</span>];</span><br><span class="line">        paths[<span class="number">0</span>] = <span class="keyword">new</span> Path(hdfsPathStr);</span><br><span class="line">        FileStatus[] status = fileSystem.listStatus(paths);</span><br><span class="line">        <span class="keyword">for</span> (FileStatus p : status) &#123;</span><br><span class="line">            System.out.println(p);</span><br><span class="line">        &#125;</span><br><span class="line">        Path[] listedPaths = FileUtil.stat2Paths(status);</span><br><span class="line">        <span class="keyword">for</span> (Path p : listedPaths) &#123;</span><br><span class="line">            System.out.println(p);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        String cmd = args[<span class="number">0</span>];</span><br><span class="line">        String hdfsPathStr = args[<span class="number">1</span>];</span><br><span class="line">        <span class="comment">//通用三步骤</span></span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        conf.set(<span class="string">&quot;fs.defaultFS&quot;</span>,<span class="string">&quot;hdfs://hadoop01:9000&quot;</span>);</span><br><span class="line">        FileSystem fileSystem = FileSystem.get(URI.create(hdfsPathStr), conf);</span><br><span class="line">        HdfsJavaApi hdfsJavaApi =<span class="keyword">new</span> HdfsJavaApi();</span><br><span class="line">        <span class="keyword">if</span>(cmd.equals(<span class="string">&quot;get&quot;</span>))&#123;</span><br><span class="line">            hdfsJavaApi.getFile(fileSystem,hdfsPathStr,args[<span class="number">2</span>]);</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span>(cmd.equals(<span class="string">&quot;put&quot;</span>))&#123;</span><br><span class="line">            hdfsJavaApi.putFile(fileSystem,hdfsPathStr,args[<span class="number">2</span>]);</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span>(cmd.equals(<span class="string">&quot;delete&quot;</span>))&#123;</span><br><span class="line">            hdfsJavaApi.delFile(fileSystem,hdfsPathStr,Boolean.parseBoolean(args[<span class="number">2</span>]));</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span>(cmd.equals(<span class="string">&quot;list&quot;</span>))&#123;</span><br><span class="line">            hdfsJavaApi.listFile(fileSystem,hdfsPathStr);</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;HDFS JAVA API ERROR:COMMAND NOT FOUND!&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>测试命令</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#执行下载命令,将HDFS/1.txt下载到~/1.txt</span></span><br><span class="line">[liujiazhao@hadoop01 ~]$ hadoop jar HadoopLearning-1.0-SNAPSHOT.jar com.api.HdfsJavaApi get /1.txt /home/liujiazhao/1.txt</span><br><span class="line"></span><br><span class="line"><span class="comment">#执行上传命令,将~/1.txt上传到HDFS的/1.txt</span></span><br><span class="line">[liujiazhao@hadoop01 ~]$ hadoop jar HadoopLearning-1.0-SNAPSHOT.jar com.api.HdfsJavaApi put /2.txt /home/liujiazhao/1.txt</span><br><span class="line"></span><br><span class="line"><span class="comment">#执行删除命令，将/1.jpg文件删除</span></span><br><span class="line">[liujiazhao@hadoop01 ~]$ hadoop jar HadoopLearning-1.0-SNAPSHOT.jar com.api.HdfsJavaApi delete /1.jpg <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#执行删除命令，将/testdata目录下全部文件删除</span></span><br><span class="line">[liujiazhao@hadoop01 ~]$ hadoop jar HadoopLearning-1.0-SNAPSHOT.jar com.api.HdfsJavaApi delete /testdata <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#执行列表查询命令，查询某个目录下全部文件</span></span><br><span class="line">[liujiazhao@hadoop01 ~]$ hadoop jar HadoopLearning-1.0-SNAPSHOT.jar com.api.HdfsJavaApi list /<span class="built_in">test</span></span><br></pre></td></tr></table></figure>

<p><strong>本项目全部源代码上传至GitHub：<a href="https://github.com/Labcz/HadoopLearning">https://github.com/Labcz/HadoopLearning</a></strong></p>
]]></content>
      <categories>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Hadoop</tag>
      </tags>
  </entry>
</search>
