<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>使用JAVA的API操作HDFS | LABCZ</title><meta name="keywords" content="Java,Hadoop"><meta name="author" content="Labcz"><meta name="copyright" content="Labcz"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="description" content="创建IDEA新项目创建新MAVEN项目    导入pom.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888">
<meta property="og:type" content="article">
<meta property="og:title" content="使用JAVA的API操作HDFS">
<meta property="og:url" content="labcz.com/ckhnapxhy0013j9fp2fbffp2m.html">
<meta property="og:site_name" content="LABCZ">
<meta property="og:description" content="创建IDEA新项目创建新MAVEN项目    导入pom.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/使用JAVA的API操作HDFS/cover.jpg">
<meta property="article:published_time" content="2020-10-30T07:17:00.000Z">
<meta property="article:modified_time" content="2020-11-06T14:38:33.000Z">
<meta property="article:author" content="Labcz">
<meta property="article:tag" content="Java">
<meta property="article:tag" content="Hadoop">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/使用JAVA的API操作HDFS/cover.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="labcz.com/ckhnapxhy0013j9fp2fbffp2m"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?11aaeae6d02d5e6867d6d0c4176d2341";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: {"limitDay":500,"position":"top","messagePrev":"距离上次更新已经有","messageNext":"天, 这篇文章的部分内容可能已经过时了。"},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  ClickShowText: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#121212","position":"bottom-left"},
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
  },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2020-11-06 22:38:33'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(function () {  window.activateDarkMode = function () {
    document.documentElement.setAttribute('data-theme', 'dark')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
    }
  }
  window.activateLightMode = function () {
    document.documentElement.setAttribute('data-theme', 'light')
   if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
    }
  }
  const autoChangeMode = 'false'
  const t = saveToLocal.get('theme')
  if (autoChangeMode === '1') {
    const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
    const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
    const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
    const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified
    if (t === undefined) {
      if (isLightMode) activateLightMode()
      else if (isDarkMode) activateDarkMode()
      else if (isNotSpecified || hasNoSupport) {
        const now = new Date()
        const hour = now.getHours()
        const isNight = hour <= 6 || hour >= 18
        isNight ? activateDarkMode() : activateLightMode()
      }
      window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
        if (saveToLocal.get('theme') === undefined) {
          e.matches ? activateDarkMode() : activateLightMode()
        }
      })
    } else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else if (autoChangeMode === '2') {
    const now = new Date()
    const hour = now.getHours()
    const isNight = hour <= 6 || hour >= 18
    if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
    else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else {
    if (t === 'dark') activateDarkMode()
    else if (t === 'light') activateLightMode()
  }const asideStatus = saveToLocal.get('aside-status')
if (asideStatus !== undefined) {
   if (asideStatus === 'hide') {
     document.documentElement.classList.add('hide-aside')
   } else {
     document.documentElement.classList.remove('hide-aside')
   }
}})()</script><link rel="stylesheet" href="/css/labcz.css"><meta name="generator" content="Hexo 5.0.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="https://cdn.jsdelivr.net/gh/Labcz/CDN/images/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">7</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">5</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa-fw fab fa-font-awesome-flag"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/artitalk/"><i class="fa-fw fa-fw fa fa-paper-plane"></i><span> 说说</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/使用JAVA的API操作HDFS/cover.jpg)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">LABCZ</a></span><span id="menus"><div id="search_button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa-fw fab fa-font-awesome-flag"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/artitalk/"><i class="fa-fw fa-fw fa fa-paper-plane"></i><span> 说说</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><span class="close" id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><h1 class="post-title">使用JAVA的API操作HDFS</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2020-10-30T07:17:00.000Z" title="发表于 2020-10-30 15:17:00">2020-10-30</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2020-11-06T14:38:33.000Z" title="更新于 2020-11-06 22:38:33">2020-11-06</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Hadoop/">Hadoop</a></span></div><div class="meta-secondline"> <span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">5.5k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>27分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/ckhnapxhy0013j9fp2fbffp2m.html#post-comment" itemprop="discussionUrl"><span class="valine-comment-count comment-count" data-xid="/ckhnapxhy0013j9fp2fbffp2m.html" itemprop="commentCount"></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="创建IDEA新项目"><a href="#创建IDEA新项目" class="headerlink" title="创建IDEA新项目"></a>创建IDEA新项目</h1><h2 id="创建新MAVEN项目"><a href="#创建新MAVEN项目" class="headerlink" title="创建新MAVEN项目"></a>创建新MAVEN项目</h2><img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/使用JAVA的API操作HDFS/1.png" style="zoom:100%;" />

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/使用JAVA的API操作HDFS/2.png" style="zoom:67%;" />

<h2 id="导入pom-xml"><a href="#导入pom-xml" class="headerlink" title="导入pom.xml"></a>导入pom.xml</h2><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0&quot;</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xmlns:xsi</span>=<span class="string">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xsi:schemaLocation</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.labcz<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>HadoopLearning<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>HadoopLearning<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">project.build.sourceEncoding</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">project.build.sourceEncoding</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">maven.compiler.source</span>&gt;</span>1.7<span class="tag">&lt;/<span class="name">maven.compiler.source</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">maven.compiler.target</span>&gt;</span>1.7<span class="tag">&lt;/<span class="name">maven.compiler.target</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 这里对jar包版本做集中管理 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">hadoop.version</span>&gt;</span>2.7.7<span class="tag">&lt;/<span class="name">hadoop.version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">junit.version</span>&gt;</span>4.12<span class="tag">&lt;/<span class="name">junit.version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- Hadoop客户端依赖，该依赖包含HDFS的相关依赖 --&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- hadoop工具类 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-common<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;hadoop.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- hadoop的客户端,用于访问HDFS --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;hadoop.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-hdfs<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;hadoop.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!-- 单元测试的依赖 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;junit.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">pluginManagement</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-clean-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-resources-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.0.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-compiler-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.8.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-surefire-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.22.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-jar-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.0.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-install-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.5.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-deploy-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.8.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-site-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.7.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-project-info-reports-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.0.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">pluginManagement</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>导入完成后，右击项目Maven-&gt;Reload Project进行解决项目jar包依赖</strong></p>
<h1 id="根据URL读取HDFS文件内容"><a href="#根据URL读取HDFS文件内容" class="headerlink" title="根据URL读取HDFS文件内容"></a>根据URL读取HDFS文件内容</h1><ul>
<li><p>提前准备好一个1.txt文本并上传至HDFS</p>
</li>
<li><p>配置好Windows下hadoop主机映射</p>
<div class="note info flat"><p>修改C:\Windows\System32\drivers\etc\hosts文件,写入对应主机映射</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/使用JAVA的API操作HDFS/hosts.png" style="zoom:67%;" />
</div>
</li>
<li><p>在src/mian/java下创建com.labcz的Package</p>
</li>
<li><p>创建HdfsUrlReader类</p>
</li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/使用JAVA的API操作HDFS/3.png" style="zoom:67%;" />

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.labcz;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FsUrlStreamHandlerFactory;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IOUtils;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.io.InputStream;</span><br><span class="line"><span class="keyword">import</span> java.net.URL;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> Labcz</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@ClassName</span> HdfsUrlReader.java</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span> 根据URL读取文件内容</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@createTime</span> 2020年10月30日 15:54:00</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HdfsUrlReader</span> </span>&#123;</span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        <span class="comment">//通过Java的URL类来访问Hdfs内的文件</span></span><br><span class="line">        URL.setURLStreamHandlerFactory(<span class="keyword">new</span> FsUrlStreamHandlerFactory());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//定义一个JAVA的输入流</span></span><br><span class="line">        InputStream inputStream = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//读取HDFS上的1.txt文件（提前上传到HDFS的/目录下）192.168.229.131为HDFS文件系统地址</span></span><br><span class="line">            inputStream = <span class="keyword">new</span> URL(<span class="string">&quot;hdfs://hadoop01:9000/1.txt&quot;</span>).openStream();</span><br><span class="line">            <span class="comment">//获取输入流，输出到控制台，每次拷贝缓冲区buffer大小，最后是否关闭数据流</span></span><br><span class="line">            IOUtils.copyBytes(inputStream,System.out,<span class="number">1024</span>,<span class="keyword">true</span>);</span><br><span class="line">            System.out.print(<span class="string">&quot;打印完成！&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            <span class="comment">//若出现异常，关闭数据流</span></span><br><span class="line">            IOUtils.closeStream(inputStream);</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>输出结果：</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/使用JAVA的API操作HDFS/4.png" style="zoom:67%;" />

<h1 id="使用FileSystem类访问HDFS"><a href="#使用FileSystem类访问HDFS" class="headerlink" title="使用FileSystem类访问HDFS"></a>使用FileSystem类访问HDFS</h1><ul>
<li>创建FileSystemReader类</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.labcz;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IOUtils;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.io.InputStream;</span><br><span class="line"><span class="keyword">import</span> java.net.URI;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> Labcz</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@ClassName</span> FileSystemReader.java</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span> 使用FileSystem类访问HDFS</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@createTime</span> 2020年10月30日 16:21:00</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FileSystemReader</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="comment">// 会默认读取core-site.xml中的fs.default.name来判断文件系统。如果未设置则默认是本地文件系统</span></span><br><span class="line">        Configuration configuration = <span class="keyword">new</span> Configuration();</span><br><span class="line">        <span class="comment">//定义访问路径</span></span><br><span class="line">        String uri = <span class="string">&quot;hdfs://hadoop01:9000/1.txt&quot;</span>;</span><br><span class="line">        <span class="comment">//定义FileSystem</span></span><br><span class="line">        FileSystem fileSystem = FileSystem.get(URI.create(uri), configuration);</span><br><span class="line">        <span class="comment">//定义输入流</span></span><br><span class="line">        InputStream inputStream = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//将String类型的url地址转换为Path类型，也可以直接定义Path类型路径</span></span><br><span class="line">            inputStream = fileSystem.open(<span class="keyword">new</span> Path(uri));</span><br><span class="line">            <span class="comment">//获取输入流，输出到控制台，每次拷贝缓冲区buffer大小，最后不关闭数据流</span></span><br><span class="line">            IOUtils.copyBytes(inputStream, System.out, <span class="number">4096</span>, <span class="keyword">false</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;<span class="keyword">finally</span> &#123;</span><br><span class="line">            <span class="comment">//关闭数据流</span></span><br><span class="line">            IOUtils.closeStream(inputStream);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>输出结果：</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/使用JAVA的API操作HDFS/5.png" style="zoom:67%;" />

<h1 id="查看HDFS文件-目录元信息"><a href="#查看HDFS文件-目录元信息" class="headerlink" title="查看HDFS文件/目录元信息"></a>查看HDFS文件/目录元信息</h1><ul>
<li>提前准备好一个hello.txt文本并上传至HDFS的/test目录下</li>
<li>创建FileStatusMetadata类</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.labcz;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileStatus;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.net.URI;</span><br><span class="line"><span class="keyword">import</span> java.sql.Timestamp;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> Labcz</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@ClassName</span> FileStatusMetadata.java</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span> 查看HDFS文件/目录元信息</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@createTime</span> 2020年10月30日 16:52:00</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FileStatusMetadata</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="comment">//读取hadoop文件系统的配置</span></span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        conf.set(<span class="string">&quot;fs.defaultFS&quot;</span>,<span class="string">&quot;hdfs://hadoop01:9000&quot;</span>);</span><br><span class="line">        <span class="comment">//把HADOOP_USER_NAME设置成系统的全局变量</span></span><br><span class="line">        System.setProperty(<span class="string">&quot;HADOOP_USER_NAME&quot;</span>,<span class="string">&quot;labcz&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;--------查看HDFS中某文件的元信息--------&quot;</span>);</span><br><span class="line">        String fileURI = <span class="string">&quot;/test/hello.txt&quot;</span>;</span><br><span class="line">        FileSystem fileSystem = FileSystem.get(URI.create(fileURI),conf);</span><br><span class="line">        <span class="comment">//获取文件元信息</span></span><br><span class="line">        FileStatus fileStatus = fileSystem.getFileStatus(<span class="keyword">new</span> Path(fileURI));</span><br><span class="line">        <span class="keyword">if</span>(fileStatus.isDirectory()==<span class="keyword">false</span>)&#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;这是个文件&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(<span class="string">&quot;文件路径: &quot;</span>+fileStatus.getPath());</span><br><span class="line">        System.out.println(<span class="string">&quot;文件长度: &quot;</span>+fileStatus.getLen());</span><br><span class="line">        System.out.println(<span class="string">&quot;文件修改日期： &quot;</span>+<span class="keyword">new</span> Timestamp(fileStatus.getModificationTime()).toString());</span><br><span class="line">        System.out.println(<span class="string">&quot;文件上次访问日期： &quot;</span>+<span class="keyword">new</span> Timestamp(fileStatus.getAccessTime()).toString());</span><br><span class="line">        System.out.println(<span class="string">&quot;文件备份数： &quot;</span>+fileStatus.getReplication());</span><br><span class="line">        System.out.println(<span class="string">&quot;文件的块大小： &quot;</span>+fileStatus.getBlockSize());</span><br><span class="line">        System.out.println(<span class="string">&quot;文件所有者：  &quot;</span>+fileStatus.getOwner());</span><br><span class="line">        System.out.println(<span class="string">&quot;文件所在的分组： &quot;</span>+fileStatus.getGroup());</span><br><span class="line">        System.out.println(<span class="string">&quot;文件的 权限： &quot;</span>+fileStatus.getPermission().toString());</span><br><span class="line">        System.out.println();</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">&quot;--------查看HDFS中某文件的元信息--------&quot;</span>);</span><br><span class="line">        String dirURI = <span class="string">&quot;/test&quot;</span>;</span><br><span class="line">        FileSystem dirFS = FileSystem.get(URI.create(dirURI) ,conf);</span><br><span class="line">        FileStatus dirStatus = dirFS.getFileStatus(<span class="keyword">new</span> Path(dirURI));</span><br><span class="line">        <span class="comment">//获取目录的元信息</span></span><br><span class="line">        <span class="keyword">if</span>(dirStatus.isDir()==<span class="keyword">true</span>)&#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;这是个目录&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(<span class="string">&quot;目录路径: &quot;</span>+dirStatus.getPath());</span><br><span class="line">        System.out.println(<span class="string">&quot;目录长度: &quot;</span>+dirStatus.getLen());</span><br><span class="line">        System.out.println(<span class="string">&quot;目录修改日期： &quot;</span>+<span class="keyword">new</span> Timestamp (dirStatus.getModificationTime()).toString());</span><br><span class="line">        System.out.println(<span class="string">&quot;目录上次访问日期： &quot;</span>+<span class="keyword">new</span> Timestamp(dirStatus.getAccessTime()).toString());</span><br><span class="line">        System.out.println(<span class="string">&quot;目录备份数： &quot;</span>+dirStatus.getReplication());</span><br><span class="line">        System.out.println(<span class="string">&quot;目录的块大小： &quot;</span>+dirStatus.getBlockSize());</span><br><span class="line">        System.out.println(<span class="string">&quot;目录所有者：  &quot;</span>+dirStatus.getOwner());</span><br><span class="line">        System.out.println(<span class="string">&quot;目录所在的分组： &quot;</span>+dirStatus.getGroup());</span><br><span class="line">        System.out.println(<span class="string">&quot;目录的 权限： &quot;</span>+dirStatus.getPermission().toString());</span><br><span class="line">        System.out.println(<span class="string">&quot;这个目录下包含以下文件或目录：&quot;</span>);</span><br><span class="line">        FileStatus[] fsList = dirFS.listStatus(<span class="keyword">new</span> Path(dirURI));</span><br><span class="line">        <span class="keyword">for</span>(FileStatus fs : fsList)&#123;</span><br><span class="line">            System.out.println(fs.getPath());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>输出结果：</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/使用JAVA的API操作HDFS/6.png" style="zoom:67%;" />

<h1 id="查找某个文件在HDFS集群的位置"><a href="#查找某个文件在HDFS集群的位置" class="headerlink" title="查找某个文件在HDFS集群的位置"></a>查找某个文件在HDFS集群的位置</h1><ul>
<li>创建BlockLocationTest类</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.labcz;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.BlockLocation;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileStatus;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.net.URI;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> Labcz</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@ClassName</span> BlockLocationTest.java</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span> 查找某个文件在HDFS集群的位置</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@createTime</span> 2020年10月30日 17:40:00</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BlockLocationTest</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        Configuration conf=<span class="keyword">new</span> Configuration();</span><br><span class="line">        conf.set(<span class="string">&quot;fs.defaultFS&quot;</span>,<span class="string">&quot;hdfs://hadoop01:9000&quot;</span>);</span><br><span class="line">        String fileURI = <span class="string">&quot;/test/hello.txt&quot;</span>;</span><br><span class="line">        FileSystem fileSystem = FileSystem.get(URI.create(fileURI),conf);</span><br><span class="line">        <span class="comment">//获取文件元信息</span></span><br><span class="line">        FileStatus fileStatus = fileSystem.getFileStatus(<span class="keyword">new</span> Path(fileURI));</span><br><span class="line">        BlockLocation[] blockLocations = fileSystem.getFileBlockLocations(fileStatus, <span class="number">0</span>, fileStatus.getLen());</span><br><span class="line">        <span class="keyword">int</span> blockLen = blockLocations.length;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;blockLen;i++)&#123;</span><br><span class="line">            String[] hosts = blockLocations[i].getHosts();</span><br><span class="line">            <span class="comment">//其中hosts[0]离自己最近</span></span><br><span class="line">            System.out.println(<span class="string">&quot;block_&quot;</span>+i+<span class="string">&quot;_location hosts[0]:&quot;</span>+hosts[<span class="number">0</span>]);</span><br><span class="line">            System.out.println(<span class="string">&quot;block_&quot;</span>+i+<span class="string">&quot;_location hosts[1]:&quot;</span>+hosts[<span class="number">1</span>]);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>输出结果：</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/使用JAVA的API操作HDFS/7.png" style="zoom:100%;" />

<h1 id="文件上传-下载"><a href="#文件上传-下载" class="headerlink" title="文件上传/下载"></a>文件上传/下载</h1><ul>
<li>创建HdfsDataInput类</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.labcz;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IOUtils;</span><br><span class="line"><span class="keyword">import</span> org.apache.log4j.Logger;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"><span class="keyword">import</span> java.net.URI;</span><br><span class="line"><span class="keyword">import</span> java.net.URL;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> Labcz</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@ClassName</span> HdfsDataInput.java</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span> 本地文件上传到HDFS,以及从HDFS上将文件下载到本地</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@createTime</span> 2020年10月30日 19:13:00</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HdfsDataInput</span> </span>&#123;</span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">final</span> Logger logger = Logger.getLogger(HdfsDataInput.class);</span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        URL.setURLStreamHandlerFactory(<span class="keyword">new</span> FsUrlStreamHandlerFactory());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        HdfsDataInput hdi = <span class="keyword">new</span> HdfsDataInput();</span><br><span class="line">        <span class="comment">//将本地桌面上的2.txt文件上传到HDFS的/2.txt</span></span><br><span class="line">        hdi.createFile(<span class="string">&quot;C:/Users/Labcz/Desktop/2.txt&quot;</span>, <span class="string">&quot;/2.txt&quot;</span>);</span><br><span class="line">        <span class="comment">//将HDFS上的/1.txt文件上获取到本地桌面的1.txt,并且打印1.txt的内容</span></span><br><span class="line">       <span class="comment">// hdi.getFile(&quot;C:/Users/Labcz/Desktop/1.txt&quot;, &quot;/1.txt&quot;,true);</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@function</span> 将本地文件上传到HDFS上</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> localPath 本地文件路径</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> hdfsPath  HDFS目标文件路径</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">createFile</span><span class="params">(String localPath,String hdfsPath)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//定义输入流</span></span><br><span class="line">        InputStream in = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">//通用三步骤</span></span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        conf.set(<span class="string">&quot;fs.defaultFS&quot;</span>,<span class="string">&quot;hdfs://hadoop01:9000&quot;</span>);</span><br><span class="line">        FileSystem fileSystem = FileSystem.get(URI.create(hdfsPath), conf);</span><br><span class="line">        <span class="comment">//在HDFS上创建空文件</span></span><br><span class="line">        FSDataOutputStream out = fileSystem.create(<span class="keyword">new</span> Path(hdfsPath));</span><br><span class="line">        in = <span class="keyword">new</span> BufferedInputStream(<span class="keyword">new</span> FileInputStream(<span class="keyword">new</span> File(localPath)));</span><br><span class="line">        <span class="comment">//将文件进行拷贝，从输入流到输出流</span></span><br><span class="line">        IOUtils.copyBytes(in, out, <span class="number">4096</span>, <span class="keyword">false</span>);</span><br><span class="line">        out.hsync();</span><br><span class="line">        out.close();</span><br><span class="line">        logger.info(<span class="string">&quot;create file in hdfs:&quot;</span> + hdfsPath);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;<span class="keyword">finally</span> &#123;</span><br><span class="line">            IOUtils.closeStream(in);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     *<span class="doctag">@function</span>  从HDFS获取文件，并拷贝到本地localPath</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> localPath 本地目标文件路径</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> hdfsPath  HDFS文件路径</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> print  是否将文件内容同时打印到控制台</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">getFile</span><span class="params">(String localPath,String hdfsPath,<span class="keyword">boolean</span> print)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="comment">//通用三步骤</span></span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        conf.set(<span class="string">&quot;fs.defaultFS&quot;</span>,<span class="string">&quot;hdfs://hadoop01:9000&quot;</span>);</span><br><span class="line">        FileSystem fileSystem = FileSystem.get(URI.create(hdfsPath), conf);</span><br><span class="line">        <span class="comment">//定义输入输出流</span></span><br><span class="line">        FSDataInputStream in = fileSystem.open(<span class="keyword">new</span> Path(hdfsPath));</span><br><span class="line">        OutputStream out = <span class="keyword">new</span> BufferedOutputStream(<span class="keyword">new</span> FileOutputStream(<span class="keyword">new</span> File(localPath)));</span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">            <span class="comment">//进行文件拷贝</span></span><br><span class="line">            IOUtils.copyBytes(in,out,<span class="number">4096</span>,!print);</span><br><span class="line">            logger.info(<span class="string">&quot;get file form hdfs to local: &quot;</span> + hdfsPath + <span class="string">&quot;, &quot;</span> + localPath);</span><br><span class="line">            <span class="keyword">if</span> (print) &#123;</span><br><span class="line">                in.seek(<span class="number">0</span>);  <span class="comment">//输入流从新回到文件开始的位置</span></span><br><span class="line">                IOUtils.copyBytes(in, System.out, <span class="number">4096</span>, <span class="keyword">true</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//关闭输出流，否则文件内容可能为空</span></span><br><span class="line">            out.close();</span><br><span class="line">        &#125;<span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;<span class="keyword">finally</span> &#123;</span><br><span class="line">            IOUtils.closeStream(in);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>输出结果：</p>
<p>（1）通过<code>hdfs dfs -ls /</code>查看HDFS上已存在的文件</p>
<p>（2）下载到本地的文件可以之间查看内容</p>
<h1 id="在Linux上进行文件上传-下载"><a href="#在Linux上进行文件上传-下载" class="headerlink" title="在Linux上进行文件上传/下载"></a>在Linux上进行文件上传/下载</h1><ul>
<li>创建HdfsDataInputOnLinux类</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.labcz;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IOUtils;</span><br><span class="line"><span class="keyword">import</span> org.apache.log4j.Logger;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"><span class="keyword">import</span> java.net.URI;</span><br><span class="line"><span class="keyword">import</span> java.net.URL;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> Labcz</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@ClassName</span> HdfsDataInputOnLinux.java</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span> TODO</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@createTime</span> 2020年10月30日 21:18:00</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HdfsDataInputOnLinux</span> </span>&#123;</span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">final</span> Logger logger = Logger.getLogger(HdfsDataInput.class);</span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        URL.setURLStreamHandlerFactory(<span class="keyword">new</span> FsUrlStreamHandlerFactory());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        HdfsDataInputOnLinux hdiol = <span class="keyword">new</span> HdfsDataInputOnLinux();</span><br><span class="line">        String cmd = args[<span class="number">0</span>];</span><br><span class="line">        String localPath = args[<span class="number">1</span>];</span><br><span class="line">        String hdfsPath = args[<span class="number">2</span>];</span><br><span class="line">        <span class="keyword">if</span> (cmd.equals(<span class="string">&quot;create&quot;</span>)) &#123;</span><br><span class="line">            hdiol.createFile(localPath, hdfsPath);</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (cmd.equals(<span class="string">&quot;get&quot;</span>)) &#123;</span><br><span class="line">            <span class="keyword">boolean</span> print = Boolean.parseBoolean(args[<span class="number">3</span>]);</span><br><span class="line">            hdiol.getFile(localPath, hdfsPath, print);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@function</span> 将本地文件上传到HDFS上</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> localPath 本地文件路径</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> hdfsPath  HDFS目标文件路径</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">createFile</span><span class="params">(String localPath,String hdfsPath)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//定义输入流</span></span><br><span class="line">        InputStream in = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//通用三步骤</span></span><br><span class="line">            Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">            conf.set(<span class="string">&quot;fs.defaultFS&quot;</span>,<span class="string">&quot;hdfs://hadoop01:9000&quot;</span>);</span><br><span class="line">            FileSystem fileSystem = FileSystem.get(URI.create(hdfsPath), conf);</span><br><span class="line">            <span class="comment">//在HDFS上创建空文件</span></span><br><span class="line">            FSDataOutputStream out = fileSystem.create(<span class="keyword">new</span> Path(hdfsPath));</span><br><span class="line">            in = <span class="keyword">new</span> BufferedInputStream(<span class="keyword">new</span> FileInputStream(<span class="keyword">new</span> File(localPath)));</span><br><span class="line">            <span class="comment">//将文件进行拷贝，从输入流到输出流</span></span><br><span class="line">            IOUtils.copyBytes(in, out, <span class="number">4096</span>, <span class="keyword">false</span>);</span><br><span class="line">            out.hsync();</span><br><span class="line">            out.close();</span><br><span class="line">            logger.info(<span class="string">&quot;create file in hdfs:&quot;</span> + hdfsPath);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;<span class="keyword">finally</span> &#123;</span><br><span class="line">            IOUtils.closeStream(in);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     *<span class="doctag">@function</span>  从HDFS获取文件，并拷贝到本地localPath</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> localPath 本地目标文件路径</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> hdfsPath  HDFS文件路径</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> print  是否将文件内容同时打印到控制台</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">getFile</span><span class="params">(String localPath,String hdfsPath,<span class="keyword">boolean</span> print)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="comment">//通用三步骤</span></span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        conf.set(<span class="string">&quot;fs.defaultFS&quot;</span>,<span class="string">&quot;hdfs://hadoop01:9000&quot;</span>);</span><br><span class="line">        FileSystem fileSystem = FileSystem.get(URI.create(hdfsPath), conf);</span><br><span class="line">        <span class="comment">//定义输入输出流</span></span><br><span class="line">        FSDataInputStream in = fileSystem.open(<span class="keyword">new</span> Path(hdfsPath));</span><br><span class="line">        OutputStream out = <span class="keyword">new</span> BufferedOutputStream(<span class="keyword">new</span> FileOutputStream(<span class="keyword">new</span> File(localPath)));</span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">            <span class="comment">//进行文件拷贝</span></span><br><span class="line">            IOUtils.copyBytes(in,out,<span class="number">4096</span>,!print);</span><br><span class="line">            logger.info(<span class="string">&quot;get file form hdfs to local: &quot;</span> + hdfsPath + <span class="string">&quot;, &quot;</span> + localPath);</span><br><span class="line">            <span class="keyword">if</span> (print) &#123;</span><br><span class="line">                in.seek(<span class="number">0</span>);  <span class="comment">//输入流从新回到文件开始的位置</span></span><br><span class="line">                IOUtils.copyBytes(in, System.out, <span class="number">4096</span>, <span class="keyword">true</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//关闭输出流，否则文件内容可能为空</span></span><br><span class="line">            out.close();</span><br><span class="line">        &#125;<span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;<span class="keyword">finally</span> &#123;</span><br><span class="line">            IOUtils.closeStream(in);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>将项目打包成jar包：点击右侧Maven图标，依次点击Lifecycle-&gt;clean,  Lifecycle-&gt;package</strong></p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/使用JAVA的API操作HDFS/8.png" style="zoom:67%;" />

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/使用JAVA的API操作HDFS/9.png" style="zoom:100%;" />

<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/使用JAVA的API操作HDFS/10.png" style="zoom:100%;" />

<p><strong>将会在右侧的target目录下看到以打成功的jar包</strong></p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/使用JAVA的API操作HDFS/11.png" style="zoom:78%;" />

<p><strong>将jar包拷贝至Linux的~目录下</strong></p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/使用JAVA的API操作HDFS/12.png" style="zoom:78%;" />

<p><strong>拷贝HdfsDataInputOnLinux的完整路径：右击该类-&gt;Copy-&gt;Copy Reference</strong></p>
<p><strong>获得该类的完整路径：com.labcz.HdfsDataInputOnLinux</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">//创建upload.txt文件用于测试文件上传与下载功能</span><br><span class="line">[liujiazhao@hadoop01 ~]$ echo &quot;Upload On Linux Test&quot; &gt;upload.txt</span><br><span class="line">[liujiazhao@hadoop01 ~]$ cat upload.txt </span><br><span class="line">Upload On Linux Test</span><br></pre></td></tr></table></figure>

<p><strong>执行文件上传命令：</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[liujiazhao@hadoop01 ~]$ hadoop jar HadoopLearning-1.0-SNAPSHOT.jar com.labcz.HdfsDataInputOnLinux create upload.txt /upload.txt</span><br></pre></td></tr></table></figure>

<p><strong>使用<code>hdfs dfs -cat /upload.txt</code>查看文件内容，检查是否上传成功</strong></p>
<p><strong>执行文件下载命令：</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[liujiazhao@hadoop01 ~]$ hadoop jar HadoopLearning-1.0-SNAPSHOT.jar com.labcz.HdfsDataInputOnLinux get /home/liujiazhao/1.txt /1.txt true</span><br></pre></td></tr></table></figure>

<p><strong>使用<code>cat /home/liujiazhao/1.txt</code>查看文件内容，检查是否下载成功</strong></p>
<h1 id="文件上传显示进度条"><a href="#文件上传显示进度条" class="headerlink" title="文件上传显示进度条"></a>文件上传显示进度条</h1><ul>
<li>准备一张较大的图片1.jpg进行实验，便于显示进度条显示过程</li>
<li>创建FileCopyWithProgress类</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.labcz;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IOUtils;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.util.Progressable;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"><span class="keyword">import</span> java.net.URI;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> Labcz</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@ClassName</span> FileCopyWithProgress.java</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span>  文件上传显示进度条</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@createTime</span> 2020年10月30日 21:58:00</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FileCopyWithProgress</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        String localURI = <span class="string">&quot;C:/Users/Labcz/Desktop/1.jpg&quot;</span>;</span><br><span class="line">        String destURI = <span class="string">&quot;/1.jpg&quot;</span>;</span><br><span class="line">        InputStream in =<span class="keyword">new</span> BufferedInputStream(<span class="keyword">new</span> FileInputStream(localURI));</span><br><span class="line">        <span class="comment">//通用三步骤</span></span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        conf.set(<span class="string">&quot;fs.defaultFS&quot;</span>,<span class="string">&quot;hdfs://hadoop01:9000&quot;</span>);</span><br><span class="line">        FileSystem fileSystem = FileSystem.get(URI.create(destURI), conf);</span><br><span class="line">        <span class="comment">//在输出流中定义进度条</span></span><br><span class="line">        OutputStream out = fileSystem.create(<span class="keyword">new</span> Path(destURI), <span class="keyword">new</span> Progressable() &#123;</span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">progress</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                System.out.print(<span class="string">&quot;.&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        IOUtils.copyBytes(in, out, <span class="number">4096</span>, <span class="keyword">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>输出结果：</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/使用JAVA的API操作HDFS/13.png" style="zoom:78%;" />

<h1 id="在Linux上文件上传显示进度条"><a href="#在Linux上文件上传显示进度条" class="headerlink" title="在Linux上文件上传显示进度条"></a>在Linux上文件上传显示进度条</h1><ul>
<li>准备一张较大的图片1.jpg进行实验，便于显示进度条显示过程</li>
<li>创建FileCopyWithProgressOnLinux类</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.labcz;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IOUtils;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.util.Progressable;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.BufferedInputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.FileInputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.InputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.OutputStream;</span><br><span class="line"><span class="keyword">import</span> java.net.URI;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> Labcz</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@ClassName</span> FileCopyWithProgressOnLinux.java</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span> 在Linux上文件上传显示进度条</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@createTime</span> 2020年10月30日 22:19:00</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FileCopyWithProgressOnLinux</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        String localURI = <span class="string">&quot;&quot;</span>;</span><br><span class="line">        String destURI = <span class="string">&quot;&quot;</span>;</span><br><span class="line">        <span class="keyword">if</span>(args.length&gt;=<span class="number">2</span>)&#123;</span><br><span class="line">            localURI = args[<span class="number">0</span>];</span><br><span class="line">            destURI = args[<span class="number">1</span>];</span><br><span class="line">        &#125;</span><br><span class="line">        InputStream in =<span class="keyword">new</span> BufferedInputStream(<span class="keyword">new</span> FileInputStream(localURI));</span><br><span class="line">        <span class="comment">//通用三步骤</span></span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        conf.set(<span class="string">&quot;fs.defaultFS&quot;</span>,<span class="string">&quot;hdfs://hadoop01:9000&quot;</span>);</span><br><span class="line">        FileSystem fileSystem = FileSystem.get(URI.create(destURI), conf);</span><br><span class="line">        <span class="comment">//在输出流中定义进度条</span></span><br><span class="line">        OutputStream out = fileSystem.create(<span class="keyword">new</span> Path(destURI), <span class="keyword">new</span> Progressable() &#123;</span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">progress</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                System.out.print(<span class="string">&quot;.&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        IOUtils.copyBytes(in, out, <span class="number">4096</span>, <span class="keyword">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>遵循之前生成导入jar包过程</strong></p>
<p><strong>执行命令：</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[liujiazhao@hadoop01 ~]$ hadoop jar HadoopLearning-1.0-SNAPSHOT.jar com.labcz.FileCopyWithProgressOnLinux 1.jpg /1.jpg</span><br></pre></td></tr></table></figure>

<p><strong>执行结果：将出现进度条，且文件成功上传</strong></p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/使用JAVA的API操作HDFS/14.png" style="zoom:78%;" />

<h1 id="读取HDFS某个目录下的所有文件"><a href="#读取HDFS某个目录下的所有文件" class="headerlink" title="读取HDFS某个目录下的所有文件"></a>读取HDFS某个目录下的所有文件</h1><ul>
<li>新建ListAllFile类</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.labcz;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileStatus;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileUtil;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.net.URI;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> Labcz</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@ClassName</span> ListAllFile.java</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span> 读取HDFS某个目录下的所有文件</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@createTime</span> 2020年10月30日 23:07:00</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ListAllFile</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="comment">//目标文件夹路径</span></span><br><span class="line">        String uri = <span class="string">&quot;/test&quot;</span>;</span><br><span class="line">        <span class="comment">//通用三步骤</span></span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        conf.set(<span class="string">&quot;fs.defaultFS&quot;</span>,<span class="string">&quot;hdfs://hadoop01:9000&quot;</span>);</span><br><span class="line">        FileSystem fileSystem = FileSystem.get(URI.create(uri), conf);</span><br><span class="line"></span><br><span class="line">        Path[] paths = <span class="keyword">new</span> Path[<span class="number">1</span>];</span><br><span class="line">        paths[<span class="number">0</span>] = <span class="keyword">new</span> Path(uri);</span><br><span class="line">        FileStatus[] status = fileSystem.listStatus(paths);</span><br><span class="line">        <span class="keyword">for</span> (FileStatus p : status) &#123;</span><br><span class="line">            System.out.println(p);</span><br><span class="line">        &#125;</span><br><span class="line">        Path[] listedPaths = FileUtil.stat2Paths(status);</span><br><span class="line">        <span class="keyword">for</span> (Path p : listedPaths) &#123;</span><br><span class="line">            System.out.println(p);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>输出结果：</p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/使用JAVA的API操作HDFS/16.png" style="zoom:78%;" />

<h1 id="在Linux上读取HDFS某个目录下的所有文件"><a href="#在Linux上读取HDFS某个目录下的所有文件" class="headerlink" title="在Linux上读取HDFS某个目录下的所有文件"></a>在Linux上读取HDFS某个目录下的所有文件</h1><ul>
<li>新建ListAllFileOnLinux类</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.labcz;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileStatus;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileUtil;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.net.URI;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> Labcz</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@ClassName</span> ListAllFileOnLinux.java</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span> 在Linux上读取HDFS某个目录下的所有文件</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@createTime</span> 2020年10月30日 22:30:00</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ListAllFileOnLinux</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        String uri = args[<span class="number">0</span>];</span><br><span class="line">        <span class="comment">//通用三步骤</span></span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        conf.set(<span class="string">&quot;fs.defaultFS&quot;</span>,<span class="string">&quot;hdfs://hadoop01:9000&quot;</span>);</span><br><span class="line">        FileSystem fileSystem = FileSystem.get(URI.create(uri), conf);</span><br><span class="line"></span><br><span class="line">        Path[] paths = <span class="keyword">new</span> Path[args.length];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; paths.length; i++) &#123;</span><br><span class="line">            paths[i] = <span class="keyword">new</span> Path(args[i]);</span><br><span class="line">        &#125;</span><br><span class="line">        FileStatus[] status = fileSystem.listStatus(paths);</span><br><span class="line">        <span class="keyword">for</span> (FileStatus p : status) &#123;</span><br><span class="line">            System.out.println(p);</span><br><span class="line">        &#125;</span><br><span class="line">        Path[] listedPaths = FileUtil.stat2Paths(status);</span><br><span class="line">        <span class="keyword">for</span> (Path p : listedPaths) &#123;</span><br><span class="line">            System.out.println(p);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>遵循之前生成导入jar包过程</strong></p>
<p><strong>执行命令：</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[liujiazhao@hadoop01 ~]$ hadoop jar HadoopLearning-1.0-SNAPSHOT.jar com.labcz.ListAllFileOnLinux /test</span><br></pre></td></tr></table></figure>

<p><strong>执行结果：显示目标路径下的各文件内容</strong></p>
<img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/使用JAVA的API操作HDFS/15.png" style="zoom:78%;" />

<h1 id="编写HDFS的API"><a href="#编写HDFS的API" class="headerlink" title="编写HDFS的API"></a>编写HDFS的API</h1><ul>
<li>创建com.api包</li>
<li>在该包下新建HdfsJavaApi类，并构建该API的基础框架</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.api;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.File;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.net.URI;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> Labcz</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@ClassName</span> HdfsJavaApi.java</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span> 对文件上传下载、修改、删除、查看等等操作</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@createTime</span> 2020年10月30日 23:14:00</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HdfsJavaApi</span> </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@function</span> 从HDFS上获取文件到本地</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> fileSystem    传入DFS文件系统</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> hdfsPathStr   HDFS文件路径</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> localPathStr   本地文件路径</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">getFile</span><span class="params">(FileSystem fileSystem,String hdfsPathStr,String localPathStr)</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@function</span> 将本地文件上传到文件系统</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> fileSystem    传入DFS文件系统</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> hdfsPathStr   HDFS文件路径</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> localPathStr  本地文件路径</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">putFile</span><span class="params">(FileSystem fileSystem,String hdfsPathStr,String localPathStr)</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@function</span> 删除文件</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> fileSystem    传入DFS文件系统</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> hdfsPathStr   HDFS文件路径</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">delFile</span><span class="params">(FileSystem fileSystem,String hdfsPathStr)</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@function</span> 列出路径下全部文件内容</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> fileSystem    传入DFS文件系统</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> hdfsPathStr   HDFS目录</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">listFile</span><span class="params">(FileSystem fileSystem,String hdfsPathStr)</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        String uri = args[<span class="number">0</span>];</span><br><span class="line">        <span class="comment">//通用三步骤</span></span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        conf.set(<span class="string">&quot;fs.defaultFS&quot;</span>,<span class="string">&quot;hdfs://hadoop01:9000&quot;</span>);</span><br><span class="line">        FileSystem fileSystem = FileSystem.get(URI.create(uri), conf);</span><br><span class="line">        HdfsJavaApi hdfsJavaApi =<span class="keyword">new</span> HdfsJavaApi();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>编写getFile下载函数</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">getFile</span><span class="params">(FileSystem fileSystem,String hdfsPathStr,String localPathStr)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    <span class="comment">//定义输入输出流</span></span><br><span class="line">    FSDataInputStream in = fileSystem.open(<span class="keyword">new</span> Path(hdfsPathStr));</span><br><span class="line">    OutputStream out = <span class="keyword">new</span> BufferedOutputStream(<span class="keyword">new</span> FileOutputStream(<span class="keyword">new</span> File(localPathStr)));</span><br><span class="line">    <span class="keyword">try</span>&#123;</span><br><span class="line">        <span class="comment">//进行文件拷贝</span></span><br><span class="line">        IOUtils.copyBytes(in,out,<span class="number">4096</span>,<span class="keyword">false</span>);</span><br><span class="line">        in.seek(<span class="number">0</span>);  <span class="comment">//输入流从新回到文件开始的位置</span></span><br><span class="line">        IOUtils.copyBytes(in, System.out, <span class="number">4096</span>, <span class="keyword">true</span>);</span><br><span class="line">        <span class="comment">//关闭输出流，否则文件内容可能为空</span></span><br><span class="line">        out.close();</span><br><span class="line">    &#125;<span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;<span class="keyword">finally</span> &#123;</span><br><span class="line">        IOUtils.closeStream(in);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>编写putFile上传函数</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">putFile</span><span class="params">(FileSystem fileSystem,String hdfsPathStr,String localPathStr)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="comment">//在HDFS上创建空文件</span></span><br><span class="line">        FSDataOutputStream out = fileSystem.create(<span class="keyword">new</span> Path(hdfsPathStr));</span><br><span class="line">        InputStream in = <span class="keyword">new</span> BufferedInputStream(<span class="keyword">new</span> FileInputStream(<span class="keyword">new</span> File(localPathStr)));</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//将文件进行拷贝，从输入流到输出流</span></span><br><span class="line">            IOUtils.copyBytes(in, out, <span class="number">4096</span>, <span class="keyword">false</span>);</span><br><span class="line">            out.close();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;<span class="keyword">finally</span> &#123;</span><br><span class="line">            IOUtils.closeStream(in);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>编写delFile删除函数</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">delFile</span><span class="params">(FileSystem fileSystem,String hdfsPathStr,<span class="keyword">boolean</span> recursive)</span></span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">//true：开启级联删除，将删除目录下的全部内容</span></span><br><span class="line">        fileSystem.delete(<span class="keyword">new</span> Path(hdfsPathStr),recursive);</span><br><span class="line">        System.out.println(<span class="string">&quot;DELETE SUCCESSFULLY&quot;</span>);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>编写listFile列表函数</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">listFile</span><span class="params">(FileSystem fileSystem,String hdfsPathStr)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    Path[] paths = <span class="keyword">new</span> Path[<span class="number">1</span>];</span><br><span class="line">    paths[<span class="number">0</span>] = <span class="keyword">new</span> Path(hdfsPathStr);</span><br><span class="line">    FileStatus[] status = fileSystem.listStatus(paths);</span><br><span class="line">    <span class="keyword">for</span> (FileStatus p : status) &#123;</span><br><span class="line">        System.out.println(p);</span><br><span class="line">    &#125;</span><br><span class="line">    Path[] listedPaths = FileUtil.stat2Paths(status);</span><br><span class="line">    <span class="keyword">for</span> (Path p : listedPaths) &#123;</span><br><span class="line">        System.out.println(p);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>完整HDFS API</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.api;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IOUtils;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"><span class="keyword">import</span> java.net.URI;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> Labcz</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@ClassName</span> HdfsJavaApi.java</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span> 对文件上传下载、修改、删除、查看等等操作</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@createTime</span> 2020年10月30日 23:14:00</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HdfsJavaApi</span> </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@function</span> 从HDFS上获取文件到本地</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> fileSystem    传入DFS文件系统</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> hdfsPathStr   HDFS文件路径</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> localPathStr   本地文件路径</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">getFile</span><span class="params">(FileSystem fileSystem,String hdfsPathStr,String localPathStr)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="comment">//定义输入输出流</span></span><br><span class="line">        FSDataInputStream in = fileSystem.open(<span class="keyword">new</span> Path(hdfsPathStr));</span><br><span class="line">        OutputStream out = <span class="keyword">new</span> BufferedOutputStream(<span class="keyword">new</span> FileOutputStream(<span class="keyword">new</span> File(localPathStr)));</span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">            <span class="comment">//进行文件拷贝</span></span><br><span class="line">            IOUtils.copyBytes(in,out,<span class="number">4096</span>,<span class="keyword">false</span>);</span><br><span class="line">            in.seek(<span class="number">0</span>);  <span class="comment">//输入流从新回到文件开始的位置</span></span><br><span class="line">            IOUtils.copyBytes(in, System.out, <span class="number">4096</span>, <span class="keyword">true</span>);</span><br><span class="line">            <span class="comment">//关闭输出流，否则文件内容可能为空</span></span><br><span class="line">            out.close();</span><br><span class="line">            System.out.println(<span class="string">&quot;GET SUCCESSFULLY&quot;</span>);</span><br><span class="line">        &#125;<span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;<span class="keyword">finally</span> &#123;</span><br><span class="line">            IOUtils.closeStream(in);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@function</span> 将本地文件上传到文件系统</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> fileSystem    传入DFS文件系统</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> hdfsPathStr   HDFS文件路径</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> localPathStr  本地文件路径</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">putFile</span><span class="params">(FileSystem fileSystem,String hdfsPathStr,String localPathStr)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="comment">//在HDFS上创建空文件</span></span><br><span class="line">        FSDataOutputStream out = fileSystem.create(<span class="keyword">new</span> Path(hdfsPathStr));</span><br><span class="line">        InputStream in = <span class="keyword">new</span> BufferedInputStream(<span class="keyword">new</span> FileInputStream(<span class="keyword">new</span> File(localPathStr)));</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//将文件进行拷贝，从输入流到输出流</span></span><br><span class="line">            IOUtils.copyBytes(in, out, <span class="number">4096</span>, <span class="keyword">false</span>);</span><br><span class="line">            out.close();</span><br><span class="line">            System.out.println(<span class="string">&quot;PUT SUCCESSFULLY&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;<span class="keyword">finally</span> &#123;</span><br><span class="line">            IOUtils.closeStream(in);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@function</span> 删除文件</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> fileSystem    传入DFS文件系统</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> hdfsPathStr   HDFS文件路径</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">delFile</span><span class="params">(FileSystem fileSystem,String hdfsPathStr,<span class="keyword">boolean</span> recursive)</span></span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//true：开启级联删除，将删除目录下的全部内容</span></span><br><span class="line">            fileSystem.delete(<span class="keyword">new</span> Path(hdfsPathStr),recursive);</span><br><span class="line">            System.out.println(<span class="string">&quot;DELETE SUCCESSFULLY&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@function</span> 列出路径下全部文件内容</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> fileSystem    传入DFS文件系统</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> hdfsPathStr   HDFS目录</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">listFile</span><span class="params">(FileSystem fileSystem,String hdfsPathStr)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        Path[] paths = <span class="keyword">new</span> Path[<span class="number">1</span>];</span><br><span class="line">        paths[<span class="number">0</span>] = <span class="keyword">new</span> Path(hdfsPathStr);</span><br><span class="line">        FileStatus[] status = fileSystem.listStatus(paths);</span><br><span class="line">        <span class="keyword">for</span> (FileStatus p : status) &#123;</span><br><span class="line">            System.out.println(p);</span><br><span class="line">        &#125;</span><br><span class="line">        Path[] listedPaths = FileUtil.stat2Paths(status);</span><br><span class="line">        <span class="keyword">for</span> (Path p : listedPaths) &#123;</span><br><span class="line">            System.out.println(p);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        String cmd = args[<span class="number">0</span>];</span><br><span class="line">        String hdfsPathStr = args[<span class="number">1</span>];</span><br><span class="line">        <span class="comment">//通用三步骤</span></span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        conf.set(<span class="string">&quot;fs.defaultFS&quot;</span>,<span class="string">&quot;hdfs://hadoop01:9000&quot;</span>);</span><br><span class="line">        FileSystem fileSystem = FileSystem.get(URI.create(hdfsPathStr), conf);</span><br><span class="line">        HdfsJavaApi hdfsJavaApi =<span class="keyword">new</span> HdfsJavaApi();</span><br><span class="line">        <span class="keyword">if</span>(cmd.equals(<span class="string">&quot;get&quot;</span>))&#123;</span><br><span class="line">            hdfsJavaApi.getFile(fileSystem,hdfsPathStr,args[<span class="number">2</span>]);</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span>(cmd.equals(<span class="string">&quot;put&quot;</span>))&#123;</span><br><span class="line">            hdfsJavaApi.putFile(fileSystem,hdfsPathStr,args[<span class="number">2</span>]);</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span>(cmd.equals(<span class="string">&quot;delete&quot;</span>))&#123;</span><br><span class="line">            hdfsJavaApi.delFile(fileSystem,hdfsPathStr,Boolean.parseBoolean(args[<span class="number">2</span>]));</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span>(cmd.equals(<span class="string">&quot;list&quot;</span>))&#123;</span><br><span class="line">            hdfsJavaApi.listFile(fileSystem,hdfsPathStr);</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;HDFS JAVA API ERROR:COMMAND NOT FOUND!&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>测试命令</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#执行下载命令,将HDFS/1.txt下载到~/1.txt</span></span><br><span class="line">[liujiazhao@hadoop01 ~]$ hadoop jar HadoopLearning-1.0-SNAPSHOT.jar com.api.HdfsJavaApi get /1.txt /home/liujiazhao/1.txt</span><br><span class="line"></span><br><span class="line"><span class="comment">#执行上传命令,将~/1.txt上传到HDFS的/1.txt</span></span><br><span class="line">[liujiazhao@hadoop01 ~]$ hadoop jar HadoopLearning-1.0-SNAPSHOT.jar com.api.HdfsJavaApi put /2.txt /home/liujiazhao/1.txt</span><br><span class="line"></span><br><span class="line"><span class="comment">#执行删除命令，将/1.jpg文件删除</span></span><br><span class="line">[liujiazhao@hadoop01 ~]$ hadoop jar HadoopLearning-1.0-SNAPSHOT.jar com.api.HdfsJavaApi delete /1.jpg <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#执行删除命令，将/testdata目录下全部文件删除</span></span><br><span class="line">[liujiazhao@hadoop01 ~]$ hadoop jar HadoopLearning-1.0-SNAPSHOT.jar com.api.HdfsJavaApi delete /testdata <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#执行列表查询命令，查询某个目录下全部文件</span></span><br><span class="line">[liujiazhao@hadoop01 ~]$ hadoop jar HadoopLearning-1.0-SNAPSHOT.jar com.api.HdfsJavaApi list /<span class="built_in">test</span></span><br></pre></td></tr></table></figure>

<p><strong>本项目全部源代码上传至GitHub：<a target="_blank" rel="noopener" href="https://github.com/Labcz/HadoopLearning">https://github.com/Labcz/HadoopLearning</a></strong></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://labcz.com">Labcz</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://labcz.com">https://labcz.com</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">此文章版权归LABCZ所有，如有转载，请注明来自原作者。</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Java/">Java</a><a class="post-meta__tags" href="/tags/Hadoop/">Hadoop</a></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/使用JAVA的API操作HDFS/cover.jpg" data-sites="wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> 打赏<div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="https://cdn.jsdelivr.net/gh/Labcz/CDN/images/wechat.jpg" target="_blank"><img class="post-qr-code-img" src="https://cdn.jsdelivr.net/gh/Labcz/CDN/images/wechat.jpg" alt="微信"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="https://cdn.jsdelivr.net/gh/Labcz/CDN/images/alipay.jpg" target="_blank"><img class="post-qr-code-img" src="https://cdn.jsdelivr.net/gh/Labcz/CDN/images/alipay.jpg" alt="支付宝"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/ckhnapxh5000sj9fp9wwp3xh4.html"><img class="prev-cover" src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/cover.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">玩转Git</div></div></a></div><div class="next-post pull-right"><a href="/ckhnapxfh0001j9fpbrx55815.html"><img class="next-cover" src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/IDEA大数据环境安装/bg.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">IDEA大数据环境安装</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相关推荐</span></div><div class="relatedPosts-list"><div><a href="/ckhnapxfh0001j9fpbrx55815.html" title="IDEA大数据环境安装"><img class="cover" src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/IDEA大数据环境安装/bg.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-10-13</div><div class="title">IDEA大数据环境安装</div></div></a></div><div><a href="/ckhnapxh1000oj9fp4e29bodn.html" title="Hadoop安装"><img class="cover" src="https://cdn.jsdelivr.net/gh/Labcz/CDN@1.0.10/passages/Hadoop安装/hadoop.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-09-11</div><div class="title">Hadoop安装</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside_content" id="aside_content"><div class="card-widget card-info"><div class="card-content"><div class="card-info-avatar is-center"><img class="avatar-img" src="https://cdn.jsdelivr.net/gh/Labcz/CDN/images/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">Labcz</div><div class="author-info__description"></div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">7</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">5</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Labcz"><i class="fab fa-github"></i><span>GitHub</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/Labcz" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:labczwork@163.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="card-content"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%88%9B%E5%BB%BAIDEA%E6%96%B0%E9%A1%B9%E7%9B%AE"><span class="toc-number">1.</span> <span class="toc-text">创建IDEA新项目</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E6%96%B0MAVEN%E9%A1%B9%E7%9B%AE"><span class="toc-number">1.1.</span> <span class="toc-text">创建新MAVEN项目</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AF%BC%E5%85%A5pom-xml"><span class="toc-number">1.2.</span> <span class="toc-text">导入pom.xml</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%A0%B9%E6%8D%AEURL%E8%AF%BB%E5%8F%96HDFS%E6%96%87%E4%BB%B6%E5%86%85%E5%AE%B9"><span class="toc-number">2.</span> <span class="toc-text">根据URL读取HDFS文件内容</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8FileSystem%E7%B1%BB%E8%AE%BF%E9%97%AEHDFS"><span class="toc-number">3.</span> <span class="toc-text">使用FileSystem类访问HDFS</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%9F%A5%E7%9C%8BHDFS%E6%96%87%E4%BB%B6-%E7%9B%AE%E5%BD%95%E5%85%83%E4%BF%A1%E6%81%AF"><span class="toc-number">4.</span> <span class="toc-text">查看HDFS文件&#x2F;目录元信息</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%9F%A5%E6%89%BE%E6%9F%90%E4%B8%AA%E6%96%87%E4%BB%B6%E5%9C%A8HDFS%E9%9B%86%E7%BE%A4%E7%9A%84%E4%BD%8D%E7%BD%AE"><span class="toc-number">5.</span> <span class="toc-text">查找某个文件在HDFS集群的位置</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0-%E4%B8%8B%E8%BD%BD"><span class="toc-number">6.</span> <span class="toc-text">文件上传&#x2F;下载</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9C%A8Linux%E4%B8%8A%E8%BF%9B%E8%A1%8C%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0-%E4%B8%8B%E8%BD%BD"><span class="toc-number">7.</span> <span class="toc-text">在Linux上进行文件上传&#x2F;下载</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%98%BE%E7%A4%BA%E8%BF%9B%E5%BA%A6%E6%9D%A1"><span class="toc-number">8.</span> <span class="toc-text">文件上传显示进度条</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9C%A8Linux%E4%B8%8A%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%98%BE%E7%A4%BA%E8%BF%9B%E5%BA%A6%E6%9D%A1"><span class="toc-number">9.</span> <span class="toc-text">在Linux上文件上传显示进度条</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%AF%BB%E5%8F%96HDFS%E6%9F%90%E4%B8%AA%E7%9B%AE%E5%BD%95%E4%B8%8B%E7%9A%84%E6%89%80%E6%9C%89%E6%96%87%E4%BB%B6"><span class="toc-number">10.</span> <span class="toc-text">读取HDFS某个目录下的所有文件</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9C%A8Linux%E4%B8%8A%E8%AF%BB%E5%8F%96HDFS%E6%9F%90%E4%B8%AA%E7%9B%AE%E5%BD%95%E4%B8%8B%E7%9A%84%E6%89%80%E6%9C%89%E6%96%87%E4%BB%B6"><span class="toc-number">11.</span> <span class="toc-text">在Linux上读取HDFS某个目录下的所有文件</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%BC%96%E5%86%99HDFS%E7%9A%84API"><span class="toc-number">12.</span> <span class="toc-text">编写HDFS的API</span></a></li></ol></div></div></div><div class="card-widget card-recent-post"><div class="card-content"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/ckhnapxh5000sj9fp9wwp3xh4.html" title="玩转Git"><img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/玩转Git/cover.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="玩转Git"/></a><div class="content"><a class="title" href="/ckhnapxh5000sj9fp9wwp3xh4.html" title="玩转Git">玩转Git</a><time datetime="2020-11-11T14:50:00.000Z" title="发表于 2020-11-11 22:50:00">2020-11-11</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/ckhnapxhy0013j9fp2fbffp2m.html" title="使用JAVA的API操作HDFS"><img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/使用JAVA的API操作HDFS/cover.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="使用JAVA的API操作HDFS"/></a><div class="content"><a class="title" href="/ckhnapxhy0013j9fp2fbffp2m.html" title="使用JAVA的API操作HDFS">使用JAVA的API操作HDFS</a><time datetime="2020-10-30T07:17:00.000Z" title="发表于 2020-10-30 15:17:00">2020-10-30</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/ckhnapxfh0001j9fpbrx55815.html" title="IDEA大数据环境安装"><img src="https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/IDEA大数据环境安装/bg.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="IDEA大数据环境安装"/></a><div class="content"><a class="title" href="/ckhnapxfh0001j9fpbrx55815.html" title="IDEA大数据环境安装">IDEA大数据环境安装</a><time datetime="2020-10-13T06:45:00.000Z" title="发表于 2020-10-13 14:45:00">2020-10-13</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/ckhnapxh1000oj9fp4e29bodn.html" title="Hadoop安装"><img src="https://cdn.jsdelivr.net/gh/Labcz/CDN@1.0.10/passages/Hadoop安装/hadoop.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Hadoop安装"/></a><div class="content"><a class="title" href="/ckhnapxh1000oj9fp4e29bodn.html" title="Hadoop安装">Hadoop安装</a><time datetime="2020-09-11T03:36:00.000Z" title="发表于 2020-09-11 11:36:00">2020-09-11</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/ckhnapxfs0007j9fpaounetwl.html" title="Linux软件安装管理"><img src="https://cdn.jsdelivr.net/gh/Labcz/CDN@latest/passages/Linux常用命令合集/bash.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Linux软件安装管理"/></a><div class="content"><a class="title" href="/ckhnapxfs0007j9fpaounetwl.html" title="Linux软件安装管理">Linux软件安装管理</a><time datetime="2020-08-07T02:13:10.000Z" title="发表于 2020-08-07 10:13:10">2020-08-07</time></div></div></div></div></div></div></div></main><footer id="footer" style="background-image: url(https://cdn.jsdelivr.net/gh/Labcz/CDN/passages/使用JAVA的API操作HDFS/cover.jpg)"><div id="footer-wrap"><div class="copyright">&copy;2020 By Labcz</div><div class="footer_custom_text"><script src="https://v1.hitokoto.cn/?encode=js&select=%23hitokoto" defer></script><span id="hitokoto"></span></div><div class="icp"><a target="_blank" rel="noopener" href="http://www.beian.miit.gov.cn/"><img class="icp-icon" src="/img/icp.png" alt="ICP"/><span>赣ICP备20002738号-1</span></a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a target="_blank" rel="noopener" href="https://github.com/wzpan/hexo-generator-search" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>function loadValine () {
  function initValine () {
    let initData = {
      el: '#vcomment',
      appId: 'MM1CQ3RqIy4n3EPt9QYrVJDs-MdYXbMMI',
      appKey: 'dIwky9uuaVfu9f3UWNQKIAmA',
      placeholder: '请开始你的表演，请文明发言哦！',
      avatar: 'monsterid',
      meta: 'nick,mail,link'.split(','),
      pageSize: '10',
      lang: 'zh-CN',
      recordIP: true,
      serverURLs: '',
      emojiCDN: '',
      emojiMaps: "",
      enableQQ: true,
      path: window.location.pathname,
    }

    if (true) { 
      initData.requiredFields= ('nick,mail'.split(','))
    }
    
    if (false) {
      const otherData = false
      initData = Object.assign({}, initData, otherData)
    }
    
    const valine = new Valine(initData)
  }

  if (typeof Valine === 'function') initValine() 
  else $.getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js', initValine)
}

if ('Valine' === 'Valine' || !false) {
  if (false) btf.loadComment(document.querySelector('#vcomment'),loadValine)
  else setTimeout(() => loadValine(), 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script src="/js/labcz.js"></script><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-fluttering-ribbon.min.js"></script></div></body></html>